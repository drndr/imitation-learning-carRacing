{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "self_driving_project.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEYo--s0imx0"
      },
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJlNATO3u4Qi"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import gzip\n",
        "import pickle\n",
        "import gdown\n",
        "import os\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.utils.prune as prune\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from skimage.color import rgb2gray\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from skimage import io, transform\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from torchsummary import summary\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jwlXbBQ8ynS"
      },
      "source": [
        "### Source Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BACm_YrhvY0K"
      },
      "source": [
        "#!gdown https://drive.google.com/uc?id=1ojhChs9QryQxG1PYbCDBW3ti5ySDmAze -O data.pkl.gzip\n",
        "\n",
        "def read_data():\n",
        "  with gzip.open('./data_19k.pkl.gzip','rb') as f:\n",
        "    data = pickle.load(f)\n",
        "  X = join_episodes(data['state'])\n",
        "  y = join_episodes(data['action'])\n",
        "  print(y.shape)\n",
        "  return X,y\n",
        "\n",
        "def join_episodes(arr,cutoff=50):\n",
        "\t# Stack all  epsiodes in to one array, discard first 50 frames\n",
        "\tstack = np.array(arr[0][cutoff:],dtype=np.float32)\n",
        "\tfor i in range(1,len(arr)):\n",
        "\t\tstack = np.vstack((stack,arr[i][cutoff:]))\n",
        "\treturn stack"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qDCuHX586wv"
      },
      "source": [
        "### Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N6uXb832Y6y"
      },
      "source": [
        "actions = np.array([\n",
        "\t[ 0.0, 0.0, 0.0 ],  # STRAIGHT\n",
        "\t[ 0.0, 1.0, 0.0 ],  # ACCELERATE\n",
        "\t[ 0.0, 0.0, 0.8 ],  # BRAKE\n",
        "\t[ 1.0, 0.0, 0.0 ],  # RIGHT\n",
        "\t[-1.0, 0.0, 0.0 ],  # LEFT\n",
        "  [ 1.0, 1.0, 0.0 ],  # RIGHT_ACCELERATE\n",
        "\t[-1.0, 1.0, 0.0 ],  # LEFT_ACCELERATE\n",
        "  [ 1.0, 0.0, 0.8 ],  # RIGHT_BRAKE\n",
        "\t[-1.0, 0.0, 0.8 ]   # LEFT_BRAKE\n",
        "], dtype=np.float32)\n",
        "\n",
        "# Replace the colors defined bellow\n",
        "def replace_color(old_color, new_color, X):\n",
        "  mask = np.all(X == old_color, axis=3)\n",
        "  X[mask] = new_color\n",
        "\n",
        "def preprocess_state(X):\n",
        "\n",
        "  X_processed = np.array(X)\n",
        "\n",
        "  new_grass_color = [102., 229., 102.]\n",
        "  replace_color([102., 229., 102.], new_grass_color, X_processed)\n",
        "  replace_color([102., 204., 102.], new_grass_color, X_processed)\n",
        "\n",
        "  new_road_color = [102.0, 102.0, 102.0]\n",
        "  replace_color([102., 102., 102.], new_road_color, X_processed)\n",
        "  replace_color([105., 105., 105.], new_road_color, X_processed)\n",
        "  replace_color([107., 107., 107.], new_road_color, X_processed)\n",
        "\n",
        "  # Normalize rgb channel\n",
        "  X_processed = X_processed / 255.0\n",
        "  # Convert to grayscale\n",
        "  X_processed = rgb2gray(X_processed)\n",
        "\t# Color whole indicator-bar except the acceleration part black\n",
        "  X_processed[:,85:,:15] = 0\n",
        "  X_processed[:,85:,30:] = 0\n",
        "\n",
        "  return X_processed\n",
        "\n",
        "def preprocess_actions(y):\n",
        "    \"\"\" Returns actions in id format\"\"\"\n",
        "    #detect_invalid_actions(In_actions) #Need this to make sure no invalid actions present\n",
        "    ids = []\n",
        "    for action in y:\n",
        "        id = np.where(np.all(actions==action, axis=1))\n",
        "        ids.append(id[0][0])\n",
        "    return np.array(ids)\n",
        "\n",
        "def balance_actions(X, y):\n",
        "    # Find out what action samples are labeled as straight\n",
        "    is_straight = np.where(y==0)[0]\n",
        "\n",
        "    # Find out what action samples are labeled as straight\n",
        "    is_acc = np.where(y==1)[0]\n",
        "\n",
        "    # Get the index of all other non straight and non advanced turning (direction+accelerate/brake) action samples\n",
        "    other_actions = np.where(np.logical_and(y>1,y<5))[0]\n",
        "\n",
        "    # Randomly pick a given amount of straight action\n",
        "    straight_keep = np.random.choice(is_straight,int(len(is_straight)*0.3))\n",
        "\n",
        "    # Randomly pick a given amount of acceleration action\n",
        "    acc_keep = np.random.choice(is_acc,int(len(is_acc)*0.5))\n",
        "\n",
        "    # Find out what action samples are labeled as brake for multiplication (rare event)\n",
        "    is_brake = np.where(y==2)[0]\n",
        "\n",
        "    # Find out what action samples are labeled as right for multiplication (rare event)\n",
        "    is_right = np.where(y==3)[0]\n",
        "\n",
        "    # Put all actions that we want to keep together\n",
        "    final_keep = np.squeeze(np.hstack((other_actions, straight_keep)))\n",
        "    final_keep = np.squeeze(np.hstack((final_keep, acc_keep)))\n",
        "    final_keep = np.squeeze(np.hstack((final_keep, is_brake)))\n",
        "    final_keep = np.squeeze(np.hstack((final_keep, is_right)))\n",
        "    final_keep = np.sort(final_keep)\n",
        "    X_bal, y_bal = X[final_keep], y[final_keep]\n",
        "    # Plot action barcharts\n",
        "    plot_action_barchart(y, 'Action distribution BEFORE balancing')\n",
        "    plot_action_barchart(y_bal, 'Action distribution AFTER balancing')\n",
        "    return X_bal, y_bal\n",
        "\n",
        "def preprocess_data(X,y):\n",
        "    print('data size:  ', len(X))\n",
        "    X = preprocess_state(X)\n",
        "    y = preprocess_actions(y)\n",
        "    return balance_actions(X,y) \n",
        "\n",
        "def split_data(X,y,ratio=0.2):\n",
        "    split=int((1-ratio)*len(X))\n",
        "    X_train, y_train = X[:split], y[:split]\n",
        "    X_test, y_test = X[split:], y[split:]\n",
        "    return X_train,y_train,X_test,y_test\n",
        "\n",
        "def plot_action_barchart(actions, title):\n",
        "    \"\"\" Plot the histogram of actions from the expert dataset \"\"\"\n",
        "    action_sums = []\n",
        "    for i in range(9):\n",
        "      action_sums.append(sum(map(lambda x: x==i, actions)))\n",
        "    action_id = [\"straight\",\"accelerate\",\"brake\",\"right\",\"left\",\"right+acc\",\"left+acc\",\"right+brake\",\"left+brake\"]\n",
        "\n",
        "    x_pos = [i for i, _ in enumerate(action_id)]\n",
        "\n",
        "    plt.figure(figsize=(15,3))\n",
        "    plt.bar(x_pos, action_sums, color='blue')\n",
        "    plt.xlabel(\"Action IDs\")\n",
        "    plt.ylabel(\"Sum of action in sample\")\n",
        "    plt.title(title)\n",
        "\n",
        "    plt.xticks(x_pos, action_id)\n",
        "    plt.show()\n",
        "\n",
        "def show_state_as_img(state, mode):\n",
        "  if (mode=='L'):\n",
        "    state = state*255\n",
        "  img = state.astype(np.uint8)\n",
        "  img = Image.fromarray(img, mode) # L - grayscale RGB - rgb\n",
        "  display(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16m2xIX9YIXj"
      },
      "source": [
        "###Data Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdQrTHXibnvr"
      },
      "source": [
        "def save_trainsplit_data(S,A):\r\n",
        "    samples = {\r\n",
        "        \"state\": [],\r\n",
        "        \"action\": []\r\n",
        "    }\r\n",
        "    samples[\"state\"] = S\r\n",
        "    samples[\"action\"] = A\r\n",
        "    data_file = os.path.join('./', 'data_train_split.pkl.gzip')\r\n",
        "    f = gzip.open(data_file,'wb')\r\n",
        "    \r\n",
        "    pickle.dump(samples, f)\r\n",
        "    f.close()\r\n",
        "\r\n",
        "def save_testsplit_data(S,A):\r\n",
        "    samples = {\r\n",
        "        \"state\": [],\r\n",
        "        \"action\": []\r\n",
        "    }\r\n",
        "    samples[\"state\"] = S\r\n",
        "    samples[\"action\"] = A\r\n",
        "    data_file = os.path.join('./', 'data_test_split.pkl.gzip')\r\n",
        "    f = gzip.open(data_file,'wb')\r\n",
        "    pickle.dump(samples, f)\r\n",
        "    f.close()\r\n",
        "\r\n",
        "def get_train_data():\r\n",
        "    tmp1, tmp2 = read_data()\r\n",
        "    S,A = preprocess_data(tmp1, tmp2)\r\n",
        "    S_train, A_train, _, _ = split_data(S,A)\r\n",
        "    print(\"train size:  \", len(S_train))\r\n",
        "    save_trainsplit_data(S_train, A_train)\r\n",
        "    return S_train, A_train\r\n",
        "\r\n",
        "def get_test_data():\r\n",
        "    tmp1, tmp2 = read_data()\r\n",
        "    S,A = preprocess_data(tmp1, tmp2)\r\n",
        "    _,_,S_test, A_test = split_data(S,A)\r\n",
        "    print(\"test size:  \", len(S_test))\r\n",
        "    save_testsplit_data(S_test, A_test)\r\n",
        "    return S_test, A_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrdgKDu7bAnk"
      },
      "source": [
        "class carRacingDataset(Dataset):\r\n",
        "    \"\"\"carRacing dataset.\"\"\"\r\n",
        "\r\n",
        "    def __init__(self, train, load=False, states=None, actions=None,transform=None):\r\n",
        "        if train:\r\n",
        "            if load:\r\n",
        "                self.states = states\r\n",
        "                self.actions = actions\r\n",
        "            else:\r\n",
        "                self.states, self.actions = get_train_data()\r\n",
        "        else:\r\n",
        "            if load:\r\n",
        "                self.states = states\r\n",
        "                self.actions = actions\r\n",
        "            else:\r\n",
        "                self.states, self.actions = get_test_data()\r\n",
        "        self.states = self.states.reshape(self.states.shape[0],1,96,96)\r\n",
        "        self.transform = transform\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.states)\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        if torch.is_tensor(idx):\r\n",
        "            idx = idx.tolist()\r\n",
        "\r\n",
        "        state = self.states[idx]\r\n",
        "        action = self.actions[idx]\r\n",
        "        sample = {'state': state, 'action': action}\r\n",
        "\r\n",
        "        if self.transform:\r\n",
        "            sample = self.transform(sample[\"state\"])\r\n",
        "\r\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Juw51gDfm63Y"
      },
      "source": [
        "### Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdTE8eYKat5J"
      },
      "source": [
        "class Net(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        super(Net, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(1, 16, 5, stride=1)\r\n",
        "        self.conv2 = nn.Conv2d(16, 32, 4, stride = 1)\r\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, stride = 3)\r\n",
        "        self.fc1 = nn.Linear(64*3*3, 256)\r\n",
        "        self.fc2 = nn.Linear(256, 128)\r\n",
        "        self.fc3 = nn.Linear(128, 5)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\r\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\r\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\r\n",
        "        x = x.view(-1, self.num_flat_features(x))\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = F.relu(self.fc2(x))\r\n",
        "        x = self.fc3(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "    def num_flat_features(self, x):\r\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\r\n",
        "        num_features = 1\r\n",
        "        for s in size:\r\n",
        "            num_features *= s\r\n",
        "        return num_features\r\n",
        "\r\n",
        "net = Net()\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0001)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-Vju_WrQq28"
      },
      "source": [
        "def loss_plot(epochs, loss):\r\n",
        "    plt.plot(epochs, loss, color='red', label='loss')\r\n",
        "\r\n",
        "def accuracy_plot(epochs, accuracy):\r\n",
        "    plt.plot(epochs, accuracy, color='blue', label='accuracy')\r\n",
        "    plt.xlabel('epoch')\r\n",
        "\r\n",
        "def train_net(net,dataloader,num_epochs):\r\n",
        "    accuracy_vals = []\r\n",
        "    loss_vals = []\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        correct = 0.0\r\n",
        "        epoch_loss = 0.0\r\n",
        "        for i, data in enumerate(dataloader, 0):\r\n",
        "            # get the inputs; data is a list of [inputs, labels]\r\n",
        "            inputs, labels = data[\"state\"].to(device), data[\"action\"].to(device)            \r\n",
        "            # zero the parameter gradients\r\n",
        "            optimizer.zero_grad()\r\n",
        "            # forward + backward + optimize\r\n",
        "            outputs = net(inputs)\r\n",
        "            loss = criterion(outputs, labels)\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "            #Collect accuracy and loss info\r\n",
        "            _, predicted = torch.max(outputs.data, 1)\r\n",
        "            correct += (predicted == labels).sum().item()\r\n",
        "            epoch_loss += outputs.shape[0] * loss.item()\r\n",
        "        # Pring training progress\r\n",
        "        print(\"epoch: \",epoch+1, \" loss: \",epoch_loss/len(carRacing_dataset),\" accuracy: \", 100*correct/len(carRacing_dataset))\r\n",
        "        # Add accuracy and loss info to plot\r\n",
        "        accuracy_vals.append(correct/len(carRacing_dataset))\r\n",
        "        loss_vals.append(epoch_loss/len(carRacing_dataset))\r\n",
        "    \r\n",
        "    accuracy_plot(np.linspace(1, num_epochs, num_epochs).astype(int), accuracy_vals)\r\n",
        "    loss_plot(np.linspace(1, num_epochs, num_epochs).astype(int), loss_vals)\r\n",
        "    print('Finished Training')\r\n",
        "\r\n",
        "def test_net(net,dataloaderTest):\r\n",
        "    correct = 0\r\n",
        "    total = 0\r\n",
        "    y_pred_list = []\r\n",
        "    y_true_list = []\r\n",
        "    with torch.no_grad():\r\n",
        "        for data in dataloaderTest:\r\n",
        "            states, actions = data[\"state\"].to(device), data[\"action\"].to(device)\r\n",
        "            outputs = net(states)\r\n",
        "            _, predicted = torch.max(outputs, dim=1)\r\n",
        "            total += actions.size(0)\r\n",
        "            correct += (predicted == actions).sum().item()\r\n",
        "            y_pred_list.append(predicted.cpu().numpy())\r\n",
        "            y_true_list.append(actions.cpu().numpy())\r\n",
        "    #print('Accuracy of the network on the test set: %d %%' % (100*correct / total))\r\n",
        "    print(classification_report(y_true_list, y_pred_list, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkITvydTO0p8"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz6QJjVGO8tL"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eUdNyJbKQ4O9",
        "outputId": "7c497924-2322-4dca-a038-3c9632610d6d"
      },
      "source": [
        "# create dataloader for training\r\n",
        "carRacing_dataset = carRacingDataset(train = True)\r\n",
        "dataloader = DataLoader(carRacing_dataset, batch_size=110,shuffle=True, num_workers=2)\r\n",
        "# create dataloader for testing\r\n",
        "carRacing_dataset_test = carRacingDataset(train = False)\r\n",
        "dataloader_test = DataLoader(carRacing_dataset_test,shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19054, 3)\n",
            "data size:   19054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4EAAADgCAYAAAC96mOuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debglVX3v//dHUJAZhCAy2CgYQwYMtjPxOoUpKnhVhBhBw5X4i4rGqybeJKJRb5yJQxxwYHBCBFRUxAHBgStgNwIyiCCDgKDMs2jj9/dHrYO7T59hd/epPsN+v55nP6dq1aqq7167zt77u9eqqlQVkiRJkqTRcL/ZDkCSJEmStOaYBEqSJEnSCDEJlCRJkqQRYhIoSZIkSSPEJFCSJEmSRohJoCRJkiSNEJNASRoRST6S5N/XwH6ekuTqgfkLkjxlhrb9wiTfHJivJDvMxLbb9u5I8rCZ2t5ClOTFSX6wiusud2z0IclfJbm4z31I0nxnEihJ80CS05LcnGSdIeuv8EW9ql5WVW/pJ8LJVdWfVtVpU9VJsqgldGtPs63PVNVuMxFXa9P/NW77G1TVZTOx/XH7uiLJ3S3JvDnJ15JsO7D8yCS/bcvHHue2ZWNts8KytnybJJ9JcmOSO5OcleSZ4/ZfbdkdSa5J8t4ka41ri9+M28dXZrod1oSq+n5V/fFsxyFJc5lJoCTNcUkWAX8FFPDsWQ1mFk2XIM4Dz6qqDYCtgF8BHxi3/J0tCR177Dxu+SbjlyXZDPgB8FvgT4HNgcOAzyZ53rj1d277/x/AC4C/H7f8FeP2/6zVfcKSpLnJJFCS5r4DgDOAI4EDBxck2TbJCUmubz1BH0zyJ8BHgCe0Hp1bWt0jk7x1YN2XJrk0yU1JTkzykIFlleRlSS5JckuS/06SiYJL8sC27ZuTXAg8ZtzyK5I8o00/NsmSJLcl+VWS97Zq32t/b2kxP6H1Zp6e5LAkNwJvmmQo4l5JLktyQ5J3Jblf29ebknx6II77ehuTvI0usf5g298HB573Dm164yRHt7a9Msm/DWz7xUl+kOTd7XlfnmTPKV/Fpqp+AxwH7DRM/Wn8E3AHcFBVXVdVd1fV54C3Ae+Z6DWrqkuB04FHrcZ+0461W5P8NMnTBxa8JMlFSW5vr8s/TLGRf0ny81b3wiTPGVg2ZRsn2SzJEUl+2ZZ/qZWPH458RZLXJjmvxfv5JOsOLH99kmvbdv5XZniIsSTNRSaBkjT3HQB8pj12T7IlQBvO91XgSmARsDVwTFVdBLwM+GHr0dlk/AaTPA34T2Bfup6pK4FjxlV7Jl1C9xet3u6TxHco8PD22J1xieo47wPeV1UbtfrHtvInt79jvV0/bPOPAy4DtqRLbCbyHGAxsAuwNyv2cK2gqv4V+D5/6P16xQTVPgBsDDyMrvfsAOAlA8sfB1xM1/v2TuATkyXKg5KsR9cTd8Z0dYfw18DxVfX7ceXHAtsBj5hg/4+kS4AvXY39Pg74Od1zPxQ4ofVKAvya7tjZiK69DkuyyyTb+XmLZWPgzcCnk2w1bj+TtfGngPXoekD/iK4HdDL7AnsA29Mdzy8GSLIH8BrgGcAOwFOmfeaStACYBErSHJZkV+ChwLFVtZTuS/PftsWPBR4CvK6q7qyq31TVsBfseCHwyao6u6ruAd5A13O4aKDO26vqlqr6BXAqk/cc7Qu8rapuqqqrgPdPsd/fATsk2byq7qiq6RKhX1bVB6pqWVXdPUmdd7R9/wL4L2D/abY5rZZg7we8oapur6orgPcALxqodmVVfayq7gWOokumt5xis19qvbK30iVv7xq3/LWt13XscdS45TcMLHttK9scuHaCfV07sHzM2UnuBC4CTgM+NG6d94/b/1Tnj/4a+K+q+l1VfZ4uUfsbgKr6WlX9vDrfBb5Jl+itoKq+UFW/rKrft+1cQndcj5mwjVuiuCfwsqq6ucXx3SnifX/bz03AV/jDsbwvcERVXVBVdwFvmmIbkrRgmARK0tx2IPDNqrqhzX+WP/S0bUv3JXnZKmz3IXS9fwBU1R3AjXS9iWOuG5i+C9hgim1dNTB/5ST1AA6i6536aZIfZdwFTCZw1TTLx9e5ssWzujYH7s/yz+VKJmmflkDA5G0EsE/rlV0XeAXw3SQPHlj+7qraZOAxvkd184Fl725lN9AlRuNtNbB8zC4tvhfQ9bCtP26dQ8btf6oryV5TVTUwf1+7J9kzyRnphhnfAuzF8snofZIckOScscQT+LNxdSdr422Bm6rq5iliHDTZsTz+2B3meJOkec8kUJLmqCQPpOup+B9JrktyHd05YDsn2ZnuC+t2mfiCKTVB2aBf0vUwju1rfeBBwDWrEOq1dF/Kx2w3WcWquqSq9qcbvvcO4Li278nine55MMG+f9mm76QbLjhmMOGabts30PVaPnSgbDtWrX2W32nVvVV1AnAvsOtqbu7bwP8cO1dxwL50x8fPxu27qupY4IfAG1djv1uPG/q6HfDLdFevPR54N7BlS3pPAlYYJpvkocDH6BLiB7W6509UdwJXAZslWWGo80q6FthmYH7bySpK0kJiEihJc9c+dInCTnTD1x4F/AnduWwHAGfRfYl9e5L1k6yb5Elt3V8B2yR5wCTb/hzwkiSPal/c/y9wZhv2uLKOBd6QZNMk2wCvnKxikr9LskU7h+2WVvx74Pr2d1Xu0fe6tu9tgVcBn2/l5wBPTrJdko3phrwO+tVk+2vDD48F3pZkw5awvAb49ET1V0Y6ewOb0g3NXB2H0Z1P94kkD27HwP7Av9INE54s0X078NJxPZEr44+AQ5LcP8nz6Y7Lk4AHAOvQvZ7L2oVcJrulx1jyfz10F5Sh6wmcVlVdC3wd+FB77e+f5MnTrTeBY+n+D/6knavZ+300JWkuMAmUpLnrQLrzlX7Rrvx4XVVdB3yQ7py+AM+iu6DFL4Cr6Yb6AXwHuAC4LskN4zdcVd+m+8J7PF0i+XC6c+BWxZvphgNeTnf+16emqLsHcEGSO+guErNfu6LlXXQXfjm9DQ18/Ers/8vAUrqk72vAJwCq6lt0CeF5bflXx633PuB57cqSE53H+Eq63sTL6G7D8FngkysR13hfac/7NrrnemBVXTCw/PVZ/j59K7xu41XVjXS9iesCF9IN6X0N8KJ2jt1k6/2E7oqsrxso/uC4/S+dYtdnAjvS9Zi+DXheVd1YVbcDh9AlVzfTnb964iQxXEh3nuUP6RLyP6e7aumwXkTXW/tTunMUX70S647F8HW6c1hPpbtQztg5qves7LYkaT7J5D8SSpIkjY50t1c5H1hnFc+1laR5wZ5ASZI0spI8J8k6STalO0/1KyaAkhY6k0BJkjTK/oFuOOnP6c7B/f9mNxxJ6p/DQSVJkiRphNgTKEmSJEkjxCRQkiRJkkbIRDcYnvc233zzWrRo0WyHIUmSJEmzYunSpTdU1RYTLVuQSeCiRYtYsmTJbIchSZIkSbMiyZWTLXM4qCRJkiSNEJNASZIkSRohJoGSJEmSNEJMAiVJkiRphJgESpIkSdIIWZBXB52rktmOYG6qmu0IJEmSpNFhT6AkSZIkjRCTQEmSJEkaISaBkiRJkjRCTAIlSZIkaYSYBEqSJEnSCOk1CUzyT0kuSHJ+ks8lWTfJ9knOTHJpks8neUCru06bv7QtXzSwnTe08ouT7N5nzJIkSZK0kPWWBCbZGjgEWFxVfwasBewHvAM4rKp2AG4GDmqrHATc3MoPa/VIslNb70+BPYAPJVmrr7glSZIkaSHrezjo2sADk6wNrAdcCzwNOK4tPwrYp03v3eZpy5+eJK38mKq6p6ouBy4FHttz3JIkSZK0IPWWBFbVNcC7gV/QJX+3AkuBW6pqWat2NbB1m94auKqtu6zVf9Bg+QTr3CfJwUmWJFly/fXXz/wTkiRJkqQFoM/hoJvS9eJtDzwEWJ9uOGcvqurwqlpcVYu32GKLvnYjSZIkSfNan8NBnwFcXlXXV9XvgBOAJwGbtOGhANsA17Tpa4BtAdryjYEbB8snWEeSJEmStBL6TAJ/ATw+yXrt3L6nAxcCpwLPa3UOBL7cpk9s87Tl36mqauX7tauHbg/sCJzVY9ySJEmStGCtPX2VVVNVZyY5DjgbWAb8GDgc+BpwTJK3trJPtFU+AXwqyaXATXRXBKWqLkhyLF0CuQx4eVXd21fckiRJkrSQpetsW1gWL15cS5Ysme0wVpDMdgRz0wI8BCVJkqRZlWRpVS2eaNnQw0GTrDdzIUmSJEmSZsO0SWCSJya5EPhpm985yYd6j0ySJEmSNOOG6Qk8DNid7kqdVNW5wJP7DEqSJEmS1I+hhoNW1VXjirwwiyRJkiTNQ8NcHfSqJE8EKsn9gVcBF/UbliRJkiSpD8P0BL4MeDmwNd1N2h/V5iVJkiRJ88y0PYFVdQPwwjUQiyRJkiSpZ5MmgUk+AEx6B7eqOqSXiCRJkiRJvZmqJ3Du3W1dkiRJkrRaJk0Cq+qowfkkG3XFdXvvUUmSJEmSejHMzeIXJ/kJcB5wfpJzkzy6/9AkSZIkSTNtmFtEfBL4x6r6PkCSXYEjgL/oMzBJkiRJ0swb5hYR944lgABV9QNgWX8hSZIkSZL6MkxP4HeTfBT4HN3VQl8AnJZkF4CqOrvH+CRJkiRJM2iYJHDn9vfQceV/SZcUPm1GI5IkSZIk9WaYm8U/dU0EIkmSJEnq37RJYJJNgAOARYP1vVm8JEmSJM0/wwwHPQk4A/gJ8Pt+w5EkSZIk9WmYJHDdqnpN75FIkiRJkno3zC0iPpXkpUm2SrLZ2KP3yCRJkiRJM26YnsDfAu8C/pXuaqC0vw/rKyhJkiRJUj+GSQL/N7BDVd3QdzCSJEmSpH4NMxz0UuCuvgORJEmSJPVvmJ7AO4FzkpwK3DNW6C0iJEmSJGn+GSYJ/FJ7SJIkSZLmuWmTwKo6ak0EIkmSJEnq37RJYJIdgf8EdgLWHSuvKq8OKkmSJEnzzDAXhjkC+DCwDHgqcDTw6WE2nmSTJMcl+WmSi5I8od1n8FtJLml/N211k+T9SS5Ncl6SXQa2c2Crf0mSA1f+aUqSJEmSYLgk8IFVdQqQqrqyqt4E/M2Q238fcHJVPRLYGbgI+BfglKraETilzQPsCezYHgfTJZ60G9MfCjwOeCxw6FjiKEmSJElaOcMkgfckuR9wSZJXJHkOsMF0KyXZGHgy8AmAqvptVd0C7A2MnWd4FLBPm94bOLo6ZwCbJNkK2B34VlXdVFU3A98C9hj+KUqSJEmSxgyTBL4KWA84BHg08CJgmCGZ2wPXA0ck+XGSjydZH9iyqq5tda4DtmzTWwNXDax/dSubrFySJEmStJKGuTroj9rkHUkOAjaoqtuG3PYuwCur6swk7+MPQz/Htl1JamWDnkiSg+mGkbLddtvNxCYlSZIkacGZticwyWeTbNR68c4HLkzyuiG2fTVwdVWd2eaPo0sKf9WGedL+/rotvwbYdmD9bVrZZOXLqarDq2pxVS3eYosthghPkiRJkkbPMMNBd2o9f/sAX6cb5vmi6VaqquuAq5L8cSt6OnAhcCJ/GE56IPDlNn0icEC7SujjgVvbsNFvALsl2bRdEGa3ViZJkiRJWknTDgcF7p/k/nRJ4Aer6ncrMYTzlcBnkjwAuAx4CV3ieWwbWnolsG+rexKwF3ApcFerS1XdlOQtwNiw1P+oqpuG3L8kSZIkacAwSeBHgSuAc4HvJXkoMMw5gVTVOcDiCRY9fYK6Bbx8ku18EvjkMPuUJEmSJE1u2uGgVfX+qtq6qvZqidov6G4aL0mSJEmaZ4bpCVxOSwSX9RCLJEmSJKlnw1wYRpIkSZK0QJgESpIkSdIIGWo4aJInAosG61fV0T3FJEmSJEnqybRJYJJPAQ8HzgHubcUFmARKkiRJ0jwzTE/gYrobxg97b0BJkiRJ0hw1zDmB5wMP7jsQSZIkSVL/hukJ3By4MMlZwD1jhVX17N6iklZSMtsRzD323UuSJGkiwySBb+o7CEmSJEnSmjFtElhV310TgUiSJEmS+jdpEpjkB1W1a5Lb6a4Get8ioKpqo96jkyRJkiTNqEmTwKratf3dcM2FI0mSJEnq0zBXB5UkSZIkLRAmgZIkSZI0QkwCJUmSJGmEmARKkiRJ0giZNglM8j+TXJLk1iS3Jbk9yW1rIjhJkiRJ0swa5mbx7wSeVVUX9R2MJEmSJKlfwwwH/ZUJoCRJkiQtDMP0BC5J8nngS8A9Y4VVdUJvUUmSJEmSejFMErgRcBew20BZASaBkiRJkjTPTJsEVtVL1kQgkiRJkqT+DXN10G2SfDHJr9vj+CTbrIngJEmSJEkza5gLwxwBnAg8pD2+0sokSZIkSfPMMEngFlV1RFUta48jgS16jkuSJEmS1INhksAbk/xdkrXa4++AG/sOTJIkSZI084ZJAv8e2Be4DrgWeB7gxWIkSZIkaR6aNgmsqiur6tlVtUVV/VFV7VNVvxh2B6338MdJvtrmt09yZpJLk3w+yQNa+Tpt/tK2fNHANt7Qyi9OsvvKP01JkiRJEkxxi4gkr6+qdyb5AN19AZdTVYcMuY9XARfR3W8Q4B3AYVV1TJKPAAcBH25/b66qHZLs1+q9IMlOwH7An9JdmObbSR5RVfcOuX9JkiRJUjNVT+BF7e8SYOkEj2m1W0n8DfDxNh/gacBxrcpRwD5teu82T1v+9FZ/b+CYqrqnqi4HLgUeO8z+JUmSJEnLm7QnsKq+0ibvqqovDC5L8vwht/9fwOuBDdv8g4BbqmpZm78a2LpNbw1c1fa9LMmtrf7WwBkD2xxcR5IkSZK0Eoa5MMwbhixbTpJnAr+uqqF6DVdXkoOTLEmy5Prrr18Tu5QkSZKkeWeqcwL3BPYCtk7y/oFFGwHLJl5rOU8Cnp1kL2Ddtt77gE2SrN16A7cBrmn1rwG2Ba5OsjawMd2tKMbKxwyuc5+qOhw4HGDx4sUrnMMoSZIkSZq6J/CXdOcD/oblzwU8EZj2Cp1V9Yaq2qaqFtFd2OU7VfVC4FS620wAHAh8uU2f2OZpy79TVdXK92tXD90e2BE4a+hnKEmSJEm6z1TnBJ4LnJvki8CdY1fjTLIWsM5q7POfgWOSvBX4MfCJVv4J4FNJLgVuokscqaoLkhwLXEjXA/lyrwwqSZIkSasmXWfbFBWSM4BnVNUdbX4D4JtV9cQ1EN8qWbx4cS1ZsmS2w1hBMtsRzE3THIJDsW1XNBPtKkmSpPkpydKqWjzRsmEuDLPuWAII0KbXm6ngJEmSJElrzjBJ4J1JdhmbSfJo4O7+QpIkSZIk9WXScwIHvBr4QpJfAgEeDLyg16gkSZIkSb2YNgmsqh8leSTwx63o4qr6Xb9hSZIkSZL6MExPIHQJ4E509/vbJQlVdXR/YUmSJEmS+jBtEpjkUOApdEngScCewA8Ak0BJkiRJmmeGuTDM84CnA9dV1UuAnYGNe41KkiRJktSLYZLAu6vq98CyJBsBvwa27TcsSZIkSVIfhjkncEmSTYCPAUuBO4Af9hqVJEmSJKkXw1wd9B/b5EeSnAxsVFXn9RuWJEmSJKkPw14dFICquqKnOCRJkiRJa8Aw5wRKkiRJkhaISZPAJNuvyUAkSZIkSf2bqifwOIAkp6yhWCRJkiRJPZvqnMD7Jfk/wCOSvGb8wqp6b39hSZIkSZL6MFUSuB+wT6uz4ZoJR5KkVZfMdgRzT9VsRyBJmmsmTQKr6mLgHUnOq6qvr8GYJEmSJEk9GebqoP8vyXuTLGmP9yTZuPfIJEmSJEkzbpgk8JPA7cC+7XEbcESfQUmSJEmS+jHMzeIfXlXPHZh/c5Jz+gpIkiRJktSfYXoC706y69hMkicBd/cXkiRJkiSpL8P0BL4MOHrgPMCbgQP7C0mSJEmS1Jdpk8CqOhfYOclGbf623qOSJEmSJPVimJ5AwORPkiRJkhaCYc4JlCRJkiQtECaBkiRJkjRCph0OmmQt4G+ARYP1q+q9/YUlSZIkSerDMOcEfgX4DfAT4Pf9hiNJkiRJ6tMwSeA2VfUXK7vhJNsCRwNbAgUcXlXvS7IZ8Hm6nsUrgH2r6uYkAd4H7AXcBby4qs5u2zoQ+Le26bdW1VErG48kSZIkabhzAr+eZLdV2PYy4H9X1U7A44GXJ9kJ+BfglKraETilzQPsCezYHgcDHwZoSeOhwOOAxwKHJtl0FeKRJEmSpJE3TBJ4BvDFJHcnuS3J7UmmvV1EVV071pNXVbcDFwFbA3sDYz15RwH7tOm9gaOrcwawSZKtgN2Bb1XVTVV1M/AtYI+VeI6SJEmSpGaYJPC9wBOA9apqo6rasKo2WpmdJFkE/CVwJrBlVV3bFl1HN1wUugTxqoHVrm5lk5WP38fBSZYkWXL99devTHiSJEmSNDKGSQKvAs6vqlqVHSTZADgeePX4G863ba7SdserqsOranFVLd5iiy1mYpOSJEmStOAMc2GYy4DTknwduGescJhbRCS5P10C+JmqOqEV/yrJVlV1bRvu+etWfg2w7cDq27Sya4CnjCs/bYi4JUmSJEnjDNMTeDndBVweAGw48JhSu9rnJ4CLxiWMJwIHtukDgS8PlB+QzuOBW9uw0W8AuyXZtF0QZrdWJkmSJElaSdP2BFbVm1dx208CXgT8JMk5rez/AG8Hjk1yEHAlsG9bdhLd7SEupbtFxEva/m9K8hbgR63ef1TVTasYkyRJkiSNtEx3ql+SU5ngvL2qelpfQa2uxYsX15IlS2Y7jBUksx3B3LRqZ5suz7Zd0Uy0qzTf+F6wIt8LJGk0JVlaVYsnWjbMOYGvHZheF3gu3T0AJUmSJEnzzDDDQZeOKzo9yVk9xSNJkiRJ6tG0SWCSzQZm7wc8Gti4t4gkSZIkSb0ZZjjoUrpzAkM3DPRy4KA+g5IkSZIk9WOY4aDbr4lAJEmSJEn9m/Q+gUkek+TBA/MHJPlykvePGyIqSZIkSZonprpZ/EeB3wIkeTLd/f2OBm4FDu8/NEmSJEnSTJtqOOhaAzdlfwFweFUdDxw/cPN3SZIkSdI8MmUSmGTtqloGPB04eMj1JEnT8KbmK/Km5pIkrRlTJXOfA76b5AbgbuD7AEl2oBsSKkmSJEmaZyZNAqvqbUlOAbYCvll132+09wNeuSaCkyRJkiTNrCmHdVbVGROU/ay/cCRJkiRJfZrq6qCSJEmSpAXGJFCSJEmSRohJoCRJkiSNEJNASZIkSRohJoGSJEmSNEJMAiVJkiRphJgESpIkSdIIMQmUJEmSpBFiEihJkiRJI8QkUJIkSZJGiEmgJEmSJI0Qk0BJkiRJGiEmgZIkSZI0Qtae7QAkSdLcl8x2BHNP1WxHIEmrxiRQkiRplphcr8jkem7zmF3RfDxm500SmGQP4H3AWsDHq+rtsxyStOD5Rr+i+fhGL0mSNGhenBOYZC3gv4E9gZ2A/ZPsNLtRSZIkSdL8M196Ah8LXFpVlwEkOQbYG7hwVqOSJEnSnORolhU5mkVj5kVPILA1cNXA/NWtTJIkSZK0EuZLT+C0khwMHNxm70hy8WzGMw9sDtww20HAgvulznbtz5xoW9u1P7ZtP2zX/ti2/bBd+2Pb9mMOt+tDJ1swX5LAa4BtB+a3aWX3qarDgcPXZFDzWZIlVbV4tuNYaGzX/ti2/bBd+2Pb9sN27Y9t2w/btT+27aqbL8NBfwTsmGT7JA8A9gNOnOWYJEmSJGnemRc9gVW1LMkrgG/Q3SLik1V1wSyHJUmSJEnzzrxIAgGq6iTgpNmOYwFx6Gw/bNf+2Lb9sF37Y9v2w3btj23bD9u1P7btKkp5rVhJkiRJGhnz5ZxASZIkSdIMMAmc55K8Osl6q7DefyR5xjR13pTktROUb5LkH1d2nwtZktOSzMjVqZLsk2SnmdjWXJVkUZLzV2P9I5M8byZjWsiSnJRkk2nqTHgMJ3lUkr36i25+S3LHEHUOSXJRks+Mwv/3RDwG++Hxt/rW5LG5up99bRvz4vOv72MzyYuTfHA1Y7wiyears435zCRw/ns1MGESmGStyVaqqjdW1bdXcZ+bACaBq2Gq1wbYBxj5D+lp2khDShLgmVV1yypu4lGAX8BXzz8Cf11VL2QE/7/7PAbbF+KnrGpsI2Ko4y/JFWsyqLlgrh6bI/T51+uxmY65ziRsmHkkyfpJvpbk3CTnJzkUeAhwapJTW507krwnybnAE5K8McmPWv3D2xvecr8kJdkryU+TLE3y/iRfHdjtTu0XsMuSHNLK3g48PMk5Sd615lpg9SX5UnueFyQ5uJXtkeTs1q6ntLINkhyR5CdJzkvy3Fa+W5IftvpfSLLBBPuYsE77xekdSc4Gnp/kpe21OTfJ8UnWS/JE4NnAu1r7Prw9Tm5xfz/JI9dYg/Vr7fbr30VJjmvPf9o2Gr+RJG9px/NaSV7X6p+X5M2z8JzmhPZr88VJjgbOB+4d+7Uzyb+3ZT9I8rks39v//CRnJflZkr9Kd0ue/wBe0I7HF8zC05k3Jjr+knwEeBjw9ST/yrj/79mMt0+zfQxO9F7fyod+v59v+jj+2uv4/dZmZ7fPqLFl/9za7Nwkb29lOyT5dis7ey4e47N9bDLBZ1/b94L9/OvxvXHbdN9RL0n3nXii13fbJB9OsqS9H6zQNkkemOTrrc3XT/LJ9lr/OMneM9IIc1FV+ZgnD+C5wMcG5jcGrgA2HygrYN+B+c0Gpj8FPKtNHwk8D1gXuArYvpV/Dvhqm34T8P+AdYDNgRuB+wOLgPNnuz1WsQ03a38fSPfmsOW45z+2/B3Afw2st2lrg+8B67eyfwbe2KZPAxZPU+cK4PUD23zQwPRbgVcOvjYDy04BdmzTjwO+M9vtOAOvw6J2rD6pzX8SeO3KthHwLuAjQIDd6K4SFrofuL4KPHm2n+sstu/vgccPHHubA48Bzmn/9xsClwCvHTiG39Om9wK+3aZfDHxwtp/TXH0Ad7S/kx5/DLxPj///XqiPNXUMtvZ8ygTl49/rHwRswZDv97PdfrNx/AFXTFC2HrBum94RWNKm96T7frDeuLY8E3hOm153bPlceszmsckkn30DcSyYz781cGy+GLiW7n977P988fjXd9nnjNgAAAgGSURBVNzxuVZ7Lf9iYP+LgG8DB7Sy/wv8XZveBPgZ7TvdQnvMm1tECICfAO9J8g66RO376Tr2Bt0LHD8w/9Qkr6d7I98MuAD4ysDyRwKXVdXlbf5zwMEDy79WVfcA9yT5NV3SNJ8dkuQ5bXpbuuf6vbHnX1U3tWXPAPYbW6mqbk7yTLqhCqe3dn8A8MNx23/8NHU+PzD9Z0neSvcmswHdfTCXk64X8YnAFwZe63VW4vnOZVdV1elt+tPAWE/zsG3078CZVTXWo7sb3YfNj9vyDei+tHyvn/DnvCur6oxxZU8CvlxVvwF+k+Qr45af0P4upftg1PA8/lbUyzGYZHe6xA1gO2DXdOcf3VNVj2vl49/rd6RLAod6vx/+Kc4Zq3T8tR6Y57fZhyQ5p02fXlUvp/vh94NJHkX3/eIRbfkzgCOq6i7o2jLJhsDWVfXFVvabGXlm/ZjNY3Oiz753t/mF+PnX17EJ8K2qurHVPwHYFfgSK76++7YRAWsDW9F9TzuvLfsy8M6q+sxAvM8e6AVel+61vGj4pzw/mATOI1X1syS70P0K9daxoSzj/Kaq7gVIsi7wIWBxVV2V5E10B/PKuGdg+l7m8TGTbmz+M4AnVNVdSU6j+9Vv2OGVoXvD2X816tw5MH0ksE9VnZvkxcBTJqh/P+CWqnrUkDHOJ+PvTzM2P2wb/Qh4dJLN2pe5AP9ZVR/tJ9x5587pq6xg7P99Xv+vzxKPvxX1cgxW1TdoX4iTHAkcWVWnjS2f5L1+ZT/75ptVOv6q6m3A26AbjjjBZ80/Ab8Cdqb7PJrLid3KmJVjc6zaFPML8fOvr2MThvgekWR7upFGj2k/6B/J8u8HpwN7JPlsdd1/AZ5bVRevTLzzkecEziNJHgLcVVWfphsGsAtwO92whYmMHeQ3tB6lia4mdTHwsCSL2vwwY9qn2udctjFwc/tS8Ei6Xrt1gSe3NwmSbNbqfgsY+6WJJJsCZwBPSrJDK1s/ySNY3jB1xmwIXJvk/sALB8rva9+qug24PMnz2/aSZOdVe/pzznZJntCm/xb4wQR1JmsjgJPpzk/9WvsF+hvA3+cP52BuneSP+gl93jodeFaSdVs7PXOIdebr//uaNuzxN+rtuSaOwYne66F7fx72/X6+6ev42xi4tqp+D7yIbjgddG32kvzhfLbNqup24Ook+7SydbIKVy+fRWvq/XGYzz5YOJ9/fb43/nWSzZI8kO7CMqdPUGcjuqTw1iRb0g1lHvRG4GbgvwfifWVy3zU0/nIlY5o3TALnlz8Hzmpd4ofSjRE/HDg57cIwg6q72tXH6MZJf4Pul6Pxde6muzrTyUmW0v0T3jpVEK3r/fR0F5uZTxeGOZnuhOyL6N48zwCupxsSekK6i+mMDcV4K7Bpe47nAk+tquvpxqB/Lsl5dMM8l+tFHKbOgH+nO3/idOCnA+XHAK9Ld0Lyw+ne/A9qcVwALJSTlC8GXt5ej02BD09QZ7I2AqCqvkB3jJ8IfB/4LPDDJD8BjmO0v2yvoKp+RNdW5wFfpxtiPuX/O3Aq3QWivDDMFKrqmwx3/I3//x4pa+gYnOi9fuz9eaj3+5V8WrOux+PvQ8CBrV0eSethqaqT6V7HJe07ydjQuRfRDcU9j+6cwQevxtNao9bg++Mwn32wQD7/en5vPIvuFKjzgOOraskE+z+XbijqT1scEyWKrwIemOSdwFvohkGfl+SCNr8gpev51ChLskFV3dF+9fhv4JKqOmy245I08wb+39ejOyfj4Ko6e7bj0ujwGNRc5bGpUeI5HwJ4aZID6S5i8mNgLo4plzQzDk93Q951gaP8gqNZ4DGoucpjUyPDnkBJkiRJGiGeEyhJkiRJI8QkUJIkSZJGiEmgJEmSJI0Qk0BJ0shKsk+SaveTm67uqwfve5bkpCSbzEAMb0ry2jZ9ZJLLk5yb5GdJjk6yzeruQ5KkQSaBkqRRtj/dzZr3H6Luq4H7ksCq2qvdj3Wmva6qdgb+mO6Kzd9J8oAe9iNJGlEmgZKkkZRkA2BX4CBgv4HytZK8u908/Lwkr0xyCPAQ4NQkp7Z6VyTZvE2/ptU/P8mrW9miJBcl+ViSC5J8M8kDh42vOocB1wF7triObPv4SZJ/mrHGkCSNFO8TKEkaVXsDJ1fVz5LcmOTRVbUUOBhYBDyqqpYl2ayqbkryGuCpVXXD4EaSPBp4CfA4IMCZSb4L3AzsCOxfVS9NcizwXODTKxnn2cAjgauBravqz9p+V3soqiRpNNkTKEkaVfsDx7TpY/jDkNBnAB+tqmUAVXXTNNvZFfhiVd1ZVXcAJwB/1ZZdXlXntOmldMnlykr7exnwsCQfSLIHcNsqbEuSJHsCJUmjJ8lmwNOAP09SwFpAJXndDO/qnoHpe4Ghh4MO+EvglKq6OcnOwO7Ay4B9gb9f/RAlSaPGnkBJ0ih6HvCpqnpoVS2qqm2By+l68L4F/EOSteG+hBHgdmDDCbb1fWCfJOslWR94TitbLekcAmwFnNzOP7xfVR0P/Buwy+ruQ5I0mkwCJUmjaH/gi+PKjm/lHwd+AZyX5Fzgb9vyw+mSsVMHV6qqs4EjgbOAM4GPV9WPVyO2d7X9/gx4DN15iL8FtgZOS3IO3XmFb1iNfUiSRliqarZjkCRJkiStIfYESpIkSdIIMQmUJEmSpBFiEihJkiRJI8QkUJIkSZJGiEmgJEmSJI0Qk0BJkiRJGiEmgZIkSZI0QkwCJUmSJGmE/P9acLFWyawStQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "train size:   8838\n",
            "(19054, 3)\n",
            "data size:   19054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "test size:   2210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ngv4DYI_jhYn"
      },
      "source": [
        "## Train network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MW3Qdx1USFo6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3345760e-6836-4d29-c513-9c6adc6ddd18"
      },
      "source": [
        "net = Net()\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0001)\r\n",
        "net.cuda()\r\n",
        "train_net(net,dataloader,5000)\r\n",
        "model = net"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  1  loss:  1.3586909684584414  accuracy:  41.14203058272489\n",
            "epoch:  2  loss:  1.2465077403130684  accuracy:  45.61234329797493\n",
            "epoch:  3  loss:  1.1702622357832366  accuracy:  47.713183634109384\n",
            "epoch:  4  loss:  0.9435495349769341  accuracy:  54.621848739495796\n",
            "epoch:  5  loss:  0.877048769237286  accuracy:  57.25306516049042\n",
            "epoch:  6  loss:  0.861417746548811  accuracy:  57.50103320016531\n",
            "epoch:  7  loss:  0.8514818709437587  accuracy:  58.024521283923406\n",
            "epoch:  8  loss:  0.8432077796092324  accuracy:  58.16916930706709\n",
            "epoch:  9  loss:  0.8389280049625811  accuracy:  58.39647334343574\n",
            "epoch:  10  loss:  0.8328808201691191  accuracy:  58.52045736327318\n",
            "epoch:  11  loss:  0.8284293021819433  accuracy:  58.671993387518945\n",
            "epoch:  12  loss:  0.8257928790427351  accuracy:  59.00261744041879\n",
            "epoch:  13  loss:  0.8209235252206164  accuracy:  58.97506543601047\n",
            "epoch:  14  loss:  0.8162739829906075  accuracy:  59.147265463562476\n",
            "epoch:  15  loss:  0.8143805688710757  accuracy:  59.2436974789916\n",
            "epoch:  16  loss:  0.8098641623312949  accuracy:  59.32635349221656\n",
            "epoch:  17  loss:  0.8059587707317866  accuracy:  59.77407356385177\n",
            "epoch:  18  loss:  0.8028829737231166  accuracy:  59.76718556274969\n",
            "epoch:  19  loss:  0.799651717832552  accuracy:  60.60063369610139\n",
            "epoch:  20  loss:  0.7974031337908041  accuracy:  60.276897644303624\n",
            "epoch:  21  loss:  0.7965825849417599  accuracy:  59.960049593607934\n",
            "epoch:  22  loss:  0.7931123193851728  accuracy:  60.36644165863066\n",
            "epoch:  23  loss:  0.7887754633679898  accuracy:  61.32387381181981\n",
            "epoch:  24  loss:  0.7889677868646142  accuracy:  60.82793773247004\n",
            "epoch:  25  loss:  0.7862553396391169  accuracy:  61.07590577214492\n",
            "epoch:  26  loss:  0.7852912537978362  accuracy:  61.082793773247005\n",
            "epoch:  27  loss:  0.7828603557095841  accuracy:  60.83482573357212\n",
            "epoch:  28  loss:  0.7811028031068559  accuracy:  61.0483537677366\n",
            "epoch:  29  loss:  0.7809232774804259  accuracy:  61.1172337787574\n",
            "epoch:  30  loss:  0.779394983506298  accuracy:  61.29632180741149\n",
            "epoch:  31  loss:  0.780403966039218  accuracy:  61.35142581622813\n",
            "epoch:  32  loss:  0.7755565250407633  accuracy:  61.89557790329246\n",
            "epoch:  33  loss:  0.7744720421032499  accuracy:  62.22620195619231\n",
            "epoch:  34  loss:  0.7731927875760404  accuracy:  61.558065849290536\n",
            "epoch:  35  loss:  0.7724320831369772  accuracy:  61.73715387794462\n",
            "epoch:  36  loss:  0.7727834264639899  accuracy:  61.65449786471966\n",
            "epoch:  37  loss:  0.7713880656359692  accuracy:  61.964457914313265\n",
            "epoch:  38  loss:  0.7673582095452159  accuracy:  61.8818019010883\n",
            "epoch:  39  loss:  0.768141566639614  accuracy:  61.92312990770078\n",
            "epoch:  40  loss:  0.7664776886769079  accuracy:  62.019561923129906\n",
            "epoch:  41  loss:  0.7648651954440937  accuracy:  62.191761950681915\n",
            "epoch:  42  loss:  0.7677592753230876  accuracy:  61.84047389447582\n",
            "epoch:  43  loss:  0.763405033167211  accuracy:  62.19864995178399\n",
            "epoch:  44  loss:  0.7642125253063832  accuracy:  62.25375396060063\n",
            "epoch:  45  loss:  0.7600003081767877  accuracy:  62.412177985948475\n",
            "epoch:  46  loss:  0.7601089238348636  accuracy:  62.019561923129906\n",
            "epoch:  47  loss:  0.7626339232384592  accuracy:  61.606281857005094\n",
            "epoch:  48  loss:  0.7596189263832932  accuracy:  62.21242595398815\n",
            "epoch:  49  loss:  0.759102910498414  accuracy:  62.48794599807136\n",
            "epoch:  50  loss:  0.7549664180031459  accuracy:  62.50172200027552\n",
            "epoch:  51  loss:  0.7560075061481212  accuracy:  62.41906598705056\n",
            "epoch:  52  loss:  0.7528681006045984  accuracy:  62.611930017908804\n",
            "epoch:  53  loss:  0.7547001005746327  accuracy:  62.58437801350048\n",
            "epoch:  54  loss:  0.7549157419682928  accuracy:  62.412177985948475\n",
            "epoch:  55  loss:  0.7514286919358776  accuracy:  62.467281994765116\n",
            "epoch:  56  loss:  0.7510883242142301  accuracy:  62.81168204986913\n",
            "epoch:  57  loss:  0.7493379299084597  accuracy:  62.88056206088993\n",
            "epoch:  58  loss:  0.7493676350109832  accuracy:  62.87367405978785\n",
            "epoch:  59  loss:  0.7461498502545949  accuracy:  63.073426091748175\n",
            "epoch:  60  loss:  0.7479601871344912  accuracy:  62.72213803554209\n",
            "epoch:  61  loss:  0.7465046633700559  accuracy:  62.88056206088993\n",
            "epoch:  62  loss:  0.7462250038125426  accuracy:  62.82545805207329\n",
            "epoch:  63  loss:  0.7442607107709666  accuracy:  63.4109381457501\n",
            "epoch:  64  loss:  0.743652192853932  accuracy:  63.479818156770904\n",
            "epoch:  65  loss:  0.7414353288374487  accuracy:  63.404050144648025\n",
            "epoch:  66  loss:  0.7400031302286945  accuracy:  63.562474169995866\n",
            "epoch:  67  loss:  0.7419600140409605  accuracy:  63.06653809064609\n",
            "epoch:  68  loss:  0.7397595038425826  accuracy:  63.63135418101667\n",
            "epoch:  69  loss:  0.7386302109476718  accuracy:  63.059650089544014\n",
            "epoch:  70  loss:  0.7414356741568228  accuracy:  63.376498140239704\n",
            "epoch:  71  loss:  0.7367656967383407  accuracy:  63.34894613583138\n",
            "epoch:  72  loss:  0.7349126911931892  accuracy:  63.50048216007715\n",
            "epoch:  73  loss:  0.7351281442397849  accuracy:  63.55558616889379\n",
            "epoch:  74  loss:  0.7339199723857776  accuracy:  63.90687422509988\n",
            "epoch:  75  loss:  0.7332876099832689  accuracy:  63.88621022179363\n",
            "epoch:  76  loss:  0.7311540153223977  accuracy:  64.16173026587684\n",
            "epoch:  77  loss:  0.7323334738560855  accuracy:  63.92065022730404\n",
            "epoch:  78  loss:  0.7328719019003028  accuracy:  63.507370161179225\n",
            "epoch:  79  loss:  0.7301725527934421  accuracy:  64.16861826697892\n",
            "epoch:  80  loss:  0.7286314194418212  accuracy:  64.06529825044773\n",
            "epoch:  81  loss:  0.727269642008847  accuracy:  64.20305827248933\n",
            "epoch:  82  loss:  0.7273244107700705  accuracy:  64.43036230885797\n",
            "epoch:  83  loss:  0.728636262321262  accuracy:  63.75533820085411\n",
            "epoch:  84  loss:  0.725753437571165  accuracy:  64.15484226477476\n",
            "epoch:  85  loss:  0.7253413677199154  accuracy:  64.26505028240804\n",
            "epoch:  86  loss:  0.7245309772628088  accuracy:  64.77476236396198\n",
            "epoch:  87  loss:  0.7224283103592092  accuracy:  64.03085824493732\n",
            "epoch:  88  loss:  0.7182191228600536  accuracy:  64.7334343573495\n",
            "epoch:  89  loss:  0.7217223431998696  accuracy:  64.34081829453093\n",
            "epoch:  90  loss:  0.7175340884594669  accuracy:  64.60945033751206\n",
            "epoch:  91  loss:  0.7183410021404472  accuracy:  64.48546631767461\n",
            "epoch:  92  loss:  0.7172041274673897  accuracy:  64.84364237498278\n",
            "epoch:  93  loss:  0.7179142807219406  accuracy:  64.8367543738807\n",
            "epoch:  94  loss:  0.7175281715304386  accuracy:  64.54057032649125\n",
            "epoch:  95  loss:  0.7123190059463484  accuracy:  65.22937043669927\n",
            "epoch:  96  loss:  0.713280262738848  accuracy:  64.74032235845158\n",
            "epoch:  97  loss:  0.7116581284403719  accuracy:  64.98140239702438\n",
            "epoch:  98  loss:  0.71115908577252  accuracy:  65.09161041465767\n",
            "epoch:  99  loss:  0.7095329359652074  accuracy:  65.09849841575975\n",
            "epoch:  100  loss:  0.708910954484665  accuracy:  64.94696239151398\n",
            "epoch:  101  loss:  0.7085248824239253  accuracy:  65.3946824631492\n",
            "epoch:  102  loss:  0.7064011202056901  accuracy:  65.24314643890342\n",
            "epoch:  103  loss:  0.706545684723211  accuracy:  65.36024245763879\n",
            "epoch:  104  loss:  0.7069733605468251  accuracy:  65.47045047527207\n",
            "epoch:  105  loss:  0.7055012328284127  accuracy:  65.72530651604905\n",
            "epoch:  106  loss:  0.7039433871029592  accuracy:  65.3533544565367\n",
            "epoch:  107  loss:  0.7027652106726526  accuracy:  65.82862653258024\n",
            "epoch:  108  loss:  0.701786007462725  accuracy:  65.7735225237636\n",
            "epoch:  109  loss:  0.7011139826072381  accuracy:  65.66331450613032\n",
            "epoch:  110  loss:  0.702303414002219  accuracy:  65.71841851494696\n",
            "epoch:  111  loss:  0.7016679453839939  accuracy:  65.52555448408872\n",
            "epoch:  112  loss:  0.6993582420464733  accuracy:  65.47045047527207\n",
            "epoch:  113  loss:  0.6961371014640094  accuracy:  66.39344262295081\n",
            "epoch:  114  loss:  0.696113985117547  accuracy:  65.84929053588648\n",
            "epoch:  115  loss:  0.6946451338974138  accuracy:  66.04904256784681\n",
            "epoch:  116  loss:  0.6953152885186079  accuracy:  66.22124259539882\n",
            "epoch:  117  loss:  0.691183431037843  accuracy:  66.46921063507371\n",
            "epoch:  118  loss:  0.6897082837640558  accuracy:  66.51742664278827\n",
            "epoch:  119  loss:  0.690289315334577  accuracy:  66.6758506681361\n",
            "epoch:  120  loss:  0.688456847346146  accuracy:  66.70340267254443\n",
            "epoch:  121  loss:  0.6883970945478225  accuracy:  66.34522661523626\n",
            "epoch:  122  loss:  0.6884266753255179  accuracy:  66.55186664829867\n",
            "epoch:  123  loss:  0.6890008830961766  accuracy:  66.28323460531753\n",
            "epoch:  124  loss:  0.6871245928680393  accuracy:  66.37966662074666\n",
            "epoch:  125  loss:  0.6836430774623163  accuracy:  66.70340267254443\n",
            "epoch:  126  loss:  0.6839694442754278  accuracy:  66.7447306791569\n",
            "epoch:  127  loss:  0.6813121881345724  accuracy:  66.8204986912798\n",
            "epoch:  128  loss:  0.6822668024865962  accuracy:  66.75161868025899\n",
            "epoch:  129  loss:  0.6787986255559174  accuracy:  67.06846673095468\n",
            "epoch:  130  loss:  0.6808415499743818  accuracy:  66.91693070670891\n",
            "epoch:  131  loss:  0.6772817571656831  accuracy:  67.28199476511917\n",
            "epoch:  132  loss:  0.676547025382839  accuracy:  66.93759471001515\n",
            "epoch:  133  loss:  0.6750580596273507  accuracy:  67.25444276071084\n",
            "epoch:  134  loss:  0.6736079675301587  accuracy:  67.27510676401708\n",
            "epoch:  135  loss:  0.6736073458403296  accuracy:  67.5850668136107\n",
            "epoch:  136  loss:  0.6755039830529045  accuracy:  67.24755475960876\n",
            "epoch:  137  loss:  0.6708946639405317  accuracy:  67.25444276071084\n",
            "epoch:  138  loss:  0.6681185557602818  accuracy:  67.87436285989806\n",
            "epoch:  139  loss:  0.6745380508553179  accuracy:  67.46797079487533\n",
            "epoch:  140  loss:  0.671087811006004  accuracy:  67.19245075079212\n",
            "epoch:  141  loss:  0.6673290045206532  accuracy:  67.59195481471276\n",
            "epoch:  142  loss:  0.6653104704640624  accuracy:  67.7228268356523\n",
            "epoch:  143  loss:  0.6642260525998112  accuracy:  67.87436285989806\n",
            "epoch:  144  loss:  0.6625034962948204  accuracy:  67.88813886210222\n",
            "epoch:  145  loss:  0.6596191099958161  accuracy:  68.17743490838959\n",
            "epoch:  146  loss:  0.6613174689458181  accuracy:  68.07411489185839\n",
            "epoch:  147  loss:  0.6594657036518817  accuracy:  68.05345088855215\n",
            "epoch:  148  loss:  0.6598328061382343  accuracy:  67.92257886761261\n",
            "epoch:  149  loss:  0.660851749962955  accuracy:  68.12233089957294\n",
            "epoch:  150  loss:  0.6573187131201175  accuracy:  68.01212288193966\n",
            "epoch:  151  loss:  0.6556279962508537  accuracy:  68.6251549800248\n",
            "epoch:  152  loss:  0.6535325724036753  accuracy:  68.6940349910456\n",
            "epoch:  153  loss:  0.6543891559144422  accuracy:  68.44606695137071\n",
            "epoch:  154  loss:  0.6515372568524103  accuracy:  68.39096294255407\n",
            "epoch:  155  loss:  0.6535384887456073  accuracy:  67.90880286540846\n",
            "epoch:  156  loss:  0.6477334654878069  accuracy:  69.09353905496624\n",
            "epoch:  157  loss:  0.6510955094962693  accuracy:  68.51494696239152\n",
            "epoch:  158  loss:  0.6512090997568486  accuracy:  68.556274969004\n",
            "epoch:  159  loss:  0.649035453336563  accuracy:  68.90756302521008\n",
            "epoch:  160  loss:  0.6458856222024879  accuracy:  68.56316297010608\n",
            "epoch:  161  loss:  0.6424493586447206  accuracy:  69.07287505166\n",
            "epoch:  162  loss:  0.6396598865307959  accuracy:  69.45171511227441\n",
            "epoch:  163  loss:  0.6396552293995947  accuracy:  69.3552830968453\n",
            "epoch:  164  loss:  0.643570558659251  accuracy:  68.52872296459567\n",
            "epoch:  165  loss:  0.6425774984614944  accuracy:  68.54938696790191\n",
            "epoch:  166  loss:  0.6421952248112297  accuracy:  68.97644303623089\n",
            "epoch:  167  loss:  0.6352573393510875  accuracy:  69.50681912109106\n",
            "epoch:  168  loss:  0.638075262895217  accuracy:  69.18997107039537\n",
            "epoch:  169  loss:  0.6338987211531426  accuracy:  69.61702713872434\n",
            "epoch:  170  loss:  0.6343201581054622  accuracy:  69.7341231574597\n",
            "epoch:  171  loss:  0.6317392611309818  accuracy:  69.70657115305139\n",
            "epoch:  172  loss:  0.6328193718432263  accuracy:  69.39661110345777\n",
            "epoch:  173  loss:  0.631414147628899  accuracy:  69.80989116958258\n",
            "epoch:  174  loss:  0.6303932633975071  accuracy:  69.4586031133765\n",
            "epoch:  175  loss:  0.6273367937922658  accuracy:  70.09229921476788\n",
            "epoch:  176  loss:  0.631633576881723  accuracy:  69.52059512329522\n",
            "epoch:  177  loss:  0.6264142408640625  accuracy:  69.9407631905221\n",
            "epoch:  178  loss:  0.6245408401104648  accuracy:  70.20250723240116\n",
            "epoch:  179  loss:  0.6249857057855385  accuracy:  70.1198512191762\n",
            "epoch:  180  loss:  0.6233644633889938  accuracy:  70.28516324562612\n",
            "epoch:  181  loss:  0.6231797906317516  accuracy:  70.14740322358452\n",
            "epoch:  182  loss:  0.6222095474886129  accuracy:  69.92698718831795\n",
            "epoch:  183  loss:  0.6184661430766685  accuracy:  70.12673922027828\n",
            "epoch:  184  loss:  0.6177966784865982  accuracy:  70.48491527758644\n",
            "epoch:  185  loss:  0.6173434641706432  accuracy:  70.40225926436148\n",
            "epoch:  186  loss:  0.6147415472063944  accuracy:  70.50557928089269\n",
            "epoch:  187  loss:  0.6130227881623195  accuracy:  70.98085135693621\n",
            "epoch:  188  loss:  0.6159436345666971  accuracy:  70.53313128530101\n",
            "epoch:  189  loss:  0.6112238394851148  accuracy:  70.73288331726133\n",
            "epoch:  190  loss:  0.6156517254007242  accuracy:  70.67089130734261\n",
            "epoch:  191  loss:  0.6102235244684827  accuracy:  70.45736327317812\n",
            "epoch:  192  loss:  0.6079455181157758  accuracy:  71.18749138999863\n",
            "epoch:  193  loss:  0.6073412194710524  accuracy:  70.87753134040501\n",
            "epoch:  194  loss:  0.6091264645649983  accuracy:  70.89130734260918\n",
            "epoch:  195  loss:  0.6072044391279986  accuracy:  71.11861137897782\n",
            "epoch:  196  loss:  0.604420798970149  accuracy:  71.15305138448822\n",
            "epoch:  197  loss:  0.6052613852807093  accuracy:  70.8499793359967\n",
            "epoch:  198  loss:  0.6005466208303248  accuracy:  71.58699545391927\n",
            "epoch:  199  loss:  0.6012030086794542  accuracy:  71.35280341644855\n",
            "epoch:  200  loss:  0.6013061139049535  accuracy:  71.2632594021215\n",
            "epoch:  201  loss:  0.6019763929371926  accuracy:  71.58699545391927\n",
            "epoch:  202  loss:  0.5990790849235174  accuracy:  71.1943793911007\n",
            "epoch:  203  loss:  0.6020245689476369  accuracy:  70.87753134040501\n",
            "epoch:  204  loss:  0.5968560302556424  accuracy:  71.45612343297975\n",
            "epoch:  205  loss:  0.596985842036485  accuracy:  71.60077145612344\n",
            "epoch:  206  loss:  0.5937062835936409  accuracy:  71.58699545391927\n",
            "epoch:  207  loss:  0.5939503290146109  accuracy:  71.86251549800248\n",
            "epoch:  208  loss:  0.5921794467679166  accuracy:  71.60765945722551\n",
            "epoch:  209  loss:  0.5913060577402826  accuracy:  71.62832346053176\n",
            "epoch:  210  loss:  0.5908349795493562  accuracy:  71.5456674473068\n",
            "epoch:  211  loss:  0.5871495941418035  accuracy:  72.22069155531065\n",
            "epoch:  212  loss:  0.5880088134193933  accuracy:  71.993387518942\n",
            "epoch:  213  loss:  0.5888708586337432  accuracy:  71.69031547045047\n",
            "epoch:  214  loss:  0.5863075214840358  accuracy:  72.08981953437113\n",
            "epoch:  215  loss:  0.5851258110747158  accuracy:  71.84873949579831\n",
            "epoch:  216  loss:  0.5842652550896824  accuracy:  72.34467557514809\n",
            "epoch:  217  loss:  0.5829065369375647  accuracy:  72.0967075354732\n",
            "epoch:  218  loss:  0.5789477918525424  accuracy:  72.53065160490425\n",
            "epoch:  219  loss:  0.5806733739410554  accuracy:  72.21380355420857\n",
            "epoch:  220  loss:  0.5782196518310355  accuracy:  72.59264361482298\n",
            "epoch:  221  loss:  0.5822949079971929  accuracy:  72.22757955641273\n",
            "epoch:  222  loss:  0.5799928173034837  accuracy:  72.57886761261882\n",
            "epoch:  223  loss:  0.5752109747186543  accuracy:  72.58575561372089\n",
            "epoch:  224  loss:  0.5782467102623459  accuracy:  72.49621159939386\n",
            "epoch:  225  loss:  0.5790504046233007  accuracy:  72.60641961702714\n",
            "epoch:  226  loss:  0.5748384170196227  accuracy:  72.48932359829178\n",
            "epoch:  227  loss:  0.5722633048118122  accuracy:  73.03347568535611\n",
            "epoch:  228  loss:  0.571302292686567  accuracy:  72.9990356798457\n",
            "epoch:  229  loss:  0.5704256363078605  accuracy:  72.68218762915002\n",
            "epoch:  230  loss:  0.5678350936817982  accuracy:  72.88882766221242\n",
            "epoch:  231  loss:  0.5675307639597007  accuracy:  72.92326766772283\n",
            "epoch:  232  loss:  0.5709970424631473  accuracy:  72.92326766772283\n",
            "epoch:  233  loss:  0.567829409214169  accuracy:  72.94393167102906\n",
            "epoch:  234  loss:  0.5627071627335273  accuracy:  73.39853974376636\n",
            "epoch:  235  loss:  0.5637204192783044  accuracy:  73.29521972723515\n",
            "epoch:  236  loss:  0.56482478722115  accuracy:  73.17123570739771\n",
            "epoch:  237  loss:  0.5609044372986164  accuracy:  73.21945171511227\n",
            "epoch:  238  loss:  0.5622360477402841  accuracy:  73.01969968315196\n",
            "epoch:  239  loss:  0.5601297569867747  accuracy:  73.43986775037884\n",
            "epoch:  240  loss:  0.5610038275552167  accuracy:  73.625843780135\n",
            "epoch:  241  loss:  0.558388792794341  accuracy:  73.71538779446205\n",
            "epoch:  242  loss:  0.5575190182600259  accuracy:  73.50874776139965\n",
            "epoch:  243  loss:  0.5569798612926334  accuracy:  73.46053175368507\n",
            "epoch:  244  loss:  0.552621292828167  accuracy:  74.05978784956605\n",
            "epoch:  245  loss:  0.562560379747386  accuracy:  73.14368370298939\n",
            "epoch:  246  loss:  0.553929248950192  accuracy:  73.79804380768701\n",
            "epoch:  247  loss:  0.5583649792032706  accuracy:  73.5225237636038\n",
            "epoch:  248  loss:  0.5507920167797244  accuracy:  73.87381181980989\n",
            "epoch:  249  loss:  0.5526340657611378  accuracy:  73.90825182532029\n",
            "epoch:  250  loss:  0.5505225184634133  accuracy:  73.97024383523902\n",
            "epoch:  251  loss:  0.5489668833156774  accuracy:  74.38352390136383\n",
            "epoch:  252  loss:  0.5470823156249016  accuracy:  74.3215318914451\n",
            "epoch:  253  loss:  0.5458634954162958  accuracy:  74.29397988703678\n",
            "epoch:  254  loss:  0.5482266807723659  accuracy:  74.2526518804243\n",
            "epoch:  255  loss:  0.5515913340051504  accuracy:  73.80493180878909\n",
            "epoch:  256  loss:  0.5436739484778382  accuracy:  74.38352390136383\n",
            "epoch:  257  loss:  0.5453981245610156  accuracy:  74.39729990356798\n",
            "epoch:  258  loss:  0.5433961311874844  accuracy:  74.41796390687422\n",
            "epoch:  259  loss:  0.5423309591613307  accuracy:  74.45240391238463\n",
            "epoch:  260  loss:  0.5404226543128547  accuracy:  74.61082793773247\n",
            "epoch:  261  loss:  0.5406181850386054  accuracy:  74.57638793222208\n",
            "epoch:  262  loss:  0.5390642742584159  accuracy:  74.6039399366304\n",
            "epoch:  263  loss:  0.5418729706890476  accuracy:  74.46617991458879\n",
            "epoch:  264  loss:  0.5339906562095602  accuracy:  74.57638793222208\n",
            "epoch:  265  loss:  0.5392636149436059  accuracy:  74.6039399366304\n",
            "epoch:  266  loss:  0.5340897175567442  accuracy:  74.71414795426367\n",
            "epoch:  267  loss:  0.5290926210823459  accuracy:  75.3960600633696\n",
            "epoch:  268  loss:  0.5364788804875046  accuracy:  74.8105799696928\n",
            "epoch:  269  loss:  0.537473495053529  accuracy:  74.65904394544702\n",
            "epoch:  270  loss:  0.5319452297754862  accuracy:  75.07921201267392\n",
            "epoch:  271  loss:  0.5354032547887092  accuracy:  74.46617991458879\n",
            "epoch:  272  loss:  0.5286819059825137  accuracy:  75.24452403912385\n",
            "epoch:  273  loss:  0.532764890499722  accuracy:  74.63149194103872\n",
            "epoch:  274  loss:  0.5228603065613299  accuracy:  75.25830004132801\n",
            "epoch:  275  loss:  0.5268374032053939  accuracy:  75.2927400468384\n",
            "epoch:  276  loss:  0.5285072818178828  accuracy:  75.37539606006337\n",
            "epoch:  277  loss:  0.5272513920486688  accuracy:  74.97589199614272\n",
            "epoch:  278  loss:  0.5232066225539161  accuracy:  75.38917206226753\n",
            "epoch:  279  loss:  0.5265173464623475  accuracy:  74.97589199614272\n",
            "epoch:  280  loss:  0.5258611690030806  accuracy:  75.086100013776\n",
            "epoch:  281  loss:  0.5275688049328164  accuracy:  75.24452403912385\n",
            "epoch:  282  loss:  0.5203045451751112  accuracy:  75.76801212288194\n",
            "epoch:  283  loss:  0.521692445154508  accuracy:  75.40294806447169\n",
            "epoch:  284  loss:  0.5214598583138864  accuracy:  75.37539606006337\n",
            "epoch:  285  loss:  0.5169553924795846  accuracy:  75.73357211737154\n",
            "epoch:  286  loss:  0.5172879871282224  accuracy:  75.58892409422785\n",
            "epoch:  287  loss:  0.516840302840723  accuracy:  75.43738806998209\n",
            "epoch:  288  loss:  0.5174207655518718  accuracy:  75.56137208981953\n",
            "epoch:  289  loss:  0.5199469236372456  accuracy:  75.35473205675713\n",
            "epoch:  290  loss:  0.5152088851208758  accuracy:  75.84378013500482\n",
            "epoch:  291  loss:  0.5175472931200716  accuracy:  75.16186802589888\n",
            "epoch:  292  loss:  0.5186996126260323  accuracy:  75.73357211737154\n",
            "epoch:  293  loss:  0.5175665803997785  accuracy:  75.36162005785921\n",
            "epoch:  294  loss:  0.5118182171292666  accuracy:  75.71979611516738\n",
            "epoch:  295  loss:  0.5080688663226282  accuracy:  76.18129218900675\n",
            "epoch:  296  loss:  0.5121177161818842  accuracy:  75.6095880975341\n",
            "epoch:  297  loss:  0.5098273512876663  accuracy:  75.91266014602563\n",
            "epoch:  298  loss:  0.5108222323133033  accuracy:  76.09174817467971\n",
            "epoch:  299  loss:  0.506002420970339  accuracy:  76.15374018459843\n",
            "epoch:  300  loss:  0.5091184596784484  accuracy:  76.02975616476098\n",
            "epoch:  301  loss:  0.5027910010317729  accuracy:  76.14685218349635\n",
            "epoch:  302  loss:  0.5051021047335779  accuracy:  76.18129218900675\n",
            "epoch:  303  loss:  0.5058891835135851  accuracy:  76.33282821325251\n",
            "epoch:  304  loss:  0.5034494716522696  accuracy:  76.29150020664004\n",
            "epoch:  305  loss:  0.5023674493913957  accuracy:  76.33282821325251\n",
            "epoch:  306  loss:  0.4981132576552316  accuracy:  76.62212425953989\n",
            "epoch:  307  loss:  0.502381294604454  accuracy:  76.40170822427332\n",
            "epoch:  308  loss:  0.5084862115174914  accuracy:  76.02975616476098\n",
            "epoch:  309  loss:  0.49792509940574115  accuracy:  76.29838820774211\n",
            "epoch:  310  loss:  0.49600529809072996  accuracy:  76.94586031133765\n",
            "epoch:  311  loss:  0.49662317770590614  accuracy:  76.93897231023557\n",
            "epoch:  312  loss:  0.4956845705470429  accuracy:  76.91830830692933\n",
            "epoch:  313  loss:  0.49660676298579626  accuracy:  76.93897231023557\n",
            "epoch:  314  loss:  0.5014624365648137  accuracy:  76.35349221655875\n",
            "epoch:  315  loss:  0.4958647811260084  accuracy:  76.718556274969\n",
            "epoch:  316  loss:  0.49499552804406544  accuracy:  76.718556274969\n",
            "epoch:  317  loss:  0.49544376993757383  accuracy:  76.75299628047941\n",
            "epoch:  318  loss:  0.4920192626836724  accuracy:  76.89075630252101\n",
            "epoch:  319  loss:  0.492827207753277  accuracy:  76.75988428158149\n",
            "epoch:  320  loss:  0.49260654720348307  accuracy:  76.91142030582725\n",
            "epoch:  321  loss:  0.49074649554603533  accuracy:  76.82876429260229\n",
            "epoch:  322  loss:  0.4890569529145492  accuracy:  76.95274831243972\n",
            "epoch:  323  loss:  0.48948132920353876  accuracy:  76.81498829039812\n",
            "epoch:  324  loss:  0.48872751011912824  accuracy:  76.89075630252101\n",
            "epoch:  325  loss:  0.4919081604305025  accuracy:  76.96652431464389\n",
            "epoch:  326  loss:  0.4842546760239439  accuracy:  77.04229232676677\n",
            "epoch:  327  loss:  0.4848294883190494  accuracy:  77.45557239289158\n",
            "epoch:  328  loss:  0.48733154945111434  accuracy:  77.2764843642375\n",
            "epoch:  329  loss:  0.4833868613197449  accuracy:  77.19382835101254\n",
            "epoch:  330  loss:  0.4854128692355066  accuracy:  77.04918032786885\n",
            "epoch:  331  loss:  0.4846590078473173  accuracy:  77.45557239289158\n",
            "epoch:  332  loss:  0.4842353869008368  accuracy:  77.22138035542086\n",
            "epoch:  333  loss:  0.48477073581787916  accuracy:  77.28337236533957\n",
            "epoch:  334  loss:  0.4812307975265602  accuracy:  77.40735638517702\n",
            "epoch:  335  loss:  0.4800435410113781  accuracy:  77.47623639619782\n",
            "epoch:  336  loss:  0.4885351987955146  accuracy:  76.9251963080314\n",
            "epoch:  337  loss:  0.4760314721569474  accuracy:  78.13748450199752\n",
            "epoch:  338  loss:  0.4798683798424812  accuracy:  77.52445240391239\n",
            "epoch:  339  loss:  0.4779086109609508  accuracy:  77.42113238738118\n",
            "epoch:  340  loss:  0.4789834861494914  accuracy:  77.73109243697479\n",
            "epoch:  341  loss:  0.4736413977324823  accuracy:  77.91018046562887\n",
            "epoch:  342  loss:  0.47483193345561897  accuracy:  77.88262846122055\n",
            "epoch:  343  loss:  0.4771203060528844  accuracy:  77.51756440281031\n",
            "epoch:  344  loss:  0.4711260158162683  accuracy:  77.80686044909767\n",
            "epoch:  345  loss:  0.4773959202992389  accuracy:  77.68287642926023\n",
            "epoch:  346  loss:  0.46958792148041717  accuracy:  78.19947651191625\n",
            "epoch:  347  loss:  0.4709322470938113  accuracy:  78.0410524865684\n",
            "epoch:  348  loss:  0.47198653588989314  accuracy:  77.89640446342472\n",
            "epoch:  349  loss:  0.46812352471188057  accuracy:  78.06860449097672\n",
            "epoch:  350  loss:  0.47177149576496397  accuracy:  77.96528447444551\n",
            "epoch:  351  loss:  0.4688871133046663  accuracy:  78.25458052073289\n",
            "epoch:  352  loss:  0.47983442383834624  accuracy:  77.64843642374983\n",
            "epoch:  353  loss:  0.46954598389786617  accuracy:  77.81374845019975\n",
            "epoch:  354  loss:  0.4677028424574958  accuracy:  78.22702851632457\n",
            "epoch:  355  loss:  0.4651603752923974  accuracy:  78.18570050971208\n",
            "epoch:  356  loss:  0.4668516372785307  accuracy:  78.46122055379529\n",
            "epoch:  357  loss:  0.46843991521502154  accuracy:  78.22014051522248\n",
            "epoch:  358  loss:  0.4683112597018829  accuracy:  77.88951646232263\n",
            "epoch:  359  loss:  0.467469238084544  accuracy:  77.95839647334344\n",
            "epoch:  360  loss:  0.4596878516557444  accuracy:  78.58520457363274\n",
            "epoch:  361  loss:  0.458249744710917  accuracy:  78.86761261881801\n",
            "epoch:  362  loss:  0.45882275501449077  accuracy:  78.59898057583689\n",
            "epoch:  363  loss:  0.4639043317039507  accuracy:  78.61275657804106\n",
            "epoch:  364  loss:  0.45762244281172343  accuracy:  78.95715663314506\n",
            "epoch:  365  loss:  0.4623353363380795  accuracy:  78.57142857142857\n",
            "epoch:  366  loss:  0.45825677035695384  accuracy:  78.55076456812233\n",
            "epoch:  367  loss:  0.46008665043306934  accuracy:  78.4887725582036\n",
            "epoch:  368  loss:  0.4609567659020112  accuracy:  78.37856454057032\n",
            "epoch:  369  loss:  0.45429460872039107  accuracy:  78.64719658355145\n",
            "epoch:  370  loss:  0.45742993839090235  accuracy:  78.39234054277449\n",
            "epoch:  371  loss:  0.4534129645972561  accuracy:  78.88138862102218\n",
            "epoch:  372  loss:  0.45802492251867827  accuracy:  78.5920925747348\n",
            "epoch:  373  loss:  0.44977977835355276  accuracy:  79.41865270698443\n",
            "epoch:  374  loss:  0.4587517252702788  accuracy:  78.57142857142857\n",
            "epoch:  375  loss:  0.4533750221763437  accuracy:  78.78495660559305\n",
            "epoch:  376  loss:  0.4527953848076484  accuracy:  79.15690866510539\n",
            "epoch:  377  loss:  0.4480582706025685  accuracy:  79.08802865408458\n",
            "epoch:  378  loss:  0.45235742106961885  accuracy:  78.86761261881801\n",
            "epoch:  379  loss:  0.4517181156825914  accuracy:  79.08802865408458\n",
            "epoch:  380  loss:  0.4463121559702343  accuracy:  79.3979887036782\n",
            "epoch:  381  loss:  0.4450557368988011  accuracy:  79.40487670478028\n",
            "epoch:  382  loss:  0.4546284704870849  accuracy:  78.4887725582036\n",
            "epoch:  383  loss:  0.4587609098870361  accuracy:  78.4887725582036\n",
            "epoch:  384  loss:  0.44676859559213383  accuracy:  79.22578867612619\n",
            "epoch:  385  loss:  0.4429461670399763  accuracy:  79.81815677090508\n",
            "epoch:  386  loss:  0.44125301469815864  accuracy:  79.48753271800524\n",
            "epoch:  387  loss:  0.4430832016573151  accuracy:  79.32910869265739\n",
            "epoch:  388  loss:  0.4424754703015331  accuracy:  79.58396473343436\n",
            "epoch:  389  loss:  0.44165692992538175  accuracy:  79.34977269596364\n",
            "epoch:  390  loss:  0.44472746883382613  accuracy:  78.99159663865547\n",
            "epoch:  391  loss:  0.4470520709800497  accuracy:  79.02603664416586\n",
            "epoch:  392  loss:  0.44359134017132024  accuracy:  79.45998071359692\n",
            "epoch:  393  loss:  0.4383676230480461  accuracy:  79.59085273453644\n",
            "epoch:  394  loss:  0.4406720410736324  accuracy:  79.34977269596364\n",
            "epoch:  395  loss:  0.4360139132375345  accuracy:  80.01102080176332\n",
            "epoch:  396  loss:  0.44742176286493357  accuracy:  79.10869265739082\n",
            "epoch:  397  loss:  0.44241884605321924  accuracy:  78.93649262983882\n",
            "epoch:  398  loss:  0.44242952841013683  accuracy:  79.46686871469899\n",
            "epoch:  399  loss:  0.43749106002996935  accuracy:  79.52197272351563\n",
            "epoch:  400  loss:  0.43984000411288504  accuracy:  79.73550075768011\n",
            "epoch:  401  loss:  0.4456436829817231  accuracy:  79.08802865408458\n",
            "epoch:  402  loss:  0.4332683801831646  accuracy:  80.03857280617164\n",
            "epoch:  403  loss:  0.43404287474676667  accuracy:  79.76994076319052\n",
            "epoch:  404  loss:  0.43151540931697585  accuracy:  80.22454883592782\n",
            "epoch:  405  loss:  0.4376735177713742  accuracy:  79.56330073012812\n",
            "epoch:  406  loss:  0.4337124490248531  accuracy:  79.45998071359692\n",
            "epoch:  407  loss:  0.43593346813129386  accuracy:  79.94902879184461\n",
            "epoch:  408  loss:  0.4311357571461556  accuracy:  79.73550075768011\n",
            "epoch:  409  loss:  0.43690067851144365  accuracy:  79.61151673784268\n",
            "epoch:  410  loss:  0.4376111163927481  accuracy:  79.66662074665932\n",
            "epoch:  411  loss:  0.4370262447032805  accuracy:  79.65284474445517\n",
            "epoch:  412  loss:  0.4302758469547446  accuracy:  79.81815677090508\n",
            "epoch:  413  loss:  0.4330924249767748  accuracy:  79.83882077421133\n",
            "epoch:  414  loss:  0.4316596687127447  accuracy:  79.94902879184461\n",
            "epoch:  415  loss:  0.42457088504568047  accuracy:  80.41741286678607\n",
            "epoch:  416  loss:  0.4285466481887501  accuracy:  80.01102080176332\n",
            "epoch:  417  loss:  0.4352460352000594  accuracy:  79.39110070257611\n",
            "epoch:  418  loss:  0.4259353587861921  accuracy:  80.28654084584653\n",
            "epoch:  419  loss:  0.42679153678173826  accuracy:  80.02479680396749\n",
            "epoch:  420  loss:  0.42447533329043247  accuracy:  80.50006888001101\n",
            "epoch:  421  loss:  0.42406217797200924  accuracy:  80.51384488221518\n",
            "epoch:  422  loss:  0.4222089813906458  accuracy:  80.47940487670478\n",
            "epoch:  423  loss:  0.4279246264448966  accuracy:  80.21077283372365\n",
            "epoch:  424  loss:  0.4299663585364482  accuracy:  79.94214079074253\n",
            "epoch:  425  loss:  0.4202900648338766  accuracy:  80.56206088992974\n",
            "epoch:  426  loss:  0.4303498966443603  accuracy:  79.96969279515085\n",
            "epoch:  427  loss:  0.42523730124286224  accuracy:  80.16944482711118\n",
            "epoch:  428  loss:  0.42227568809430055  accuracy:  80.35542085686734\n",
            "epoch:  429  loss:  0.41695364550595637  accuracy:  80.8238049318088\n",
            "epoch:  430  loss:  0.41556581861389164  accuracy:  80.80314092850254\n",
            "epoch:  431  loss:  0.42004317332601593  accuracy:  80.6102768976443\n",
            "epoch:  432  loss:  0.4132935535868332  accuracy:  81.09243697478992\n",
            "epoch:  433  loss:  0.4173545949935979  accuracy:  80.90646094503376\n",
            "epoch:  434  loss:  0.41556744313811544  accuracy:  80.74114891858383\n",
            "epoch:  435  loss:  0.41572240678990474  accuracy:  80.63782890205262\n",
            "epoch:  436  loss:  0.4159950898778818  accuracy:  80.55517288882766\n",
            "epoch:  437  loss:  0.4138165491723311  accuracy:  80.98222895715664\n",
            "epoch:  438  loss:  0.41540054030811874  accuracy:  80.75492492078799\n",
            "epoch:  439  loss:  0.415723625503307  accuracy:  80.52073288331727\n",
            "epoch:  440  loss:  0.422054058921815  accuracy:  80.52762088441933\n",
            "epoch:  441  loss:  0.4151649689942061  accuracy:  80.78936492629839\n",
            "epoch:  442  loss:  0.4146123704527311  accuracy:  80.96845295495247\n",
            "epoch:  443  loss:  0.40841038739209923  accuracy:  81.3404050144648\n",
            "epoch:  444  loss:  0.4162192804530265  accuracy:  80.6447169031547\n",
            "epoch:  445  loss:  0.4172817715387861  accuracy:  80.6791569086651\n",
            "epoch:  446  loss:  0.409566163528161  accuracy:  81.27841300454608\n",
            "epoch:  447  loss:  0.4102460882653545  accuracy:  81.21642099462736\n",
            "epoch:  448  loss:  0.4108542663213684  accuracy:  81.20953299352527\n",
            "epoch:  449  loss:  0.41110386919804487  accuracy:  80.9615649538504\n",
            "epoch:  450  loss:  0.4096241668985474  accuracy:  81.07177297148368\n",
            "epoch:  451  loss:  0.4036591444228664  accuracy:  81.66414106626257\n",
            "epoch:  452  loss:  0.4102228672515264  accuracy:  81.05110896817743\n",
            "epoch:  453  loss:  0.4076604278911357  accuracy:  80.90646094503376\n",
            "epoch:  454  loss:  0.4046327401692093  accuracy:  81.36106901777104\n",
            "epoch:  455  loss:  0.4086971552489562  accuracy:  81.07866097258575\n",
            "epoch:  456  loss:  0.4119516209081967  accuracy:  80.58961289433806\n",
            "epoch:  457  loss:  0.4060328887142513  accuracy:  81.40239702438352\n",
            "epoch:  458  loss:  0.4003741604095485  accuracy:  81.62970106075217\n",
            "epoch:  459  loss:  0.4068395970757465  accuracy:  81.42306102768977\n",
            "epoch:  460  loss:  0.4041050782724589  accuracy:  81.2026449924232\n",
            "epoch:  461  loss:  0.40702037597625507  accuracy:  81.47127703540433\n",
            "epoch:  462  loss:  0.4030989259625125  accuracy:  81.17509298801488\n",
            "epoch:  463  loss:  0.40434679794630113  accuracy:  81.33351701336272\n",
            "epoch:  464  loss:  0.4013307503242272  accuracy:  81.53326904532305\n",
            "epoch:  465  loss:  0.40353657342396027  accuracy:  81.49194103871056\n",
            "epoch:  466  loss:  0.40188615801479227  accuracy:  81.45061303209809\n",
            "epoch:  467  loss:  0.3980298577170839  accuracy:  81.73302107728337\n",
            "epoch:  468  loss:  0.39989385365996416  accuracy:  81.48505303760848\n",
            "epoch:  469  loss:  0.3990578182531234  accuracy:  81.56082104973137\n",
            "epoch:  470  loss:  0.3980966504344534  accuracy:  81.73990907838545\n",
            "epoch:  471  loss:  0.3954268631314029  accuracy:  81.76057308169169\n",
            "epoch:  472  loss:  0.3962888934918057  accuracy:  81.49882903981265\n",
            "epoch:  473  loss:  0.4034495993017871  accuracy:  81.22330899572944\n",
            "epoch:  474  loss:  0.3973556963031754  accuracy:  81.67791706846673\n",
            "epoch:  475  loss:  0.39862345196619753  accuracy:  81.62281305965008\n",
            "epoch:  476  loss:  0.3982379818310799  accuracy:  81.56770905083344\n",
            "epoch:  477  loss:  0.3997394239004198  accuracy:  81.5126050420168\n",
            "epoch:  478  loss:  0.39723892994189103  accuracy:  81.71235707397713\n",
            "epoch:  479  loss:  0.3894589355430716  accuracy:  82.15318914451026\n",
            "epoch:  480  loss:  0.390253341071516  accuracy:  82.1738531478165\n",
            "epoch:  481  loss:  0.3937708484287317  accuracy:  81.76746108279377\n",
            "epoch:  482  loss:  0.3956171101587077  accuracy:  81.70546907287505\n",
            "epoch:  483  loss:  0.392661547526165  accuracy:  81.73302107728337\n",
            "epoch:  484  loss:  0.39409770466667476  accuracy:  81.60214905634385\n",
            "epoch:  485  loss:  0.3891798643669095  accuracy:  82.11874913899986\n",
            "epoch:  486  loss:  0.39661498363886116  accuracy:  81.76057308169169\n",
            "epoch:  487  loss:  0.3897228977321051  accuracy:  81.71924507507921\n",
            "epoch:  488  loss:  0.3878188871749424  accuracy:  82.28406116544978\n",
            "epoch:  489  loss:  0.39014307520067354  accuracy:  81.91899710703953\n",
            "epoch:  490  loss:  0.38837987230712184  accuracy:  82.07742113238739\n",
            "epoch:  491  loss:  0.3918615248614163  accuracy:  81.80190108830418\n",
            "epoch:  492  loss:  0.3870383848630293  accuracy:  82.34605317536851\n",
            "epoch:  493  loss:  0.3848553156085802  accuracy:  82.15318914451026\n",
            "epoch:  494  loss:  0.3871840619855322  accuracy:  82.2082931533269\n",
            "epoch:  495  loss:  0.38785871916737563  accuracy:  82.24273315883731\n",
            "epoch:  496  loss:  0.388729267227763  accuracy:  82.47003719520595\n",
            "epoch:  497  loss:  0.38709327833910984  accuracy:  82.09119713459154\n",
            "epoch:  498  loss:  0.385818253327605  accuracy:  82.2771731643477\n",
            "epoch:  499  loss:  0.38231264502487494  accuracy:  82.56646921063508\n",
            "epoch:  500  loss:  0.38726163912220163  accuracy:  81.78812508610001\n",
            "epoch:  501  loss:  0.3831131491085964  accuracy:  82.44248519079763\n",
            "epoch:  502  loss:  0.39206175629897855  accuracy:  81.83634109381458\n",
            "epoch:  503  loss:  0.38097742579662863  accuracy:  82.5940212150434\n",
            "epoch:  504  loss:  0.3826206312607858  accuracy:  82.37360517977683\n",
            "epoch:  505  loss:  0.3893839411210679  accuracy:  82.07742113238739\n",
            "epoch:  506  loss:  0.38201007578701074  accuracy:  82.42870918859347\n",
            "epoch:  507  loss:  0.37863557319254204  accuracy:  82.51825320292052\n",
            "epoch:  508  loss:  0.37897904946597455  accuracy:  82.75933324149332\n",
            "epoch:  509  loss:  0.38294072141084384  accuracy:  82.2082931533269\n",
            "epoch:  510  loss:  0.3784906974872917  accuracy:  82.62846122055379\n",
            "epoch:  511  loss:  0.38222647657127057  accuracy:  82.58024521283923\n",
            "epoch:  512  loss:  0.3809776233278501  accuracy:  82.60090921614548\n",
            "epoch:  513  loss:  0.37440875066075546  accuracy:  82.8695412591266\n",
            "epoch:  514  loss:  0.3801736518040655  accuracy:  82.60779721724755\n",
            "epoch:  515  loss:  0.3777267908176323  accuracy:  82.62157321945172\n",
            "epoch:  516  loss:  0.3742780195055692  accuracy:  82.91775726684116\n",
            "epoch:  517  loss:  0.3815417574372957  accuracy:  82.3116131698581\n",
            "epoch:  518  loss:  0.3754900728113347  accuracy:  82.81443725030996\n",
            "epoch:  519  loss:  0.3779010871300308  accuracy:  82.55269320843091\n",
            "epoch:  520  loss:  0.36845955964552995  accuracy:  83.00730128116821\n",
            "epoch:  521  loss:  0.37535353650533065  accuracy:  82.44937319189971\n",
            "epoch:  522  loss:  0.3724592763426087  accuracy:  83.11062129769941\n",
            "epoch:  523  loss:  0.3806334545907443  accuracy:  82.54580520732884\n",
            "epoch:  524  loss:  0.3794899804029834  accuracy:  82.58024521283923\n",
            "epoch:  525  loss:  0.37071593355001015  accuracy:  83.01418928227028\n",
            "epoch:  526  loss:  0.3710392781391274  accuracy:  82.74555723928916\n",
            "epoch:  527  loss:  0.3749536151136474  accuracy:  82.61468521834963\n",
            "epoch:  528  loss:  0.3669587745862257  accuracy:  83.03485328557653\n",
            "epoch:  529  loss:  0.37523422145222746  accuracy:  82.66978922716628\n",
            "epoch:  530  loss:  0.372058652420398  accuracy:  82.8351012536162\n",
            "epoch:  531  loss:  0.3657052676931264  accuracy:  83.10373329659733\n",
            "epoch:  532  loss:  0.3711632179859207  accuracy:  83.06929329108692\n",
            "epoch:  533  loss:  0.3732634804489068  accuracy:  82.559581209533\n",
            "epoch:  534  loss:  0.369593874127071  accuracy:  83.03485328557653\n",
            "epoch:  535  loss:  0.3718207848599207  accuracy:  83.15194930431188\n",
            "epoch:  536  loss:  0.3789970316942245  accuracy:  82.40804518528724\n",
            "epoch:  537  loss:  0.38172038284596504  accuracy:  82.38049318087891\n",
            "epoch:  538  loss:  0.3695248147191251  accuracy:  83.12439729990356\n",
            "epoch:  539  loss:  0.37159834654555535  accuracy:  82.8695412591266\n",
            "epoch:  540  loss:  0.3770937910214947  accuracy:  82.56646921063508\n",
            "epoch:  541  loss:  0.3734708833232992  accuracy:  82.94530927124949\n",
            "epoch:  542  loss:  0.36937257468511553  accuracy:  83.2208293153327\n",
            "epoch:  543  loss:  0.36231686349150927  accuracy:  83.54456536713046\n",
            "epoch:  544  loss:  0.36611995221268195  accuracy:  83.33792533406805\n",
            "epoch:  545  loss:  0.3648424811095701  accuracy:  83.19327731092437\n",
            "epoch:  546  loss:  0.3631858985102822  accuracy:  83.30348532855766\n",
            "epoch:  547  loss:  0.3632475459546093  accuracy:  83.75809340129494\n",
            "epoch:  548  loss:  0.3619275287703092  accuracy:  83.3585893373743\n",
            "epoch:  549  loss:  0.3672942326800983  accuracy:  83.06929329108692\n",
            "epoch:  550  loss:  0.3607750470902838  accuracy:  83.60655737704919\n",
            "epoch:  551  loss:  0.36058537822967557  accuracy:  83.16572530651605\n",
            "epoch:  552  loss:  0.3695801178570506  accuracy:  82.81443725030996\n",
            "epoch:  553  loss:  0.36663163230921353  accuracy:  83.13817330210773\n",
            "epoch:  554  loss:  0.3545684325110405  accuracy:  83.97162143545943\n",
            "epoch:  555  loss:  0.37215658318226225  accuracy:  82.49758919961427\n",
            "epoch:  556  loss:  0.3578880367273798  accuracy:  83.68921339027415\n",
            "epoch:  557  loss:  0.36307420091682235  accuracy:  83.36547733847637\n",
            "epoch:  558  loss:  0.3588253230037136  accuracy:  83.59278137484502\n",
            "epoch:  559  loss:  0.35569330627045564  accuracy:  83.62722138035542\n",
            "epoch:  560  loss:  0.36063150778455927  accuracy:  83.57211737153878\n",
            "epoch:  561  loss:  0.35579158279920087  accuracy:  83.91651742664278\n",
            "epoch:  562  loss:  0.3580080166465242  accuracy:  83.58589337374293\n",
            "epoch:  563  loss:  0.3560536961090566  accuracy:  83.50323736051797\n",
            "epoch:  564  loss:  0.3611309736975298  accuracy:  83.48946135831382\n",
            "epoch:  565  loss:  0.36020012550699526  accuracy:  83.46879735500758\n",
            "epoch:  566  loss:  0.3559682493610378  accuracy:  83.89585342333655\n",
            "epoch:  567  loss:  0.36006911873472575  accuracy:  83.41369334619094\n",
            "epoch:  568  loss:  0.3531504939645755  accuracy:  83.91651742664278\n",
            "epoch:  569  loss:  0.3570286058077291  accuracy:  83.48946135831382\n",
            "epoch:  570  loss:  0.3553766682384789  accuracy:  83.70987739358038\n",
            "epoch:  571  loss:  0.3564823789424288  accuracy:  83.8407494145199\n",
            "epoch:  572  loss:  0.3602767799910246  accuracy:  83.18638930982229\n",
            "epoch:  573  loss:  0.35899121196149447  accuracy:  83.48946135831382\n",
            "epoch:  574  loss:  0.3492889226895256  accuracy:  83.95784543325527\n",
            "epoch:  575  loss:  0.3523669441506823  accuracy:  83.57211737153878\n",
            "epoch:  576  loss:  0.3514976547447212  accuracy:  83.90274142443863\n",
            "epoch:  577  loss:  0.3511954915270626  accuracy:  83.9853974376636\n",
            "epoch:  578  loss:  0.3548147726246174  accuracy:  83.62722138035542\n",
            "epoch:  579  loss:  0.3541094886934746  accuracy:  83.70987739358038\n",
            "epoch:  580  loss:  0.3529317784935897  accuracy:  83.7374293979887\n",
            "epoch:  581  loss:  0.3523107683146225  accuracy:  83.91651742664278\n",
            "epoch:  582  loss:  0.34549672015853977  accuracy:  84.35046149607383\n",
            "epoch:  583  loss:  0.3500127469578596  accuracy:  84.04738944758232\n",
            "epoch:  584  loss:  0.3546422310342866  accuracy:  83.67543738806998\n",
            "epoch:  585  loss:  0.3552934056262632  accuracy:  83.79253340680535\n",
            "epoch:  586  loss:  0.34498538873152623  accuracy:  84.29535748725719\n",
            "epoch:  587  loss:  0.3507901183364805  accuracy:  84.14382146301143\n",
            "epoch:  588  loss:  0.34391366747977864  accuracy:  84.35734949717592\n",
            "epoch:  589  loss:  0.350574330228274  accuracy:  83.9853974376636\n",
            "epoch:  590  loss:  0.35036652048998157  accuracy:  83.81319741011158\n",
            "epoch:  591  loss:  0.34612921936885765  accuracy:  84.07494145199063\n",
            "epoch:  592  loss:  0.3497560740436859  accuracy:  84.06116544978647\n",
            "epoch:  593  loss:  0.34764834845348536  accuracy:  84.04050144648023\n",
            "epoch:  594  loss:  0.3517373452741329  accuracy:  84.019837443174\n",
            "epoch:  595  loss:  0.34292451613639763  accuracy:  84.42622950819673\n",
            "epoch:  596  loss:  0.3468454544874965  accuracy:  84.02672544427607\n",
            "epoch:  597  loss:  0.3406137260138159  accuracy:  84.53643752583001\n",
            "epoch:  598  loss:  0.34392573433501084  accuracy:  84.364237498278\n",
            "epoch:  599  loss:  0.34517087579340067  accuracy:  84.56398953023833\n",
            "epoch:  600  loss:  0.3376664185137242  accuracy:  84.89461358313817\n",
            "epoch:  601  loss:  0.3477633302411128  accuracy:  84.10249345639895\n",
            "epoch:  602  loss:  0.34412872781847476  accuracy:  84.20581347293016\n",
            "epoch:  603  loss:  0.3493194057500827  accuracy:  84.04738944758232\n",
            "epoch:  604  loss:  0.34529802193119763  accuracy:  84.09560545529688\n",
            "epoch:  605  loss:  0.34465273214833336  accuracy:  84.48133351701337\n",
            "epoch:  606  loss:  0.34224516394948284  accuracy:  84.27469348395095\n",
            "epoch:  607  loss:  0.33663640287169116  accuracy:  84.68108554897368\n",
            "epoch:  608  loss:  0.3396685523941819  accuracy:  84.5708775313404\n",
            "epoch:  609  loss:  0.33870124126337897  accuracy:  84.84639757542361\n",
            "epoch:  610  loss:  0.33933444333266977  accuracy:  84.49510951921752\n",
            "epoch:  611  loss:  0.3396704551897392  accuracy:  84.44689351150296\n",
            "epoch:  612  loss:  0.3343843957218097  accuracy:  84.97038159526106\n",
            "epoch:  613  loss:  0.34234796488460784  accuracy:  84.55710152913625\n",
            "epoch:  614  loss:  0.3355381068184547  accuracy:  84.68797355007577\n",
            "epoch:  615  loss:  0.34384512594825456  accuracy:  83.95095743215319\n",
            "epoch:  616  loss:  0.3416428663157812  accuracy:  84.21958947513431\n",
            "epoch:  617  loss:  0.3364596075653816  accuracy:  84.77062956330073\n",
            "epoch:  618  loss:  0.33980764944595415  accuracy:  84.47444551591128\n",
            "epoch:  619  loss:  0.33617539442731814  accuracy:  84.8119575699132\n",
            "epoch:  620  loss:  0.332989022655089  accuracy:  84.75685356109658\n",
            "epoch:  621  loss:  0.338635412478089  accuracy:  84.4331175092988\n",
            "epoch:  622  loss:  0.33598828325998786  accuracy:  84.78440556550488\n",
            "epoch:  623  loss:  0.332026849483258  accuracy:  84.8877255820361\n",
            "epoch:  624  loss:  0.3291421246862819  accuracy:  85.05303760848602\n",
            "epoch:  625  loss:  0.33186234587775  accuracy:  84.48133351701337\n",
            "epoch:  626  loss:  0.33391767619751195  accuracy:  84.80506956881113\n",
            "epoch:  627  loss:  0.3380746702108194  accuracy:  84.708637553382\n",
            "epoch:  628  loss:  0.3308718284967435  accuracy:  84.90838958534233\n",
            "epoch:  629  loss:  0.3338640082151802  accuracy:  84.59842953574872\n",
            "epoch:  630  loss:  0.34355796358936463  accuracy:  84.17826146852184\n",
            "epoch:  631  loss:  0.332743004822488  accuracy:  84.5019975203196\n",
            "epoch:  632  loss:  0.335481890345477  accuracy:  84.75685356109658\n",
            "epoch:  633  loss:  0.3336627384136327  accuracy:  84.8119575699132\n",
            "epoch:  634  loss:  0.32837431703672737  accuracy:  84.97038159526106\n",
            "epoch:  635  loss:  0.3285614054838411  accuracy:  84.93594158975066\n",
            "epoch:  636  loss:  0.3302487924721701  accuracy:  84.89461358313817\n",
            "epoch:  637  loss:  0.32533278135717003  accuracy:  85.20457363273178\n",
            "epoch:  638  loss:  0.3368795855423195  accuracy:  84.5708775313404\n",
            "epoch:  639  loss:  0.33649500611236  accuracy:  84.76374156219865\n",
            "epoch:  640  loss:  0.33454497563952273  accuracy:  84.58465353354457\n",
            "epoch:  641  loss:  0.33179579260329894  accuracy:  84.78440556550488\n",
            "epoch:  642  loss:  0.33158642764893886  accuracy:  84.86017357762778\n",
            "epoch:  643  loss:  0.328504284880496  accuracy:  85.05992560958809\n",
            "epoch:  644  loss:  0.3299070312137987  accuracy:  84.88083758093401\n",
            "epoch:  645  loss:  0.33448699790635933  accuracy:  84.66042154566745\n",
            "epoch:  646  loss:  0.32163095589199087  accuracy:  85.27345364375259\n",
            "epoch:  647  loss:  0.32198253916074854  accuracy:  85.30100564816091\n",
            "epoch:  648  loss:  0.32884939845878736  accuracy:  84.87394957983193\n",
            "epoch:  649  loss:  0.32387268408991315  accuracy:  85.11502961840473\n",
            "epoch:  650  loss:  0.3265239122584267  accuracy:  84.79129356660697\n",
            "epoch:  651  loss:  0.32583073349157665  accuracy:  85.07370161179226\n",
            "epoch:  652  loss:  0.32999013811000893  accuracy:  84.8877255820361\n",
            "epoch:  653  loss:  0.32856450718137936  accuracy:  84.8877255820361\n",
            "epoch:  654  loss:  0.32488393245534575  accuracy:  85.24590163934427\n",
            "epoch:  655  loss:  0.3278742183694204  accuracy:  84.73618955779033\n",
            "epoch:  656  loss:  0.32980065240292106  accuracy:  85.21146163383386\n",
            "epoch:  657  loss:  0.32236210396506926  accuracy:  85.28034164485466\n",
            "epoch:  658  loss:  0.3216284986825041  accuracy:  85.1288056206089\n",
            "epoch:  659  loss:  0.32351762333887146  accuracy:  85.11502961840473\n",
            "epoch:  660  loss:  0.3224908995027302  accuracy:  85.2665656426505\n",
            "epoch:  661  loss:  0.3239545354047152  accuracy:  85.08747761399641\n",
            "epoch:  662  loss:  0.31955384605227133  accuracy:  85.44565367130458\n",
            "epoch:  663  loss:  0.31951718700541365  accuracy:  85.70739771318364\n",
            "epoch:  664  loss:  0.3217909701444637  accuracy:  85.31478165036506\n",
            "epoch:  665  loss:  0.3217255854728974  accuracy:  85.39054966248794\n",
            "epoch:  666  loss:  0.317346140865469  accuracy:  85.50764568122331\n",
            "epoch:  667  loss:  0.32024971580789474  accuracy:  85.56963769114203\n",
            "epoch:  668  loss:  0.3190493719142435  accuracy:  85.45942967350875\n",
            "epoch:  669  loss:  0.32218364037943864  accuracy:  85.28722964595674\n",
            "epoch:  670  loss:  0.32034587531661934  accuracy:  85.67984570877532\n",
            "epoch:  671  loss:  0.32016473779058896  accuracy:  85.39054966248794\n",
            "epoch:  672  loss:  0.32018705966847383  accuracy:  85.54208568673371\n",
            "epoch:  673  loss:  0.31644892244648387  accuracy:  85.58341369334619\n",
            "epoch:  674  loss:  0.324009571569832  accuracy:  85.3698856591817\n",
            "epoch:  675  loss:  0.3201536908407056  accuracy:  85.4112136657942\n",
            "epoch:  676  loss:  0.31640685903851956  accuracy:  85.46631767461083\n",
            "epoch:  677  loss:  0.31546506729684665  accuracy:  85.68673370987739\n",
            "epoch:  678  loss:  0.32575185169142656  accuracy:  85.07370161179226\n",
            "epoch:  679  loss:  0.31770094302727314  accuracy:  85.74872571979611\n",
            "epoch:  680  loss:  0.31600798144454156  accuracy:  85.54208568673371\n",
            "epoch:  681  loss:  0.3139886295443183  accuracy:  85.67295770767323\n",
            "epoch:  682  loss:  0.3164459686192095  accuracy:  85.52830968452955\n",
            "epoch:  683  loss:  0.317369305665852  accuracy:  85.1976856316297\n",
            "epoch:  684  loss:  0.31403631661438813  accuracy:  85.70050971208155\n",
            "epoch:  685  loss:  0.3148064532708918  accuracy:  85.67295770767323\n",
            "epoch:  686  loss:  0.31338637792582946  accuracy:  85.74183771869403\n",
            "epoch:  687  loss:  0.31869055313920497  accuracy:  85.39743766359003\n",
            "epoch:  688  loss:  0.3159204410679791  accuracy:  85.83138173302108\n",
            "epoch:  689  loss:  0.3191886462978398  accuracy:  85.52830968452955\n",
            "epoch:  690  loss:  0.31289478015646754  accuracy:  85.71428571428571\n",
            "epoch:  691  loss:  0.31457386646722035  accuracy:  85.70739771318364\n",
            "epoch:  692  loss:  0.3095758547774194  accuracy:  85.94847775175644\n",
            "epoch:  693  loss:  0.30857054773425086  accuracy:  86.1000137760022\n",
            "epoch:  694  loss:  0.3149783196491485  accuracy:  85.58341369334619\n",
            "epoch:  695  loss:  0.30665107630167576  accuracy:  86.11378977820637\n",
            "epoch:  696  loss:  0.30824814511036835  accuracy:  85.98980575836892\n",
            "epoch:  697  loss:  0.31072168420466006  accuracy:  86.26532580245213\n",
            "epoch:  698  loss:  0.30625794373656917  accuracy:  85.74183771869403\n",
            "epoch:  699  loss:  0.3047563261870166  accuracy:  86.23088579694173\n",
            "epoch:  700  loss:  0.30658412082519787  accuracy:  86.00358176057308\n",
            "epoch:  701  loss:  0.30804745001862865  accuracy:  85.70739771318364\n",
            "epoch:  702  loss:  0.32011951003410977  accuracy:  85.14946962391514\n",
            "epoch:  703  loss:  0.3123956933599117  accuracy:  85.81071772971484\n",
            "epoch:  704  loss:  0.30934417667566605  accuracy:  85.98980575836892\n",
            "epoch:  705  loss:  0.3080216816637138  accuracy:  86.12067777930845\n",
            "epoch:  706  loss:  0.3038380975105132  accuracy:  86.32731781237085\n",
            "epoch:  707  loss:  0.30568981906782744  accuracy:  86.10690177710428\n",
            "epoch:  708  loss:  0.30745354747415854  accuracy:  86.05179776828764\n",
            "epoch:  709  loss:  0.3040821907983074  accuracy:  86.14134178261469\n",
            "epoch:  710  loss:  0.30800771243990344  accuracy:  85.9278137484502\n",
            "epoch:  711  loss:  0.30910588492373653  accuracy:  85.92092574734812\n",
            "epoch:  712  loss:  0.31370849476518803  accuracy:  85.39054966248794\n",
            "epoch:  713  loss:  0.30452857567540115  accuracy:  86.22399779583965\n",
            "epoch:  714  loss:  0.30290723079565324  accuracy:  86.34798181567709\n",
            "epoch:  715  loss:  0.3077546499073218  accuracy:  86.19644579143133\n",
            "epoch:  716  loss:  0.30471701603082607  accuracy:  86.25843780135004\n",
            "epoch:  717  loss:  0.3023311290030375  accuracy:  86.49262983882078\n",
            "epoch:  718  loss:  0.3053034864697579  accuracy:  86.18266978922716\n",
            "epoch:  719  loss:  0.30586740785121985  accuracy:  86.31354181016668\n",
            "epoch:  720  loss:  0.3103145068342782  accuracy:  85.67984570877532\n",
            "epoch:  721  loss:  0.29929175672616193  accuracy:  86.51329384212701\n",
            "epoch:  722  loss:  0.2999167331266147  accuracy:  86.50640584102493\n",
            "epoch:  723  loss:  0.3068459684883436  accuracy:  86.10690177710428\n",
            "epoch:  724  loss:  0.30854997347580004  accuracy:  85.96914175506268\n",
            "epoch:  725  loss:  0.3037483984198283  accuracy:  86.32731781237085\n",
            "epoch:  726  loss:  0.29954982394685364  accuracy:  86.66482986637278\n",
            "epoch:  727  loss:  0.29760150757764126  accuracy:  86.81636589061854\n",
            "epoch:  728  loss:  0.31166695945969725  accuracy:  85.81760573081692\n",
            "epoch:  729  loss:  0.3051175417273083  accuracy:  85.88648574183772\n",
            "epoch:  730  loss:  0.3008455660002736  accuracy:  86.53395784543325\n",
            "epoch:  731  loss:  0.2962741156302794  accuracy:  86.47885383661661\n",
            "epoch:  732  loss:  0.3047517282396395  accuracy:  85.87270973963356\n",
            "epoch:  733  loss:  0.304393309437304  accuracy:  86.22399779583965\n",
            "epoch:  734  loss:  0.3105103074457383  accuracy:  85.7900537264086\n",
            "epoch:  735  loss:  0.3039840471380784  accuracy:  86.49262983882078\n",
            "epoch:  736  loss:  0.29922361933859865  accuracy:  86.45130183220829\n",
            "epoch:  737  loss:  0.2991089306577767  accuracy:  86.6923818707811\n",
            "epoch:  738  loss:  0.3023327799527536  accuracy:  86.09312577490013\n",
            "epoch:  739  loss:  0.301488019529084  accuracy:  86.32042981126877\n",
            "epoch:  740  loss:  0.2939511246200205  accuracy:  86.7612618818019\n",
            "epoch:  741  loss:  0.2999818556535209  accuracy:  86.23088579694173\n",
            "epoch:  742  loss:  0.2997692175818173  accuracy:  86.54773384763742\n",
            "epoch:  743  loss:  0.30085120504183915  accuracy:  86.34798181567709\n",
            "epoch:  744  loss:  0.29137131471183286  accuracy:  86.91968590714974\n",
            "epoch:  745  loss:  0.3025149740530187  accuracy:  86.21710979473757\n",
            "epoch:  746  loss:  0.3041573044870786  accuracy:  86.32731781237085\n",
            "epoch:  747  loss:  0.2965122629975727  accuracy:  86.51329384212701\n",
            "epoch:  748  loss:  0.2973459502141951  accuracy:  86.54084584653533\n",
            "epoch:  749  loss:  0.29625447638017743  accuracy:  86.47196583551454\n",
            "epoch:  750  loss:  0.2991412998555465  accuracy:  86.29976580796253\n",
            "epoch:  751  loss:  0.2945130211596877  accuracy:  86.47885383661661\n",
            "epoch:  752  loss:  0.2882387986059507  accuracy:  87.11943793911007\n",
            "epoch:  753  loss:  0.29309317499156956  accuracy:  86.6579418652707\n",
            "epoch:  754  loss:  0.2902248027317615  accuracy:  86.56150984984157\n",
            "epoch:  755  loss:  0.29379855938392296  accuracy:  86.74059787849566\n",
            "epoch:  756  loss:  0.2862717722615586  accuracy:  87.38118198098911\n",
            "epoch:  757  loss:  0.2983403890475144  accuracy:  86.64416586306653\n",
            "epoch:  758  loss:  0.2950459514329019  accuracy:  86.43063782890205\n",
            "epoch:  759  loss:  0.2901173601085316  accuracy:  86.90590990494559\n",
            "epoch:  760  loss:  0.30419895817161446  accuracy:  85.93470174955227\n",
            "epoch:  761  loss:  0.28874775301960154  accuracy:  87.07810993249758\n",
            "epoch:  762  loss:  0.2898756039238679  accuracy:  86.63038986086238\n",
            "epoch:  763  loss:  0.29910135413270494  accuracy:  86.34798181567709\n",
            "epoch:  764  loss:  0.29067021978880225  accuracy:  86.87146989943518\n",
            "epoch:  765  loss:  0.29034040496317803  accuracy:  86.78881388621022\n",
            "epoch:  766  loss:  0.2869227614214243  accuracy:  87.14698994351839\n",
            "epoch:  767  loss:  0.28639096125933666  accuracy:  87.23653395784544\n",
            "epoch:  768  loss:  0.28639527270371534  accuracy:  87.28474996556\n",
            "epoch:  769  loss:  0.2933644117965303  accuracy:  86.63727786196446\n",
            "epoch:  770  loss:  0.29524234707468155  accuracy:  86.7268218762915\n",
            "epoch:  771  loss:  0.2890624650575057  accuracy:  86.63038986086238\n",
            "epoch:  772  loss:  0.2913244062074207  accuracy:  86.80258988841439\n",
            "epoch:  773  loss:  0.2891534837867327  accuracy:  87.05055792808926\n",
            "epoch:  774  loss:  0.2904186171964109  accuracy:  87.1056619369059\n",
            "epoch:  775  loss:  0.28591258682845333  accuracy:  87.11943793911007\n",
            "epoch:  776  loss:  0.29609009636665345  accuracy:  86.7268218762915\n",
            "epoch:  777  loss:  0.2877687355969165  accuracy:  86.88524590163935\n",
            "epoch:  778  loss:  0.2821948135920605  accuracy:  87.28474996556\n",
            "epoch:  779  loss:  0.30241794017724616  accuracy:  86.44441383110622\n",
            "epoch:  780  loss:  0.296301194642805  accuracy:  86.61661385865821\n",
            "epoch:  781  loss:  0.2826231928165827  accuracy:  87.20209395233503\n",
            "epoch:  782  loss:  0.2852164619240588  accuracy:  86.97478991596638\n",
            "epoch:  783  loss:  0.2841181346890289  accuracy:  87.26408596225376\n",
            "epoch:  784  loss:  0.29195182979772005  accuracy:  86.6579418652707\n",
            "epoch:  785  loss:  0.281954004982891  accuracy:  87.28474996556\n",
            "epoch:  786  loss:  0.29071431835380235  accuracy:  86.73370987739358\n",
            "epoch:  787  loss:  0.2821717085071726  accuracy:  87.43628598980575\n",
            "epoch:  788  loss:  0.2822152482858127  accuracy:  87.33296597327455\n",
            "epoch:  789  loss:  0.2855303362966454  accuracy:  87.0023419203747\n",
            "epoch:  790  loss:  0.28484612798162  accuracy:  87.24342195894751\n",
            "epoch:  791  loss:  0.2846793811899158  accuracy:  87.08499793359967\n",
            "epoch:  792  loss:  0.28249697429916387  accuracy:  87.35362997658079\n",
            "epoch:  793  loss:  0.28249055307082915  accuracy:  87.19520595123295\n",
            "epoch:  794  loss:  0.2846976504856799  accuracy:  87.09877393580383\n",
            "epoch:  795  loss:  0.28839999201467237  accuracy:  87.31230196996832\n",
            "epoch:  796  loss:  0.28341091307525973  accuracy:  87.13321394131422\n",
            "epoch:  797  loss:  0.28372546359804285  accuracy:  87.09188593470175\n",
            "epoch:  798  loss:  0.27822353280818996  accuracy:  87.59471001515361\n",
            "epoch:  799  loss:  0.2831958491811412  accuracy:  87.14010194241631\n",
            "epoch:  800  loss:  0.28937510697535207  accuracy:  87.08499793359967\n",
            "epoch:  801  loss:  0.2803213266030473  accuracy:  87.60159801625568\n",
            "epoch:  802  loss:  0.2864471339238447  accuracy:  87.02300592368094\n",
            "epoch:  803  loss:  0.28883338433961464  accuracy:  86.7612618818019\n",
            "epoch:  804  loss:  0.2773193901260787  accuracy:  87.89089406254305\n",
            "epoch:  805  loss:  0.28189544151646817  accuracy:  87.43628598980575\n",
            "epoch:  806  loss:  0.28355780647656265  accuracy:  87.18831795013087\n",
            "epoch:  807  loss:  0.2846625541701332  accuracy:  87.28474996556\n",
            "epoch:  808  loss:  0.27621326363066995  accuracy:  87.59471001515361\n",
            "epoch:  809  loss:  0.2789055818568939  accuracy:  87.53960600633697\n",
            "epoch:  810  loss:  0.27917613268087416  accuracy:  87.34674197547872\n",
            "epoch:  811  loss:  0.2797840560397295  accuracy:  87.33296597327455\n",
            "epoch:  812  loss:  0.2739652773535503  accuracy:  87.79446204711392\n",
            "epoch:  813  loss:  0.2877167007563971  accuracy:  86.92657390825183\n",
            "epoch:  814  loss:  0.2722498481390906  accuracy:  87.85645405703265\n",
            "epoch:  815  loss:  0.2714777668902887  accuracy:  88.0837580934013\n",
            "epoch:  816  loss:  0.2738635085029434  accuracy:  87.78068604490977\n",
            "epoch:  817  loss:  0.27909095211123647  accuracy:  87.5602700096432\n",
            "epoch:  818  loss:  0.2765225564822594  accuracy:  87.69803003168481\n",
            "epoch:  819  loss:  0.27722318621152425  accuracy:  87.31230196996832\n",
            "epoch:  820  loss:  0.28658109185271624  accuracy:  87.22964595674335\n",
            "epoch:  821  loss:  0.28096200080922296  accuracy:  87.32607797217247\n",
            "epoch:  822  loss:  0.2833216795971085  accuracy:  87.12632594021215\n",
            "epoch:  823  loss:  0.27576133555240384  accuracy:  87.70491803278688\n",
            "epoch:  824  loss:  0.2760039398161599  accuracy:  87.62226201956193\n",
            "epoch:  825  loss:  0.28263922513377027  accuracy:  87.09877393580383\n",
            "epoch:  826  loss:  0.2751179633944106  accuracy:  87.60848601735776\n",
            "epoch:  827  loss:  0.2766282909138831  accuracy:  87.34674197547872\n",
            "epoch:  828  loss:  0.2727291201006399  accuracy:  87.40184598429536\n",
            "epoch:  829  loss:  0.2723478219355248  accuracy:  87.58782201405153\n",
            "epoch:  830  loss:  0.2737933942286793  accuracy:  87.77379804380769\n",
            "epoch:  831  loss:  0.27668069576466603  accuracy:  87.629150020664\n",
            "epoch:  832  loss:  0.2705922888619855  accuracy:  87.7669100427056\n",
            "epoch:  833  loss:  0.27195760489889603  accuracy:  87.71180603388896\n",
            "epoch:  834  loss:  0.2691469799174489  accuracy:  87.90467006474721\n",
            "epoch:  835  loss:  0.2721294601141117  accuracy:  87.95977407356385\n",
            "epoch:  836  loss:  0.2776928396531415  accuracy:  87.32607797217247\n",
            "epoch:  837  loss:  0.27598525549257275  accuracy:  87.51894200303072\n",
            "epoch:  838  loss:  0.2829444791938438  accuracy:  87.34674197547872\n",
            "epoch:  839  loss:  0.2722950251117392  accuracy:  87.93911007025761\n",
            "epoch:  840  loss:  0.2709487878655514  accuracy:  87.87711806033889\n",
            "epoch:  841  loss:  0.27641108711119905  accuracy:  87.40184598429536\n",
            "epoch:  842  loss:  0.27612858802954643  accuracy:  87.36740597878496\n",
            "epoch:  843  loss:  0.2715180294685972  accuracy:  87.67736602837857\n",
            "epoch:  844  loss:  0.26483757869035257  accuracy:  88.0837580934013\n",
            "epoch:  845  loss:  0.27610398311476386  accuracy:  87.61537401845985\n",
            "epoch:  846  loss:  0.27046202760554655  accuracy:  87.84956605593057\n",
            "epoch:  847  loss:  0.27508851074124685  accuracy:  87.49827799972448\n",
            "epoch:  848  loss:  0.2782789857973161  accuracy:  87.41562198649952\n",
            "epoch:  849  loss:  0.26066890040127466  accuracy:  88.54525416724067\n",
            "epoch:  850  loss:  0.2606718813273545  accuracy:  88.47637415621986\n",
            "epoch:  851  loss:  0.26387464329918514  accuracy:  88.1870781099325\n",
            "epoch:  852  loss:  0.2634616354753663  accuracy:  88.02176608348258\n",
            "epoch:  853  loss:  0.26399515715163013  accuracy:  88.33861413417826\n",
            "epoch:  854  loss:  0.2654564212912747  accuracy:  88.0837580934013\n",
            "epoch:  855  loss:  0.27081272057559735  accuracy:  87.84267805482848\n",
            "epoch:  856  loss:  0.2682148750565042  accuracy:  87.88400606144097\n",
            "epoch:  857  loss:  0.26855987167946316  accuracy:  88.05620608899298\n",
            "epoch:  858  loss:  0.2697514853688997  accuracy:  87.9459980713597\n",
            "epoch:  859  loss:  0.2758920072938542  accuracy:  87.54649400743904\n",
            "epoch:  860  loss:  0.26787393255114866  accuracy:  88.04243008678881\n",
            "epoch:  861  loss:  0.26845032238840383  accuracy:  88.09753409560545\n",
            "epoch:  862  loss:  0.26879017229110747  accuracy:  88.02865408458466\n",
            "epoch:  863  loss:  0.27088062686686315  accuracy:  88.07687009229922\n",
            "epoch:  864  loss:  0.26053065800776837  accuracy:  88.5314781650365\n",
            "epoch:  865  loss:  0.266110542123435  accuracy:  88.04243008678881\n",
            "epoch:  866  loss:  0.26591222262658404  accuracy:  87.87711806033889\n",
            "epoch:  867  loss:  0.25750559017643126  accuracy:  88.76567020250724\n",
            "epoch:  868  loss:  0.2719038375248543  accuracy:  87.71180603388896\n",
            "epoch:  869  loss:  0.2621678624587999  accuracy:  88.09064609450337\n",
            "epoch:  870  loss:  0.26139081295880917  accuracy:  88.42127014740322\n",
            "epoch:  871  loss:  0.2630946801264336  accuracy:  88.15952610552418\n",
            "epoch:  872  loss:  0.2631501358457629  accuracy:  88.14575010332001\n",
            "epoch:  873  loss:  0.26625529475400295  accuracy:  87.9459980713597\n",
            "epoch:  874  loss:  0.26651910260239653  accuracy:  87.80135004821601\n",
            "epoch:  875  loss:  0.26020655197937276  accuracy:  88.36616613858658\n",
            "epoch:  876  loss:  0.26118478346485163  accuracy:  88.23529411764706\n",
            "epoch:  877  loss:  0.26324850902985664  accuracy:  88.2559581209533\n",
            "epoch:  878  loss:  0.26539382393127925  accuracy:  88.09064609450337\n",
            "epoch:  879  loss:  0.2546538001890927  accuracy:  88.79322220691556\n",
            "epoch:  880  loss:  0.2757076552738942  accuracy:  87.67047802727649\n",
            "epoch:  881  loss:  0.26450854553009034  accuracy:  88.09064609450337\n",
            "epoch:  882  loss:  0.25170166605529515  accuracy:  89.01363824218213\n",
            "epoch:  883  loss:  0.25695741999566446  accuracy:  88.57969417275106\n",
            "epoch:  884  loss:  0.2624322838577329  accuracy:  88.1526381044221\n",
            "epoch:  885  loss:  0.2660518744494702  accuracy:  87.97355007576802\n",
            "epoch:  886  loss:  0.26133165485825416  accuracy:  88.27662212425955\n",
            "epoch:  887  loss:  0.25986326021429823  accuracy:  88.41438214630114\n",
            "epoch:  888  loss:  0.26184906900331395  accuracy:  88.4281581485053\n",
            "epoch:  889  loss:  0.2593763540382802  accuracy:  88.24907011985123\n",
            "epoch:  890  loss:  0.25705062897388625  accuracy:  88.2215181154429\n",
            "epoch:  891  loss:  0.25363479281838136  accuracy:  88.90343022454884\n",
            "epoch:  892  loss:  0.26412672020586286  accuracy:  88.27662212425955\n",
            "epoch:  893  loss:  0.257590714826172  accuracy:  88.6347981815677\n",
            "epoch:  894  loss:  0.2580989300896764  accuracy:  88.29728612756578\n",
            "epoch:  895  loss:  0.25930047465275596  accuracy:  88.62102217936355\n",
            "epoch:  896  loss:  0.2654191393270228  accuracy:  87.98732607797217\n",
            "epoch:  897  loss:  0.25754614267357123  accuracy:  88.62102217936355\n",
            "epoch:  898  loss:  0.2545986165868495  accuracy:  88.74500619920099\n",
            "epoch:  899  loss:  0.2637343993116663  accuracy:  88.00110208017634\n",
            "epoch:  900  loss:  0.26047652309090985  accuracy:  88.15952610552418\n",
            "epoch:  901  loss:  0.2541110730890499  accuracy:  88.75878220140515\n",
            "epoch:  902  loss:  0.2554229185126803  accuracy:  88.66235018597602\n",
            "epoch:  903  loss:  0.24805310599476135  accuracy:  89.11695825871332\n",
            "epoch:  904  loss:  0.2519103686767499  accuracy:  88.74500619920099\n",
            "epoch:  905  loss:  0.25136313626943235  accuracy:  88.70367819258851\n",
            "epoch:  906  loss:  0.25276541950280945  accuracy:  88.77944620471139\n",
            "epoch:  907  loss:  0.2548278788488781  accuracy:  88.77255820360931\n",
            "epoch:  908  loss:  0.2633687985601923  accuracy:  88.00110208017634\n",
            "epoch:  909  loss:  0.25854928318766757  accuracy:  88.64857418377187\n",
            "epoch:  910  loss:  0.25002881226657525  accuracy:  88.82077421132388\n",
            "epoch:  911  loss:  0.25385708546717317  accuracy:  88.66923818707811\n",
            "epoch:  912  loss:  0.247143213227771  accuracy:  89.10318225650916\n",
            "epoch:  913  loss:  0.2534021535599128  accuracy:  88.51081416173027\n",
            "epoch:  914  loss:  0.25924844836824146  accuracy:  88.35927813748451\n",
            "epoch:  915  loss:  0.24697562165579892  accuracy:  89.261606281857\n",
            "epoch:  916  loss:  0.25476007472673945  accuracy:  88.55214216834274\n",
            "epoch:  917  loss:  0.2482619124316762  accuracy:  88.78633420581347\n",
            "epoch:  918  loss:  0.25759659299863275  accuracy:  88.30417412866787\n",
            "epoch:  919  loss:  0.25259801709901564  accuracy:  88.58658217385315\n",
            "epoch:  920  loss:  0.2541117745172322  accuracy:  88.73123019699683\n",
            "epoch:  921  loss:  0.24638556578276258  accuracy:  89.08251825320292\n",
            "epoch:  922  loss:  0.2455918593259041  accuracy:  89.04807824769252\n",
            "epoch:  923  loss:  0.2510185426182943  accuracy:  88.97919823667172\n",
            "epoch:  924  loss:  0.24988379764735888  accuracy:  88.70367819258851\n",
            "epoch:  925  loss:  0.2488981845999966  accuracy:  88.94475823116132\n",
            "epoch:  926  loss:  0.25076982646642726  accuracy:  88.89654222344676\n",
            "epoch:  927  loss:  0.25074989652564694  accuracy:  88.5314781650365\n",
            "epoch:  928  loss:  0.24360286360569344  accuracy:  89.07563025210084\n",
            "epoch:  929  loss:  0.24576993547107975  accuracy:  89.04119024659045\n",
            "epoch:  930  loss:  0.2500603858769999  accuracy:  88.65546218487395\n",
            "epoch:  931  loss:  0.2555294602222557  accuracy:  88.46948615511778\n",
            "epoch:  932  loss:  0.2504423549022864  accuracy:  88.88965422234467\n",
            "epoch:  933  loss:  0.24281933765028574  accuracy:  89.28227028516325\n",
            "epoch:  934  loss:  0.25264661909094  accuracy:  88.69679019148643\n",
            "epoch:  935  loss:  0.24946504035860173  accuracy:  88.87587822014052\n",
            "epoch:  936  loss:  0.2504930328421232  accuracy:  88.94475823116132\n",
            "epoch:  937  loss:  0.24995061578846187  accuracy:  88.73123019699683\n",
            "epoch:  938  loss:  0.2504838897224004  accuracy:  88.80699820911971\n",
            "epoch:  939  loss:  0.24444386132501802  accuracy:  89.13073426091748\n",
            "epoch:  940  loss:  0.24808079099947467  accuracy:  88.86210221793635\n",
            "epoch:  941  loss:  0.24569772102604853  accuracy:  89.23405427744868\n",
            "epoch:  942  loss:  0.24498881864176586  accuracy:  89.06185424989668\n",
            "epoch:  943  loss:  0.2407472905011229  accuracy:  89.43380630940901\n",
            "epoch:  944  loss:  0.23298308704490256  accuracy:  89.84019837443174\n",
            "epoch:  945  loss:  0.2428240134012668  accuracy:  89.43380630940901\n",
            "epoch:  946  loss:  0.24210725106603762  accuracy:  89.2960462873674\n",
            "epoch:  947  loss:  0.24165833848889726  accuracy:  89.33048629287781\n",
            "epoch:  948  loss:  0.24147936958783192  accuracy:  89.33737429397989\n",
            "epoch:  949  loss:  0.2415155505155676  accuracy:  89.3993663038986\n",
            "epoch:  950  loss:  0.2500370905359581  accuracy:  88.76567020250724\n",
            "epoch:  951  loss:  0.25167432224180664  accuracy:  88.79322220691556\n",
            "epoch:  952  loss:  0.2419268263200867  accuracy:  89.28915828626532\n",
            "epoch:  953  loss:  0.24578603670844723  accuracy:  89.17206226752997\n",
            "epoch:  954  loss:  0.23894138462694736  accuracy:  89.45447031271524\n",
            "epoch:  955  loss:  0.2370473130827174  accuracy:  89.35803829728613\n",
            "epoch:  956  loss:  0.2390729572871842  accuracy:  89.6128943380631\n",
            "epoch:  957  loss:  0.24163103040822495  accuracy:  89.09629425540709\n",
            "epoch:  958  loss:  0.2429867974365853  accuracy:  89.21339027414244\n",
            "epoch:  959  loss:  0.2402392973057707  accuracy:  89.28915828626532\n",
            "epoch:  960  loss:  0.24474902855436867  accuracy:  89.51646232263397\n",
            "epoch:  961  loss:  0.2466612562921064  accuracy:  88.79322220691556\n",
            "epoch:  962  loss:  0.23873873983866126  accuracy:  89.52335032373605\n",
            "epoch:  963  loss:  0.24260466955453341  accuracy:  89.37181429949028\n",
            "epoch:  964  loss:  0.24305526622564508  accuracy:  89.15139826422372\n",
            "epoch:  965  loss:  0.23880463055440063  accuracy:  89.23405427744868\n",
            "epoch:  966  loss:  0.2329472451991558  accuracy:  89.7850943656151\n",
            "epoch:  967  loss:  0.24046851647164574  accuracy:  89.30982228957157\n",
            "epoch:  968  loss:  0.23756020486802334  accuracy:  89.42691830830692\n",
            "epoch:  969  loss:  0.24667468266121562  accuracy:  89.06874225099877\n",
            "epoch:  970  loss:  0.23771044700200572  accuracy:  89.45447031271524\n",
            "epoch:  971  loss:  0.23280896628456416  accuracy:  89.92974238875878\n",
            "epoch:  972  loss:  0.23869719215169527  accuracy:  89.41314230610277\n",
            "epoch:  973  loss:  0.23710491073773673  accuracy:  89.57156633145061\n",
            "epoch:  974  loss:  0.23580820259065532  accuracy:  89.7162143545943\n",
            "epoch:  975  loss:  0.24492927088169605  accuracy:  88.99297423887587\n",
            "epoch:  976  loss:  0.2440371892279888  accuracy:  89.03430224548836\n",
            "epoch:  977  loss:  0.23749028699081748  accuracy:  89.46135831381733\n",
            "epoch:  978  loss:  0.2388530436060057  accuracy:  89.35803829728613\n",
            "epoch:  979  loss:  0.2343900682722049  accuracy:  89.48891031822565\n",
            "epoch:  980  loss:  0.23126573515366977  accuracy:  89.86775037884006\n",
            "epoch:  981  loss:  0.22837344028968132  accuracy:  89.61978233916517\n",
            "epoch:  982  loss:  0.24647991042283962  accuracy:  89.01363824218213\n",
            "epoch:  983  loss:  0.260549883203067  accuracy:  88.67612618818019\n",
            "epoch:  984  loss:  0.24092581703948948  accuracy:  89.36492629838821\n",
            "epoch:  985  loss:  0.23656071032977233  accuracy:  89.53023832483814\n",
            "epoch:  986  loss:  0.23466385699288217  accuracy:  89.55090232814437\n",
            "epoch:  987  loss:  0.23015619372431445  accuracy:  89.8195343711255\n",
            "epoch:  988  loss:  0.2279555137298836  accuracy:  89.9572943931671\n",
            "epoch:  989  loss:  0.24267157939761644  accuracy:  89.17895026863204\n",
            "epoch:  990  loss:  0.23362617975018507  accuracy:  89.7162143545943\n",
            "epoch:  991  loss:  0.22849559543759784  accuracy:  90.01239840198375\n",
            "epoch:  992  loss:  0.23150483717445763  accuracy:  89.82642237222758\n",
            "epoch:  993  loss:  0.22861971110126042  accuracy:  89.79198236671718\n",
            "epoch:  994  loss:  0.230467633597367  accuracy:  89.88152638104422\n",
            "epoch:  995  loss:  0.2364280994297437  accuracy:  89.70932635349222\n",
            "epoch:  996  loss:  0.24496468380021727  accuracy:  89.14451026312165\n",
            "epoch:  997  loss:  0.23014151709256117  accuracy:  89.66111034577766\n",
            "epoch:  998  loss:  0.23222995814557476  accuracy:  89.94351839096294\n",
            "epoch:  999  loss:  0.23479223664568252  accuracy:  89.52335032373605\n",
            "epoch:  1000  loss:  0.2340490554856735  accuracy:  89.8195343711255\n",
            "epoch:  1001  loss:  0.23992420058738004  accuracy:  89.31671029067364\n",
            "epoch:  1002  loss:  0.23396265687184123  accuracy:  89.67488634798181\n",
            "epoch:  1003  loss:  0.23009584818247314  accuracy:  89.90219038435046\n",
            "epoch:  1004  loss:  0.22895148937400667  accuracy:  89.93663038986087\n",
            "epoch:  1005  loss:  0.22854766366049548  accuracy:  89.88152638104422\n",
            "epoch:  1006  loss:  0.22628432742811003  accuracy:  90.01928640308583\n",
            "epoch:  1007  loss:  0.22802508020942114  accuracy:  89.98484639757542\n",
            "epoch:  1008  loss:  0.22289793995568405  accuracy:  90.17082242733159\n",
            "epoch:  1009  loss:  0.2264950574676037  accuracy:  90.15704642512743\n",
            "epoch:  1010  loss:  0.23236107846042278  accuracy:  89.62667034026725\n",
            "epoch:  1011  loss:  0.22452834333528054  accuracy:  90.10883041741286\n",
            "epoch:  1012  loss:  0.22950962726563062  accuracy:  89.9228543876567\n",
            "epoch:  1013  loss:  0.2293501449080436  accuracy:  89.79198236671718\n",
            "epoch:  1014  loss:  0.2273009328749213  accuracy:  90.03995040639207\n",
            "epoch:  1015  loss:  0.23884903330918858  accuracy:  89.43380630940901\n",
            "epoch:  1016  loss:  0.23824872589091622  accuracy:  89.43380630940901\n",
            "epoch:  1017  loss:  0.22610856940191562  accuracy:  90.10883041741286\n",
            "epoch:  1018  loss:  0.22351997891213385  accuracy:  90.10194241631079\n",
            "epoch:  1019  loss:  0.2282595741389983  accuracy:  90.10883041741286\n",
            "epoch:  1020  loss:  0.2236221041209623  accuracy:  90.17082242733159\n",
            "epoch:  1021  loss:  0.22269408721982292  accuracy:  90.33613445378151\n",
            "epoch:  1022  loss:  0.23174359936912226  accuracy:  89.68866235018598\n",
            "epoch:  1023  loss:  0.22477824915570485  accuracy:  89.82642237222758\n",
            "epoch:  1024  loss:  0.2299589553776318  accuracy:  89.82642237222758\n",
            "epoch:  1025  loss:  0.2220584531748963  accuracy:  90.2397024383524\n",
            "epoch:  1026  loss:  0.22207769876152775  accuracy:  90.4807824769252\n",
            "epoch:  1027  loss:  0.22682245909851564  accuracy:  89.8884143821463\n",
            "epoch:  1028  loss:  0.2180224310538463  accuracy:  90.22592643614823\n",
            "epoch:  1029  loss:  0.22965676349284056  accuracy:  89.62667034026725\n",
            "epoch:  1030  loss:  0.22000972451499745  accuracy:  90.21903843504614\n",
            "epoch:  1031  loss:  0.21988341794031713  accuracy:  90.31547045047527\n",
            "epoch:  1032  loss:  0.21829616958394754  accuracy:  90.53588648574184\n",
            "epoch:  1033  loss:  0.22097593496852153  accuracy:  90.26036644165863\n",
            "epoch:  1034  loss:  0.2223563560163175  accuracy:  90.21215043394407\n",
            "epoch:  1035  loss:  0.2210823608517959  accuracy:  90.19837443173991\n",
            "epoch:  1036  loss:  0.21266056634182937  accuracy:  91.03182256509162\n",
            "epoch:  1037  loss:  0.2250738648207888  accuracy:  90.11571841851494\n",
            "epoch:  1038  loss:  0.22382843425133814  accuracy:  90.2397024383524\n",
            "epoch:  1039  loss:  0.22765115610018366  accuracy:  90.01239840198375\n",
            "epoch:  1040  loss:  0.22556005998828027  accuracy:  90.10883041741286\n",
            "epoch:  1041  loss:  0.21400516913652848  accuracy:  90.48767047802728\n",
            "epoch:  1042  loss:  0.22393600547842488  accuracy:  89.96418239426919\n",
            "epoch:  1043  loss:  0.22287192579627219  accuracy:  90.3430224548836\n",
            "epoch:  1044  loss:  0.22338192202977067  accuracy:  90.0261744041879\n",
            "epoch:  1045  loss:  0.22199689980351509  accuracy:  90.3430224548836\n",
            "epoch:  1046  loss:  0.22303645112023798  accuracy:  90.30858244937319\n",
            "epoch:  1047  loss:  0.21770252758604483  accuracy:  90.55655048904808\n",
            "epoch:  1048  loss:  0.2270740567303538  accuracy:  90.06750241080039\n",
            "epoch:  1049  loss:  0.2148074346405528  accuracy:  90.76319052211048\n",
            "epoch:  1050  loss:  0.22332088078085688  accuracy:  90.06750241080039\n",
            "epoch:  1051  loss:  0.21336639795684834  accuracy:  90.74941451990632\n",
            "epoch:  1052  loss:  0.21635645153577013  accuracy:  90.6185424989668\n",
            "epoch:  1053  loss:  0.21382909459152372  accuracy:  90.75630252100841\n",
            "epoch:  1054  loss:  0.2159894980035516  accuracy:  90.72875051660009\n",
            "epoch:  1055  loss:  0.22439560826335633  accuracy:  89.79887036781926\n",
            "epoch:  1056  loss:  0.2225577832253647  accuracy:  90.3016944482711\n",
            "epoch:  1057  loss:  0.22689137662519582  accuracy:  90.11571841851494\n",
            "epoch:  1058  loss:  0.2132766431802839  accuracy:  90.55655048904808\n",
            "epoch:  1059  loss:  0.2225036315772878  accuracy:  90.28791844606695\n",
            "epoch:  1060  loss:  0.21525078325363406  accuracy:  90.83207053313129\n",
            "epoch:  1061  loss:  0.21301274070161352  accuracy:  90.73563851770216\n",
            "epoch:  1062  loss:  0.21107678756862983  accuracy:  90.74252651880424\n",
            "epoch:  1063  loss:  0.2155720841851358  accuracy:  90.5841024934564\n",
            "epoch:  1064  loss:  0.21727534306042778  accuracy:  90.41190246590439\n",
            "epoch:  1065  loss:  0.21661894983300362  accuracy:  90.56343849015016\n",
            "epoch:  1066  loss:  0.2136867592068378  accuracy:  90.70119851219177\n",
            "epoch:  1067  loss:  0.21567633374447762  accuracy:  90.74252651880424\n",
            "epoch:  1068  loss:  0.22266664828441576  accuracy:  90.48767047802728\n",
            "epoch:  1069  loss:  0.22650507955979604  accuracy:  89.86086237773797\n",
            "epoch:  1070  loss:  0.2128686989163758  accuracy:  90.85273453643752\n",
            "epoch:  1071  loss:  0.2203953235146756  accuracy:  90.28103044496487\n",
            "epoch:  1072  loss:  0.21376842843762014  accuracy:  90.59787849566055\n",
            "epoch:  1073  loss:  0.20989534241291163  accuracy:  91.2797906047665\n",
            "epoch:  1074  loss:  0.2088255196797452  accuracy:  91.0042705606833\n",
            "epoch:  1075  loss:  0.20741069617186356  accuracy:  90.90095054415208\n",
            "epoch:  1076  loss:  0.21086371194698017  accuracy:  90.61165449786472\n",
            "epoch:  1077  loss:  0.21658136785843268  accuracy:  90.5152224824356\n",
            "epoch:  1078  loss:  0.21742794688476447  accuracy:  90.549662487946\n",
            "epoch:  1079  loss:  0.21460883663732463  accuracy:  90.46700647472103\n",
            "epoch:  1080  loss:  0.21714644783956155  accuracy:  90.3430224548836\n",
            "epoch:  1081  loss:  0.20461723930083747  accuracy:  91.36244661799145\n",
            "epoch:  1082  loss:  0.21016034957281665  accuracy:  90.73563851770216\n",
            "epoch:  1083  loss:  0.21629716632270604  accuracy:  90.43256646921064\n",
            "epoch:  1084  loss:  0.20923639275364547  accuracy:  90.86651053864169\n",
            "epoch:  1085  loss:  0.2198819896119786  accuracy:  90.4807824769252\n",
            "epoch:  1086  loss:  0.214580107735346  accuracy:  90.7907425265188\n",
            "epoch:  1087  loss:  0.21019255988302926  accuracy:  90.93539054966249\n",
            "epoch:  1088  loss:  0.21617689318590574  accuracy:  90.6874225099876\n",
            "epoch:  1089  loss:  0.21572486810947616  accuracy:  90.39123846259815\n",
            "epoch:  1090  loss:  0.20847688906920123  accuracy:  90.71497451439592\n",
            "epoch:  1091  loss:  0.21699162185775098  accuracy:  90.39812646370024\n",
            "epoch:  1092  loss:  0.20454013132699217  accuracy:  91.1075905772145\n",
            "epoch:  1093  loss:  0.20569749082792624  accuracy:  91.2109105937457\n",
            "epoch:  1094  loss:  0.2012396898058545  accuracy:  91.19024659043946\n",
            "epoch:  1095  loss:  0.20959379592247615  accuracy:  90.77007852321256\n",
            "epoch:  1096  loss:  0.2107609694813102  accuracy:  90.7907425265188\n",
            "epoch:  1097  loss:  0.20644291416929353  accuracy:  91.16958258713322\n",
            "epoch:  1098  loss:  0.21096878864906726  accuracy:  90.89406254305001\n",
            "epoch:  1099  loss:  0.2007650661085046  accuracy:  91.50709464113514\n",
            "epoch:  1100  loss:  0.2063791940502185  accuracy:  91.02493456398953\n",
            "epoch:  1101  loss:  0.21783299025859956  accuracy:  90.4807824769252\n",
            "epoch:  1102  loss:  0.20526617976350223  accuracy:  91.07315057170409\n",
            "epoch:  1103  loss:  0.20890046807935142  accuracy:  91.19024659043946\n",
            "epoch:  1104  loss:  0.20634726325532657  accuracy:  91.35555861688938\n",
            "epoch:  1105  loss:  0.20812358003392464  accuracy:  90.60476649676264\n",
            "epoch:  1106  loss:  0.20509290244809555  accuracy:  90.90783854525417\n",
            "epoch:  1107  loss:  0.19829465154076528  accuracy:  91.45887863342058\n",
            "epoch:  1108  loss:  0.19990578036381204  accuracy:  91.17647058823529\n",
            "epoch:  1109  loss:  0.2093095697913145  accuracy:  90.96983055517289\n",
            "epoch:  1110  loss:  0.2216303506646706  accuracy:  90.04683840749415\n",
            "epoch:  1111  loss:  0.2015629758598276  accuracy:  91.34178261468521\n",
            "epoch:  1112  loss:  0.20638968208031083  accuracy:  91.17647058823529\n",
            "epoch:  1113  loss:  0.2059083411061808  accuracy:  91.19024659043946\n",
            "epoch:  1114  loss:  0.1989197472931761  accuracy:  91.35555861688938\n",
            "epoch:  1115  loss:  0.20903029788261374  accuracy:  90.77696652431464\n",
            "epoch:  1116  loss:  0.2074021305927381  accuracy:  90.9285025485604\n",
            "epoch:  1117  loss:  0.2118924137075047  accuracy:  90.85273453643752\n",
            "epoch:  1118  loss:  0.20114480850535296  accuracy:  91.54153464664554\n",
            "epoch:  1119  loss:  0.20860636153711665  accuracy:  90.79763052762088\n",
            "epoch:  1120  loss:  0.21099150854540455  accuracy:  90.90783854525417\n",
            "epoch:  1121  loss:  0.20610787649180282  accuracy:  91.19024659043946\n",
            "epoch:  1122  loss:  0.20769068591973064  accuracy:  90.94227855076457\n",
            "epoch:  1123  loss:  0.2006831757969593  accuracy:  91.44510263121641\n",
            "epoch:  1124  loss:  0.19373990404021232  accuracy:  91.81016668962667\n",
            "epoch:  1125  loss:  0.20254092379934385  accuracy:  91.08692657390826\n",
            "epoch:  1126  loss:  0.196187699919012  accuracy:  91.49331863893099\n",
            "epoch:  1127  loss:  0.20183761965651242  accuracy:  91.20402259264361\n",
            "epoch:  1128  loss:  0.19751840579922755  accuracy:  91.53464664554346\n",
            "epoch:  1129  loss:  0.20025747347808373  accuracy:  91.20402259264361\n",
            "epoch:  1130  loss:  0.20169497545301002  accuracy:  91.03871056619369\n",
            "epoch:  1131  loss:  0.19666240960133768  accuracy:  91.5553106488497\n",
            "epoch:  1132  loss:  0.19899321695011432  accuracy:  91.43821463011435\n",
            "epoch:  1133  loss:  0.21072742355470897  accuracy:  90.84584653533544\n",
            "epoch:  1134  loss:  0.1998285814485433  accuracy:  91.39688662350186\n",
            "epoch:  1135  loss:  0.2052457067155283  accuracy:  91.27290260366442\n",
            "epoch:  1136  loss:  0.1958522011800104  accuracy:  91.4175506268081\n",
            "epoch:  1137  loss:  0.1944719520611102  accuracy:  91.92726270836204\n",
            "epoch:  1138  loss:  0.2106933060611127  accuracy:  90.74941451990632\n",
            "epoch:  1139  loss:  0.19012480032995788  accuracy:  92.04435872709739\n",
            "epoch:  1140  loss:  0.1972565977117102  accuracy:  91.45887863342058\n",
            "epoch:  1141  loss:  0.20263150398097168  accuracy:  91.05937456949994\n",
            "epoch:  1142  loss:  0.2008151315170094  accuracy:  91.10070257611241\n",
            "epoch:  1143  loss:  0.19390103759590235  accuracy:  91.50709464113514\n",
            "epoch:  1144  loss:  0.18964248226129543  accuracy:  91.85838269734123\n",
            "epoch:  1145  loss:  0.19117655537438502  accuracy:  91.80327868852459\n",
            "epoch:  1146  loss:  0.20205156927365608  accuracy:  91.18335858933737\n",
            "epoch:  1147  loss:  0.22060809882116772  accuracy:  90.49455847912935\n",
            "epoch:  1148  loss:  0.19814390976729676  accuracy:  91.58286265325802\n",
            "epoch:  1149  loss:  0.1947540350259377  accuracy:  91.73439867750379\n",
            "epoch:  1150  loss:  0.20297754887260014  accuracy:  91.01804656288745\n",
            "epoch:  1151  loss:  0.19009422963706565  accuracy:  91.91348670615787\n",
            "epoch:  1152  loss:  0.1890687123772395  accuracy:  91.71373467419755\n",
            "epoch:  1153  loss:  0.19205074241267597  accuracy:  91.89282270285163\n",
            "epoch:  1154  loss:  0.1889917470636915  accuracy:  91.96859071497451\n",
            "epoch:  1155  loss:  0.1894162340808923  accuracy:  91.88593470174955\n",
            "epoch:  1156  loss:  0.20101575833724902  accuracy:  91.03871056619369\n",
            "epoch:  1157  loss:  0.19525086215346588  accuracy:  91.73439867750379\n",
            "epoch:  1158  loss:  0.19357365703374202  accuracy:  91.64485466317674\n",
            "epoch:  1159  loss:  0.19893751375429525  accuracy:  91.33489461358313\n",
            "epoch:  1160  loss:  0.19290353486604114  accuracy:  91.56908665105387\n",
            "epoch:  1161  loss:  0.19977630354912587  accuracy:  91.19713459154154\n",
            "epoch:  1162  loss:  0.1962321354618971  accuracy:  91.4175506268081\n",
            "epoch:  1163  loss:  0.19288697828314064  accuracy:  91.56908665105387\n",
            "epoch:  1164  loss:  0.1899818350720182  accuracy:  91.87904670064748\n",
            "epoch:  1165  loss:  0.19063008141851834  accuracy:  91.72062267529962\n",
            "epoch:  1166  loss:  0.1878968303614386  accuracy:  91.99614271938283\n",
            "epoch:  1167  loss:  0.18896407752773423  accuracy:  91.95481471277036\n",
            "epoch:  1168  loss:  0.18828065236531305  accuracy:  91.9754787160766\n",
            "epoch:  1169  loss:  0.19256771805940343  accuracy:  91.88593470174955\n",
            "epoch:  1170  loss:  0.19124926532151565  accuracy:  91.56908665105387\n",
            "epoch:  1171  loss:  0.19259595431881119  accuracy:  91.5553106488497\n",
            "epoch:  1172  loss:  0.19639994017240972  accuracy:  91.42443862791018\n",
            "epoch:  1173  loss:  0.20194188069297125  accuracy:  91.2453505992561\n",
            "epoch:  1174  loss:  0.19417377263163876  accuracy:  91.58286265325802\n",
            "epoch:  1175  loss:  0.18862333496870096  accuracy:  91.85149469623916\n",
            "epoch:  1176  loss:  0.18323144760382604  accuracy:  92.27855076456812\n",
            "epoch:  1177  loss:  0.18897848652465593  accuracy:  91.71373467419755\n",
            "epoch:  1178  loss:  0.1883233809246556  accuracy:  91.89282270285163\n",
            "epoch:  1179  loss:  0.19211442839702736  accuracy:  91.52087064333931\n",
            "epoch:  1180  loss:  0.1844611060054428  accuracy:  92.23033475685357\n",
            "epoch:  1181  loss:  0.18033275790722972  accuracy:  92.24411075905772\n",
            "epoch:  1182  loss:  0.1973130311116418  accuracy:  91.60352665656427\n",
            "epoch:  1183  loss:  0.19352003606324977  accuracy:  91.69995867199339\n",
            "epoch:  1184  loss:  0.18651533537387913  accuracy:  92.06502273040364\n",
            "epoch:  1185  loss:  0.19201726681241188  accuracy:  91.74817467970794\n",
            "epoch:  1186  loss:  0.19171153212060843  accuracy:  91.84460669513707\n",
            "epoch:  1187  loss:  0.18750191782604386  accuracy:  91.74128667860587\n",
            "epoch:  1188  loss:  0.18593038700675976  accuracy:  92.07191073150571\n",
            "epoch:  1189  loss:  0.1801584770327955  accuracy:  92.34054277448685\n",
            "epoch:  1190  loss:  0.18903434721727086  accuracy:  92.00303072048492\n",
            "epoch:  1191  loss:  0.17873271530793544  accuracy:  92.33365477338477\n",
            "epoch:  1192  loss:  0.18677590704683528  accuracy:  92.01680672268908\n",
            "epoch:  1193  loss:  0.1887418680875274  accuracy:  91.92726270836204\n",
            "epoch:  1194  loss:  0.18663025158325952  accuracy:  92.19589475134316\n",
            "epoch:  1195  loss:  0.2172528317054206  accuracy:  90.50833448133352\n",
            "epoch:  1196  loss:  0.187435676751345  accuracy:  91.94792671166827\n",
            "epoch:  1197  loss:  0.18353607810090472  accuracy:  92.37498277999724\n",
            "epoch:  1198  loss:  0.1861042227267086  accuracy:  92.12701474032235\n",
            "epoch:  1199  loss:  0.1864375450442704  accuracy:  92.13390274142444\n",
            "epoch:  1200  loss:  0.18096895076674213  accuracy:  92.47141479542637\n",
            "epoch:  1201  loss:  0.18091268309167896  accuracy:  92.354318776691\n",
            "epoch:  1202  loss:  0.1800548858557757  accuracy:  92.45075079212013\n",
            "epoch:  1203  loss:  0.18955163181419296  accuracy:  91.81705469072875\n",
            "epoch:  1204  loss:  0.19039012605222005  accuracy:  91.72062267529962\n",
            "epoch:  1205  loss:  0.18220347722571223  accuracy:  92.14079074252652\n",
            "epoch:  1206  loss:  0.18588883062419953  accuracy:  91.98236671717868\n",
            "epoch:  1207  loss:  0.1919543968590844  accuracy:  91.5897506543601\n",
            "epoch:  1208  loss:  0.18083540325360056  accuracy:  92.45075079212013\n",
            "epoch:  1209  loss:  0.17534045577931953  accuracy:  92.7744868439179\n",
            "epoch:  1210  loss:  0.18687319035232192  accuracy:  91.85149469623916\n",
            "epoch:  1211  loss:  0.19459978597196834  accuracy:  91.47954263672682\n",
            "epoch:  1212  loss:  0.18021020147282815  accuracy:  92.40253478440556\n",
            "epoch:  1213  loss:  0.1804848826620053  accuracy:  92.31299077007853\n",
            "epoch:  1214  loss:  0.18138135221809507  accuracy:  92.20967075354731\n",
            "epoch:  1215  loss:  0.19234248081162902  accuracy:  91.8721586995454\n",
            "epoch:  1216  loss:  0.18327877685511829  accuracy:  92.18900675024108\n",
            "epoch:  1217  loss:  0.19105261825163644  accuracy:  91.75506268081003\n",
            "epoch:  1218  loss:  0.1881623892563896  accuracy:  91.72062267529962\n",
            "epoch:  1219  loss:  0.17910855793705788  accuracy:  92.56784681085549\n",
            "epoch:  1220  loss:  0.17706459871413607  accuracy:  92.52651880424301\n",
            "epoch:  1221  loss:  0.17875789848692178  accuracy:  92.27166276346604\n",
            "epoch:  1222  loss:  0.18126017106398026  accuracy:  92.354318776691\n",
            "epoch:  1223  loss:  0.19137819222916025  accuracy:  91.98236671717868\n",
            "epoch:  1224  loss:  0.17975254120021125  accuracy:  92.22344675575148\n",
            "epoch:  1225  loss:  0.18318155502436295  accuracy:  92.2509987601598\n",
            "epoch:  1226  loss:  0.17645237014007595  accuracy:  92.69183083069294\n",
            "epoch:  1227  loss:  0.17588186917336687  accuracy:  92.54029480644716\n",
            "epoch:  1228  loss:  0.1780566875518132  accuracy:  92.52651880424301\n",
            "epoch:  1229  loss:  0.17652560374324258  accuracy:  92.44386279101805\n",
            "epoch:  1230  loss:  0.18397668592466568  accuracy:  92.01680672268908\n",
            "epoch:  1231  loss:  0.17578921898253153  accuracy:  92.4920787987326\n",
            "epoch:  1232  loss:  0.1747453011585704  accuracy:  92.80892684942829\n",
            "epoch:  1233  loss:  0.1903990469385415  accuracy:  91.74817467970794\n",
            "epoch:  1234  loss:  0.1840531883025107  accuracy:  92.22344675575148\n",
            "epoch:  1235  loss:  0.17444946022504354  accuracy:  92.76071084171373\n",
            "epoch:  1236  loss:  0.18666243843014763  accuracy:  92.12701474032235\n",
            "epoch:  1237  loss:  0.17114048502196916  accuracy:  92.87091885934701\n",
            "epoch:  1238  loss:  0.18030039255021935  accuracy:  92.34743077558892\n",
            "epoch:  1239  loss:  0.17048627217170012  accuracy:  92.83647885383661\n",
            "epoch:  1240  loss:  0.1748348777668012  accuracy:  92.354318776691\n",
            "epoch:  1241  loss:  0.1763480999964396  accuracy:  92.64361482297838\n",
            "epoch:  1242  loss:  0.17182112350405077  accuracy:  92.79515084722414\n",
            "epoch:  1243  loss:  0.17647039757576802  accuracy:  92.55407080865133\n",
            "epoch:  1244  loss:  0.1718273738319346  accuracy:  92.72627083620334\n",
            "epoch:  1245  loss:  0.17557437480715357  accuracy:  92.52651880424301\n",
            "epoch:  1246  loss:  0.18337990420755398  accuracy:  92.09946273591403\n",
            "epoch:  1247  loss:  0.18502545577630078  accuracy:  92.4576387932222\n",
            "epoch:  1248  loss:  0.18666894755870583  accuracy:  92.09257473481196\n",
            "epoch:  1249  loss:  0.17480918912971163  accuracy:  92.49896679983469\n",
            "epoch:  1250  loss:  0.182450962540433  accuracy:  92.10635073701611\n",
            "epoch:  1251  loss:  0.17181289737436262  accuracy:  92.61606281857006\n",
            "epoch:  1252  loss:  0.17328874126768487  accuracy:  92.5953988152638\n",
            "epoch:  1253  loss:  0.17228564281411235  accuracy:  92.76759884281581\n",
            "epoch:  1254  loss:  0.16741021875179674  accuracy:  92.9466868714699\n",
            "epoch:  1255  loss:  0.17238773895859438  accuracy:  92.78826284612205\n",
            "epoch:  1256  loss:  0.17863796570381033  accuracy:  92.32676677228268\n",
            "epoch:  1257  loss:  0.17113473288430575  accuracy:  92.69871883179502\n",
            "epoch:  1258  loss:  0.16389093605537425  accuracy:  93.00867888138862\n",
            "epoch:  1259  loss:  0.17546467550888192  accuracy:  92.43008678881388\n",
            "epoch:  1260  loss:  0.16621051435793113  accuracy:  93.2222069155531\n",
            "epoch:  1261  loss:  0.17121484257175107  accuracy:  92.82270285163246\n",
            "epoch:  1262  loss:  0.16941818120431468  accuracy:  92.85025485604078\n",
            "epoch:  1263  loss:  0.1706699132067406  accuracy:  92.85025485604078\n",
            "epoch:  1264  loss:  0.1713382568133897  accuracy:  92.78137484501997\n",
            "epoch:  1265  loss:  0.1924524337118988  accuracy:  91.78261468521835\n",
            "epoch:  1266  loss:  0.17284494932196426  accuracy:  92.73315883730541\n",
            "epoch:  1267  loss:  0.18140064931011082  accuracy:  92.48519079763052\n",
            "epoch:  1268  loss:  0.18484195014599156  accuracy:  92.08568673370988\n",
            "epoch:  1269  loss:  0.1715447130883868  accuracy:  92.60917481746797\n",
            "epoch:  1270  loss:  0.1761553671972074  accuracy:  92.65050282408045\n",
            "epoch:  1271  loss:  0.17225922339915703  accuracy:  92.8433668549387\n",
            "epoch:  1272  loss:  0.1679440075763823  accuracy:  92.91913486706157\n",
            "epoch:  1273  loss:  0.16676337291430238  accuracy:  92.75382284061165\n",
            "epoch:  1274  loss:  0.162731675342606  accuracy:  93.18776691004271\n",
            "epoch:  1275  loss:  0.16274055830168485  accuracy:  93.31863893098223\n",
            "epoch:  1276  loss:  0.1696843808338011  accuracy:  92.70560683289709\n",
            "epoch:  1277  loss:  0.16777097011445097  accuracy:  93.18776691004271\n",
            "epoch:  1278  loss:  0.16505559285037  accuracy:  92.9122468659595\n",
            "epoch:  1279  loss:  0.16669341007701488  accuracy:  93.19465491114478\n",
            "epoch:  1280  loss:  0.16607665814760056  accuracy:  93.04311888689902\n",
            "epoch:  1281  loss:  0.17559921157160546  accuracy:  92.5334068053451\n",
            "epoch:  1282  loss:  0.17476770339167008  accuracy:  92.58851081416174\n",
            "epoch:  1283  loss:  0.16983245332771663  accuracy:  92.48519079763052\n",
            "epoch:  1284  loss:  0.16453752070685887  accuracy:  93.10511089681775\n",
            "epoch:  1285  loss:  0.16357651117428026  accuracy:  93.18087890894063\n",
            "epoch:  1286  loss:  0.16252291246782669  accuracy:  93.06378289020526\n",
            "epoch:  1287  loss:  0.16332795297492714  accuracy:  93.07067089130734\n",
            "epoch:  1288  loss:  0.16831253102055133  accuracy:  92.96735087477614\n",
            "epoch:  1289  loss:  0.18724935787253544  accuracy:  92.06502273040364\n",
            "epoch:  1290  loss:  0.17817805998128938  accuracy:  92.58162281305965\n",
            "epoch:  1291  loss:  0.15785153058872914  accuracy:  93.62859898057583\n",
            "epoch:  1292  loss:  0.16844774897202988  accuracy:  92.79515084722414\n",
            "epoch:  1293  loss:  0.16593209667949083  accuracy:  92.98801487808238\n",
            "epoch:  1294  loss:  0.16769227242955065  accuracy:  92.99490287918447\n",
            "epoch:  1295  loss:  0.15724424282321098  accuracy:  93.27042292326767\n",
            "epoch:  1296  loss:  0.16093531019912802  accuracy:  93.32552693208432\n",
            "epoch:  1297  loss:  0.16485555145752498  accuracy:  93.03623088579694\n",
            "epoch:  1298  loss:  0.16563317557392182  accuracy:  92.9466868714699\n",
            "epoch:  1299  loss:  0.16676192631926282  accuracy:  93.00179088028653\n",
            "epoch:  1300  loss:  0.16648881397253554  accuracy:  93.04311888689902\n",
            "epoch:  1301  loss:  0.16379791690940648  accuracy:  93.0500068880011\n",
            "epoch:  1302  loss:  0.1609288837946977  accuracy:  93.26353492216559\n",
            "epoch:  1303  loss:  0.16365087599399777  accuracy:  93.02245488359279\n",
            "epoch:  1304  loss:  0.15231194067348675  accuracy:  93.62859898057583\n",
            "epoch:  1305  loss:  0.16997380370951862  accuracy:  92.62983882077421\n",
            "epoch:  1306  loss:  0.1650461108108282  accuracy:  93.00179088028653\n",
            "epoch:  1307  loss:  0.15718187075115989  accuracy:  93.37374293979887\n",
            "epoch:  1308  loss:  0.16721627069605105  accuracy:  92.8433668549387\n",
            "epoch:  1309  loss:  0.16643787469478297  accuracy:  92.92602286816366\n",
            "epoch:  1310  loss:  0.15981137659849748  accuracy:  93.19465491114478\n",
            "epoch:  1311  loss:  0.16210320739316486  accuracy:  93.0844468935115\n",
            "epoch:  1312  loss:  0.17074131593877973  accuracy:  92.66427882628462\n",
            "epoch:  1313  loss:  0.1604642638166075  accuracy:  93.2222069155531\n",
            "epoch:  1314  loss:  0.17229917466759534  accuracy:  92.71938283510126\n",
            "epoch:  1315  loss:  0.15964267129559115  accuracy:  93.19465491114478\n",
            "epoch:  1316  loss:  0.15186705434227107  accuracy:  93.51839096294255\n",
            "epoch:  1317  loss:  0.15496371741883763  accuracy:  93.77324700371952\n",
            "epoch:  1318  loss:  0.1688502197955607  accuracy:  92.71249483399917\n",
            "epoch:  1319  loss:  0.15717392342960823  accuracy:  93.5390549662488\n",
            "epoch:  1320  loss:  0.1528018788108814  accuracy:  93.76635900261743\n",
            "epoch:  1321  loss:  0.15523522300408357  accuracy:  93.82146301143408\n",
            "epoch:  1322  loss:  0.1662335861579481  accuracy:  92.89847086375534\n",
            "epoch:  1323  loss:  0.1626801738544492  accuracy:  93.17399090783854\n",
            "epoch:  1324  loss:  0.16414608377750328  accuracy:  93.13266290122607\n",
            "epoch:  1325  loss:  0.16673849910838429  accuracy:  92.92602286816366\n",
            "epoch:  1326  loss:  0.15594853653134616  accuracy:  93.58727097396336\n",
            "epoch:  1327  loss:  0.14911484066871658  accuracy:  93.75947100151537\n",
            "epoch:  1328  loss:  0.16508279804857265  accuracy:  92.93291086926574\n",
            "epoch:  1329  loss:  0.17068949993943558  accuracy:  92.92602286816366\n",
            "epoch:  1330  loss:  0.1580525238884433  accuracy:  93.42195894751343\n",
            "epoch:  1331  loss:  0.15966175876548588  accuracy:  93.4012949442072\n",
            "epoch:  1332  loss:  0.15123043539196782  accuracy:  93.59415897506544\n",
            "epoch:  1333  loss:  0.14841797604658072  accuracy:  93.97299903567985\n",
            "epoch:  1334  loss:  0.15030534103264376  accuracy:  93.83523901363824\n",
            "epoch:  1335  loss:  0.17461101848230265  accuracy:  92.65050282408045\n",
            "epoch:  1336  loss:  0.18567748697155648  accuracy:  92.27166276346604\n",
            "epoch:  1337  loss:  0.15437771179801194  accuracy:  93.78702300592369\n",
            "epoch:  1338  loss:  0.16192255493082575  accuracy:  93.23598291775727\n",
            "epoch:  1339  loss:  0.15248778796603257  accuracy:  93.4357349497176\n",
            "epoch:  1340  loss:  0.15504554113498123  accuracy:  93.44951095192175\n",
            "epoch:  1341  loss:  0.1524099448264951  accuracy:  93.57349497175919\n",
            "epoch:  1342  loss:  0.1545713866014818  accuracy:  93.52527896404463\n",
            "epoch:  1343  loss:  0.1563254078424967  accuracy:  93.76635900261743\n",
            "epoch:  1344  loss:  0.1511237168688964  accuracy:  93.52527896404463\n",
            "epoch:  1345  loss:  0.1503573284035528  accuracy:  93.57349497175919\n",
            "epoch:  1346  loss:  0.14451891846594558  accuracy:  94.18652706984433\n",
            "epoch:  1347  loss:  0.15395104716978283  accuracy:  93.33930293428847\n",
            "epoch:  1348  loss:  0.15213188904160918  accuracy:  93.86279101804656\n",
            "epoch:  1349  loss:  0.1625592915826485  accuracy:  93.04311888689902\n",
            "epoch:  1350  loss:  0.14730190385437353  accuracy:  93.9178950268632\n",
            "epoch:  1351  loss:  0.16395998671743262  accuracy:  93.19465491114478\n",
            "epoch:  1352  loss:  0.1630126149999831  accuracy:  92.9122468659595\n",
            "epoch:  1353  loss:  0.15508592823723785  accuracy:  93.55971896955504\n",
            "epoch:  1354  loss:  0.1482265784008343  accuracy:  93.97988703678193\n",
            "epoch:  1355  loss:  0.1479908834292485  accuracy:  93.89723102355697\n",
            "epoch:  1356  loss:  0.150432469462097  accuracy:  93.73880699820911\n",
            "epoch:  1357  loss:  0.15547621613700685  accuracy:  93.45639895302384\n",
            "epoch:  1358  loss:  0.1702934951986027  accuracy:  92.71249483399917\n",
            "epoch:  1359  loss:  0.1699163802979094  accuracy:  93.13266290122607\n",
            "epoch:  1360  loss:  0.16097317362171606  accuracy:  93.12577490012399\n",
            "epoch:  1361  loss:  0.14934063433188516  accuracy:  93.93855903016944\n",
            "epoch:  1362  loss:  0.1523443181491092  accuracy:  93.68370298939247\n",
            "epoch:  1363  loss:  0.14462820505706678  accuracy:  93.90411902465904\n",
            "epoch:  1364  loss:  0.15638091047718466  accuracy:  93.42195894751343\n",
            "epoch:  1365  loss:  0.15389583939087262  accuracy:  93.77324700371952\n",
            "epoch:  1366  loss:  0.14765705524405298  accuracy:  93.72503099600496\n",
            "epoch:  1367  loss:  0.14631035297448058  accuracy:  93.8834550213528\n",
            "epoch:  1368  loss:  0.15750813291846005  accuracy:  93.47706295633007\n",
            "epoch:  1369  loss:  0.15248358800734252  accuracy:  93.6079349772696\n",
            "epoch:  1370  loss:  0.14097224866076102  accuracy:  94.45515911282546\n",
            "epoch:  1371  loss:  0.14321843685895586  accuracy:  94.20719107315057\n",
            "epoch:  1372  loss:  0.15365426567717844  accuracy:  93.55283096845295\n",
            "epoch:  1373  loss:  0.1537294104676845  accuracy:  93.41507094641135\n",
            "epoch:  1374  loss:  0.14563601144004054  accuracy:  94.11075905772145\n",
            "epoch:  1375  loss:  0.15770389149762215  accuracy:  93.27042292326767\n",
            "epoch:  1376  loss:  0.1407765056801936  accuracy:  94.31739909078385\n",
            "epoch:  1377  loss:  0.14133156696494856  accuracy:  94.31739909078385\n",
            "epoch:  1378  loss:  0.1482859559850861  accuracy:  93.90411902465904\n",
            "epoch:  1379  loss:  0.1408230814903683  accuracy:  94.27607108417138\n",
            "epoch:  1380  loss:  0.14212559431356114  accuracy:  94.17963906874225\n",
            "epoch:  1381  loss:  0.15455361545077695  accuracy:  93.76635900261743\n",
            "epoch:  1382  loss:  0.15207676139416026  accuracy:  93.55283096845295\n",
            "epoch:  1383  loss:  0.14764111509482744  accuracy:  93.92478302796529\n",
            "epoch:  1384  loss:  0.14285232766770942  accuracy:  94.0212150433944\n",
            "epoch:  1385  loss:  0.14077508116900747  accuracy:  94.24163107866097\n",
            "epoch:  1386  loss:  0.15015492730847502  accuracy:  93.6768149882904\n",
            "epoch:  1387  loss:  0.15056072422965924  accuracy:  93.73191899710704\n",
            "epoch:  1388  loss:  0.14415149758864343  accuracy:  94.05565504890481\n",
            "epoch:  1389  loss:  0.15601151784257647  accuracy:  93.41507094641135\n",
            "epoch:  1390  loss:  0.1715324489482672  accuracy:  93.0500068880011\n",
            "epoch:  1391  loss:  0.1612420431075879  accuracy:  93.40818294530928\n",
            "epoch:  1392  loss:  0.15632041420657733  accuracy:  93.51150296184048\n",
            "epoch:  1393  loss:  0.1653768125141943  accuracy:  93.0844468935115\n",
            "epoch:  1394  loss:  0.14771030069152946  accuracy:  93.68370298939247\n",
            "epoch:  1395  loss:  0.1426406996921249  accuracy:  94.1245350599256\n",
            "epoch:  1396  loss:  0.14002984297544047  accuracy:  94.28984708637553\n",
            "epoch:  1397  loss:  0.1399636774893913  accuracy:  94.11764705882354\n",
            "epoch:  1398  loss:  0.14318579732745634  accuracy:  93.91100702576112\n",
            "epoch:  1399  loss:  0.13425349234664288  accuracy:  94.67557514809202\n",
            "epoch:  1400  loss:  0.13986848908620098  accuracy:  94.25540708086513\n",
            "epoch:  1401  loss:  0.13835895705451354  accuracy:  94.2003030720485\n",
            "epoch:  1402  loss:  0.14540168495813108  accuracy:  93.95922303347568\n",
            "epoch:  1403  loss:  0.14286945464033318  accuracy:  93.96611103457776\n",
            "epoch:  1404  loss:  0.14831704553768382  accuracy:  93.92478302796529\n",
            "epoch:  1405  loss:  0.14226644661291388  accuracy:  94.09698305551728\n",
            "epoch:  1406  loss:  0.1472672826593442  accuracy:  94.02810304449649\n",
            "epoch:  1407  loss:  0.14279101149401383  accuracy:  94.25540708086513\n",
            "epoch:  1408  loss:  0.15155716998909832  accuracy:  93.72503099600496\n",
            "epoch:  1409  loss:  0.14557745746261308  accuracy:  94.01432704229232\n",
            "epoch:  1410  loss:  0.1386173812574732  accuracy:  94.11764705882354\n",
            "epoch:  1411  loss:  0.13533582175536693  accuracy:  94.58603113376498\n",
            "epoch:  1412  loss:  0.1456730763326172  accuracy:  94.11764705882354\n",
            "epoch:  1413  loss:  0.14207783353416564  accuracy:  93.9178950268632\n",
            "epoch:  1414  loss:  0.14294839373215332  accuracy:  94.13142306102769\n",
            "epoch:  1415  loss:  0.15510500543499997  accuracy:  93.87656702025072\n",
            "epoch:  1416  loss:  0.18467255031225815  accuracy:  92.50585480093677\n",
            "epoch:  1417  loss:  0.14545892720126238  accuracy:  94.27607108417138\n",
            "epoch:  1418  loss:  0.12898299345837216  accuracy:  94.79267116682739\n",
            "epoch:  1419  loss:  0.1322403435551327  accuracy:  94.62735914037746\n",
            "epoch:  1420  loss:  0.1389425192687741  accuracy:  94.3036230885797\n",
            "epoch:  1421  loss:  0.129861903349293  accuracy:  94.77200716352115\n",
            "epoch:  1422  loss:  0.13220935659658845  accuracy:  94.62735914037746\n",
            "epoch:  1423  loss:  0.13455248922612537  accuracy:  94.59980713596914\n",
            "epoch:  1424  loss:  0.13891496260670086  accuracy:  94.26229508196721\n",
            "epoch:  1425  loss:  0.14629383146442612  accuracy:  93.7801350048216\n",
            "epoch:  1426  loss:  0.1417096246997176  accuracy:  94.04187904670064\n",
            "epoch:  1427  loss:  0.15862118038638168  accuracy:  93.38751894200303\n",
            "epoch:  1428  loss:  0.14592613059966292  accuracy:  93.97988703678193\n",
            "epoch:  1429  loss:  0.13376438935374668  accuracy:  94.6135831381733\n",
            "epoch:  1430  loss:  0.13141672369357  accuracy:  94.57225513156082\n",
            "epoch:  1431  loss:  0.1366609092989126  accuracy:  94.48271111723378\n",
            "epoch:  1432  loss:  0.13687206982061592  accuracy:  94.36561509849841\n",
            "epoch:  1433  loss:  0.13619366198735045  accuracy:  94.44827111172337\n",
            "epoch:  1434  loss:  0.13171309109801332  accuracy:  94.5791431326629\n",
            "epoch:  1435  loss:  0.13952981166922368  accuracy:  94.15208706433393\n",
            "epoch:  1436  loss:  0.13777075895844848  accuracy:  94.42071910731505\n",
            "epoch:  1437  loss:  0.15130091702737727  accuracy:  93.99366303898609\n",
            "epoch:  1438  loss:  0.16728189278751682  accuracy:  93.00867888138862\n",
            "epoch:  1439  loss:  0.14116580201945927  accuracy:  94.04876704780273\n",
            "epoch:  1440  loss:  0.13403465182414345  accuracy:  94.46204711392754\n",
            "epoch:  1441  loss:  0.13106541952033857  accuracy:  94.64113514258162\n",
            "epoch:  1442  loss:  0.13288071600817536  accuracy:  94.56536713045874\n",
            "epoch:  1443  loss:  0.13090575912682245  accuracy:  94.64113514258162\n",
            "epoch:  1444  loss:  0.13540594743130818  accuracy:  94.31051108968177\n",
            "epoch:  1445  loss:  0.13473507414110963  accuracy:  94.28984708637553\n",
            "epoch:  1446  loss:  0.1290626659592143  accuracy:  94.86155117784818\n",
            "epoch:  1447  loss:  0.1292966940304369  accuracy:  94.66868714698994\n",
            "epoch:  1448  loss:  0.1345894082273222  accuracy:  94.2691830830693\n",
            "epoch:  1449  loss:  0.1368043529330855  accuracy:  94.38627910180466\n",
            "epoch:  1450  loss:  0.13865318704298465  accuracy:  94.3036230885797\n",
            "epoch:  1451  loss:  0.14281281325742878  accuracy:  93.99366303898609\n",
            "epoch:  1452  loss:  0.1410023868053162  accuracy:  94.34495109519217\n",
            "epoch:  1453  loss:  0.15526577850431922  accuracy:  93.61482297837168\n",
            "epoch:  1454  loss:  0.1463418152305948  accuracy:  94.08320705331313\n",
            "epoch:  1455  loss:  0.16141826882886565  accuracy:  93.30486292877806\n",
            "epoch:  1456  loss:  0.14011067519779621  accuracy:  94.35183909629426\n",
            "epoch:  1457  loss:  0.12931310823837708  accuracy:  94.85466317674612\n",
            "epoch:  1458  loss:  0.12611407364247373  accuracy:  95.11640721862516\n",
            "epoch:  1459  loss:  0.12993771444227614  accuracy:  94.71001515360243\n",
            "epoch:  1460  loss:  0.1324655782138329  accuracy:  94.51715112274418\n",
            "epoch:  1461  loss:  0.1344908924152625  accuracy:  94.40005510400881\n",
            "epoch:  1462  loss:  0.1337873628248827  accuracy:  94.34495109519217\n",
            "epoch:  1463  loss:  0.13023343342553323  accuracy:  94.79955916792947\n",
            "epoch:  1464  loss:  0.1265583027896802  accuracy:  94.69623915139826\n",
            "epoch:  1465  loss:  0.1256917038895749  accuracy:  94.930431188869\n",
            "epoch:  1466  loss:  0.1278235198954796  accuracy:  94.93731918997106\n",
            "epoch:  1467  loss:  0.1403126584162995  accuracy:  94.09698305551728\n",
            "epoch:  1468  loss:  0.1363159175282225  accuracy:  94.66179914588787\n",
            "epoch:  1469  loss:  0.12927702398446494  accuracy:  94.95798319327731\n",
            "epoch:  1470  loss:  0.12923393195349006  accuracy:  94.6824631491941\n",
            "epoch:  1471  loss:  0.1480483379538829  accuracy:  94.0625430500069\n",
            "epoch:  1472  loss:  0.14367336385082422  accuracy:  94.25540708086513\n",
            "epoch:  1473  loss:  0.13673416423153445  accuracy:  94.25540708086513\n",
            "epoch:  1474  loss:  0.1349991943986394  accuracy:  94.52403912384626\n",
            "epoch:  1475  loss:  0.12118870915029312  accuracy:  95.21972723515636\n",
            "epoch:  1476  loss:  0.12417597971104248  accuracy:  94.84088717454195\n",
            "epoch:  1477  loss:  0.12476464672462394  accuracy:  94.91665518666483\n",
            "epoch:  1478  loss:  0.13479924788343164  accuracy:  94.18652706984433\n",
            "epoch:  1479  loss:  0.1308488422366587  accuracy:  94.53092712494833\n",
            "epoch:  1480  loss:  0.1305312450489183  accuracy:  94.66179914588787\n",
            "epoch:  1481  loss:  0.13242686100387263  accuracy:  94.58603113376498\n",
            "epoch:  1482  loss:  0.14172585591528103  accuracy:  94.04876704780273\n",
            "epoch:  1483  loss:  0.12561026986065868  accuracy:  94.90976718556276\n",
            "epoch:  1484  loss:  0.12908258020697194  accuracy:  94.7513431602149\n",
            "epoch:  1485  loss:  0.1474952781189324  accuracy:  93.99366303898609\n",
            "epoch:  1486  loss:  0.12518672304996972  accuracy:  95.14395922303348\n",
            "epoch:  1487  loss:  0.12683909879372557  accuracy:  95.17839922854388\n",
            "epoch:  1488  loss:  0.12158015537055042  accuracy:  95.07507921201267\n",
            "epoch:  1489  loss:  0.13309666135247408  accuracy:  94.52403912384626\n",
            "epoch:  1490  loss:  0.12970265212700638  accuracy:  94.6135831381733\n",
            "epoch:  1491  loss:  0.13695818787015474  accuracy:  94.2003030720485\n",
            "epoch:  1492  loss:  0.12981499498344384  accuracy:  94.60669513707123\n",
            "epoch:  1493  loss:  0.12247414575133513  accuracy:  95.11640721862516\n",
            "epoch:  1494  loss:  0.13276380213483796  accuracy:  94.60669513707123\n",
            "epoch:  1495  loss:  0.1256093638135039  accuracy:  94.83399917343986\n",
            "epoch:  1496  loss:  0.11723238756803954  accuracy:  95.35059925609588\n",
            "epoch:  1497  loss:  0.12962439111859234  accuracy:  94.73067915690866\n",
            "epoch:  1498  loss:  0.12147465087488789  accuracy:  95.24039123846259\n",
            "epoch:  1499  loss:  0.11834963565616095  accuracy:  95.25416724066676\n",
            "epoch:  1500  loss:  0.11900060291846341  accuracy:  95.3437112549938\n",
            "epoch:  1501  loss:  0.1313487787160446  accuracy:  94.49648711943794\n",
            "epoch:  1502  loss:  0.12646839820707628  accuracy:  94.77889516462322\n",
            "epoch:  1503  loss:  0.1320877544343767  accuracy:  94.6824631491941\n",
            "epoch:  1504  loss:  0.13569870417908642  accuracy:  94.59980713596914\n",
            "epoch:  1505  loss:  0.12461859491664133  accuracy:  94.97175919548147\n",
            "epoch:  1506  loss:  0.13062120754210677  accuracy:  94.73067915690866\n",
            "epoch:  1507  loss:  0.13512720402731992  accuracy:  94.2691830830693\n",
            "epoch:  1508  loss:  0.12167288940787348  accuracy:  95.00619920099187\n",
            "epoch:  1509  loss:  0.12505595182289447  accuracy:  94.75823116131698\n",
            "epoch:  1510  loss:  0.12202510677348863  accuracy:  95.01308720209396\n",
            "epoch:  1511  loss:  0.11945196218149182  accuracy:  95.23350323736052\n",
            "epoch:  1512  loss:  0.12229138603817581  accuracy:  95.12329521972724\n",
            "epoch:  1513  loss:  0.135850391410089  accuracy:  94.39316710290673\n",
            "epoch:  1514  loss:  0.12389487552249098  accuracy:  94.9924231987877\n",
            "epoch:  1515  loss:  0.13484520074490722  accuracy:  94.67557514809202\n",
            "epoch:  1516  loss:  0.13336658582321242  accuracy:  94.58603113376498\n",
            "epoch:  1517  loss:  0.13291202936763358  accuracy:  94.51715112274418\n",
            "epoch:  1518  loss:  0.11413669281086575  accuracy:  95.48835927813748\n",
            "epoch:  1519  loss:  0.1296807914322599  accuracy:  94.86155117784818\n",
            "epoch:  1520  loss:  0.13968426484025975  accuracy:  94.31739909078385\n",
            "epoch:  1521  loss:  0.12227956795730625  accuracy:  95.38503926160628\n",
            "epoch:  1522  loss:  0.13416628396021282  accuracy:  94.46893511502962\n",
            "epoch:  1523  loss:  0.119401575554327  accuracy:  95.01308720209396\n",
            "epoch:  1524  loss:  0.11744273874515064  accuracy:  95.31615925058549\n",
            "epoch:  1525  loss:  0.11761176671700908  accuracy:  95.42636726821877\n",
            "epoch:  1526  loss:  0.12000674806983777  accuracy:  95.4125912660146\n",
            "epoch:  1527  loss:  0.12013356152981959  accuracy:  95.16462322633971\n",
            "epoch:  1528  loss:  0.1319385058315706  accuracy:  94.71690315470451\n",
            "epoch:  1529  loss:  0.15418737520567558  accuracy:  93.6768149882904\n",
            "epoch:  1530  loss:  0.13541472786458864  accuracy:  94.59291913486706\n",
            "epoch:  1531  loss:  0.11675121490887858  accuracy:  95.30238324838132\n",
            "epoch:  1532  loss:  0.11251370385001802  accuracy:  95.66055930568949\n",
            "epoch:  1533  loss:  0.11467893894252197  accuracy:  95.48835927813748\n",
            "epoch:  1534  loss:  0.12234101709959132  accuracy:  94.99931119988979\n",
            "epoch:  1535  loss:  0.11719265818120667  accuracy:  95.41947926711669\n",
            "epoch:  1536  loss:  0.12138880605914981  accuracy:  95.23350323736052\n",
            "epoch:  1537  loss:  0.12148078961752305  accuracy:  95.15773522523763\n",
            "epoch:  1538  loss:  0.11488358805399737  accuracy:  95.46080727372916\n",
            "epoch:  1539  loss:  0.11819828404769259  accuracy:  95.33682325389172\n",
            "epoch:  1540  loss:  0.11236442656006461  accuracy:  95.58479129356661\n",
            "epoch:  1541  loss:  0.11979643483485199  accuracy:  95.2059512329522\n",
            "epoch:  1542  loss:  0.11056363083989779  accuracy:  95.68122330899573\n",
            "epoch:  1543  loss:  0.11650314134110562  accuracy:  95.43325526932084\n",
            "epoch:  1544  loss:  0.12248775429581295  accuracy:  94.8271111723378\n",
            "epoch:  1545  loss:  0.12595432356435138  accuracy:  95.02686320429811\n",
            "epoch:  1546  loss:  0.1414416511910672  accuracy:  94.11764705882354\n",
            "epoch:  1547  loss:  0.12178142682561567  accuracy:  95.2059512329522\n",
            "epoch:  1548  loss:  0.1277488782937237  accuracy:  94.98553519768564\n",
            "epoch:  1549  loss:  0.14001692737396107  accuracy:  94.27607108417138\n",
            "epoch:  1550  loss:  0.11572660870654046  accuracy:  95.57101529136244\n",
            "epoch:  1551  loss:  0.11896217078019772  accuracy:  95.22661523625844\n",
            "epoch:  1552  loss:  0.11657462935196268  accuracy:  95.66055930568949\n",
            "epoch:  1553  loss:  0.11643693754907514  accuracy:  95.44014327042292\n",
            "epoch:  1554  loss:  0.11344133841238463  accuracy:  95.46080727372916\n",
            "epoch:  1555  loss:  0.10993723437766888  accuracy:  95.64678330348534\n",
            "epoch:  1556  loss:  0.11134266215686398  accuracy:  95.48147127703541\n",
            "epoch:  1557  loss:  0.11116602360372915  accuracy:  95.70188731230196\n",
            "epoch:  1558  loss:  0.1129906726599495  accuracy:  95.35748725719796\n",
            "epoch:  1559  loss:  0.12331736692087449  accuracy:  94.90287918446067\n",
            "epoch:  1560  loss:  0.11215456445008734  accuracy:  95.48147127703541\n",
            "epoch:  1561  loss:  0.11077476669842423  accuracy:  95.63300730128117\n",
            "epoch:  1562  loss:  0.11869231960566219  accuracy:  95.3437112549938\n",
            "epoch:  1563  loss:  0.11781697821132259  accuracy:  95.28171924507508\n",
            "epoch:  1564  loss:  0.12768751654103203  accuracy:  94.79267116682739\n",
            "epoch:  1565  loss:  0.13291574457619518  accuracy:  94.66868714698994\n",
            "epoch:  1566  loss:  0.11457350400391567  accuracy:  95.41947926711669\n",
            "epoch:  1567  loss:  0.11596205297465954  accuracy:  95.35748725719796\n",
            "epoch:  1568  loss:  0.12017088925165978  accuracy:  95.14395922303348\n",
            "epoch:  1569  loss:  0.11022117170876651  accuracy:  95.48147127703541\n",
            "epoch:  1570  loss:  0.12391578488309515  accuracy:  94.90976718556276\n",
            "epoch:  1571  loss:  0.11218049243464091  accuracy:  95.57101529136244\n",
            "epoch:  1572  loss:  0.10788505054771169  accuracy:  95.77765532442486\n",
            "epoch:  1573  loss:  0.11831852360966613  accuracy:  95.31615925058549\n",
            "epoch:  1574  loss:  0.11224741089120682  accuracy:  95.57790329246453\n",
            "epoch:  1575  loss:  0.12449088391880882  accuracy:  95.10263121642099\n",
            "epoch:  1576  loss:  0.13775037439882074  accuracy:  94.35183909629426\n",
            "epoch:  1577  loss:  0.11712183356685388  accuracy:  95.38503926160628\n",
            "epoch:  1578  loss:  0.11020290551681232  accuracy:  95.75010332001654\n",
            "epoch:  1579  loss:  0.11065734133795611  accuracy:  95.63300730128117\n",
            "epoch:  1580  loss:  0.11362686885472319  accuracy:  95.64678330348534\n",
            "epoch:  1581  loss:  0.10782654835330766  accuracy:  95.81898333103733\n",
            "epoch:  1582  loss:  0.11594254644527335  accuracy:  95.46080727372916\n",
            "epoch:  1583  loss:  0.116115832442418  accuracy:  95.3092712494834\n",
            "epoch:  1584  loss:  0.10502479838820376  accuracy:  95.99807135969142\n",
            "epoch:  1585  loss:  0.12948042141020355  accuracy:  94.51715112274418\n",
            "epoch:  1586  loss:  0.11273718993422627  accuracy:  95.5916792946687\n",
            "epoch:  1587  loss:  0.11223571392871622  accuracy:  95.447031271525\n",
            "epoch:  1588  loss:  0.11542511848651488  accuracy:  95.39881526381045\n",
            "epoch:  1589  loss:  0.11197143512849703  accuracy:  95.70877531340405\n",
            "epoch:  1590  loss:  0.12050370969322698  accuracy:  95.21972723515636\n",
            "epoch:  1591  loss:  0.11734943841751456  accuracy:  95.32304725168756\n",
            "epoch:  1592  loss:  0.10683456609670429  accuracy:  95.81209532993525\n",
            "epoch:  1593  loss:  0.10253609168183  accuracy:  96.17027138724342\n",
            "epoch:  1594  loss:  0.1357906031494036  accuracy:  94.2691830830693\n",
            "epoch:  1595  loss:  0.11036616904610509  accuracy:  95.57101529136244\n",
            "epoch:  1596  loss:  0.10401254630773205  accuracy:  96.16338338614135\n",
            "epoch:  1597  loss:  0.10375333111669048  accuracy:  95.81898333103733\n",
            "epoch:  1598  loss:  0.10343552460961473  accuracy:  95.86031133764982\n",
            "epoch:  1599  loss:  0.11048822722151795  accuracy:  95.47458327593333\n",
            "epoch:  1600  loss:  0.10785687602887076  accuracy:  95.67433530789364\n",
            "epoch:  1601  loss:  0.11677216725478587  accuracy:  95.21972723515636\n",
            "epoch:  1602  loss:  0.17622330451630777  accuracy:  93.16710290673646\n",
            "epoch:  1603  loss:  0.13605642304561374  accuracy:  94.77889516462322\n",
            "epoch:  1604  loss:  0.10790416223481596  accuracy:  95.72943931671028\n",
            "epoch:  1605  loss:  0.10300627090924698  accuracy:  95.86719933875189\n",
            "epoch:  1606  loss:  0.10410558079569641  accuracy:  95.86031133764982\n",
            "epoch:  1607  loss:  0.10328326155619527  accuracy:  95.96363135418102\n",
            "epoch:  1608  loss:  0.1035527871432326  accuracy:  96.06695137071222\n",
            "epoch:  1609  loss:  0.09868186372426575  accuracy:  96.20471139275382\n",
            "epoch:  1610  loss:  0.10675676912736476  accuracy:  95.8327593332415\n",
            "epoch:  1611  loss:  0.09878898542546294  accuracy:  96.1082793773247\n",
            "epoch:  1612  loss:  0.10644761763255464  accuracy:  95.67433530789364\n",
            "epoch:  1613  loss:  0.10162777996314493  accuracy:  96.06006336961013\n",
            "epoch:  1614  loss:  0.1041061383845134  accuracy:  95.8327593332415\n",
            "epoch:  1615  loss:  0.1014965592419983  accuracy:  96.08761537401845\n",
            "epoch:  1616  loss:  0.10919450430520508  accuracy:  95.57101529136244\n",
            "epoch:  1617  loss:  0.1081126188644571  accuracy:  95.68122330899573\n",
            "epoch:  1618  loss:  0.10580577433595793  accuracy:  95.73632731781237\n",
            "epoch:  1619  loss:  0.11279520496288793  accuracy:  95.40570326491252\n",
            "epoch:  1620  loss:  0.11487197354158794  accuracy:  95.32993525278964\n",
            "epoch:  1621  loss:  0.1609487151884888  accuracy:  93.68370298939247\n",
            "epoch:  1622  loss:  0.12163029686755789  accuracy:  95.15084722413556\n",
            "epoch:  1623  loss:  0.10066536379297306  accuracy:  95.98429535748726\n",
            "epoch:  1624  loss:  0.1058146095067316  accuracy:  95.77765532442486\n",
            "epoch:  1625  loss:  0.10513632976694949  accuracy:  95.78454332552693\n",
            "epoch:  1626  loss:  0.10208615273050425  accuracy:  95.77765532442486\n",
            "epoch:  1627  loss:  0.11571249428827057  accuracy:  95.57790329246453\n",
            "epoch:  1628  loss:  0.12390985997848676  accuracy:  95.1370712219314\n",
            "epoch:  1629  loss:  0.10362088662305471  accuracy:  96.1082793773247\n",
            "epoch:  1630  loss:  0.10467993147093364  accuracy:  95.92230334756853\n",
            "epoch:  1631  loss:  0.10354139347602914  accuracy:  95.9705193552831\n",
            "epoch:  1632  loss:  0.09658804897463737  accuracy:  96.34247141479543\n",
            "epoch:  1633  loss:  0.10766428663920216  accuracy:  95.63989530238325\n",
            "epoch:  1634  loss:  0.09619681382063483  accuracy:  96.52844744455159\n",
            "epoch:  1635  loss:  0.10496667850537313  accuracy:  95.77765532442486\n",
            "epoch:  1636  loss:  0.10137036871275375  accuracy:  96.02562336409974\n",
            "epoch:  1637  loss:  0.10310834964201263  accuracy:  95.94985535197685\n",
            "epoch:  1638  loss:  0.11215432613260787  accuracy:  95.60545529687285\n",
            "epoch:  1639  loss:  0.10679071932750878  accuracy:  95.74321531891445\n",
            "epoch:  1640  loss:  0.12269025859564753  accuracy:  95.10951921752307\n",
            "epoch:  1641  loss:  0.10641098869952934  accuracy:  95.94296735087478\n",
            "epoch:  1642  loss:  0.11587722083795644  accuracy:  95.5159112825458\n",
            "epoch:  1643  loss:  0.1205230886615707  accuracy:  95.48835927813748\n",
            "epoch:  1644  loss:  0.10383393299971291  accuracy:  96.05317536850806\n",
            "epoch:  1645  loss:  0.09606066260310815  accuracy:  96.39757542361207\n",
            "epoch:  1646  loss:  0.09763193881350339  accuracy:  96.18404738944758\n",
            "epoch:  1647  loss:  0.09658828401176754  accuracy:  96.23915139826423\n",
            "epoch:  1648  loss:  0.09626079216201225  accuracy:  96.32869541259127\n",
            "epoch:  1649  loss:  0.10015732369355253  accuracy:  96.09450337512054\n",
            "epoch:  1650  loss:  0.0999503072973724  accuracy:  95.99807135969142\n",
            "epoch:  1651  loss:  0.10722625324866186  accuracy:  95.61234329797493\n",
            "epoch:  1652  loss:  0.09872206734147737  accuracy:  96.22537539606006\n",
            "epoch:  1653  loss:  0.11208926291885102  accuracy:  95.39881526381045\n",
            "epoch:  1654  loss:  0.1142694261261198  accuracy:  95.25416724066676\n",
            "epoch:  1655  loss:  0.10322262370146278  accuracy:  96.08761537401845\n",
            "epoch:  1656  loss:  0.13527105075494122  accuracy:  94.72379115580658\n",
            "epoch:  1657  loss:  0.11753443272083583  accuracy:  95.28171924507508\n",
            "epoch:  1658  loss:  0.10784019273785968  accuracy:  95.85342333654773\n",
            "epoch:  1659  loss:  0.11454613120562611  accuracy:  95.5503512880562\n",
            "epoch:  1660  loss:  0.10250557151411761  accuracy:  96.08072737291639\n",
            "epoch:  1661  loss:  0.09930585836882613  accuracy:  96.36313541810166\n",
            "epoch:  1662  loss:  0.09243039010657901  accuracy:  96.49400743904118\n",
            "epoch:  1663  loss:  0.0943750986796812  accuracy:  96.48711943793911\n",
            "epoch:  1664  loss:  0.09727393533356558  accuracy:  96.29425540708087\n",
            "epoch:  1665  loss:  0.10219750683977923  accuracy:  96.03251136520181\n",
            "epoch:  1666  loss:  0.10422044798664062  accuracy:  95.74321531891445\n",
            "epoch:  1667  loss:  0.1077238305785272  accuracy:  95.64678330348534\n",
            "epoch:  1668  loss:  0.10669294641526265  accuracy:  95.81898333103733\n",
            "epoch:  1669  loss:  0.10478131931861713  accuracy:  95.88786334205814\n",
            "epoch:  1670  loss:  0.11971126833653742  accuracy:  95.0337512054002\n",
            "epoch:  1671  loss:  0.1364539314843001  accuracy:  94.88221518115444\n",
            "epoch:  1672  loss:  0.10227836268147107  accuracy:  95.99807135969142\n",
            "epoch:  1673  loss:  0.09574163131100742  accuracy:  96.32180741148919\n",
            "epoch:  1674  loss:  0.09523299486902499  accuracy:  96.25292740046838\n",
            "epoch:  1675  loss:  0.10088841036682632  accuracy:  95.92919134867061\n",
            "epoch:  1676  loss:  0.09580969478961177  accuracy:  96.28736740597878\n",
            "epoch:  1677  loss:  0.09770900225475941  accuracy:  96.23226339716214\n",
            "epoch:  1678  loss:  0.09414608688043044  accuracy:  96.57666345226615\n",
            "epoch:  1679  loss:  0.08989911700979558  accuracy:  96.62487945998072\n",
            "epoch:  1680  loss:  0.0936560051482084  accuracy:  96.2115993938559\n",
            "epoch:  1681  loss:  0.0907487062713482  accuracy:  96.54222344675576\n",
            "epoch:  1682  loss:  0.09341827986159179  accuracy:  96.30803140928502\n",
            "epoch:  1683  loss:  0.10480686083009033  accuracy:  95.94985535197685\n",
            "epoch:  1684  loss:  0.15030548461361487  accuracy:  93.93167102906736\n",
            "epoch:  1685  loss:  0.10093037874678686  accuracy:  96.04628736740598\n",
            "epoch:  1686  loss:  0.10073193308683955  accuracy:  96.0738393718143\n",
            "epoch:  1687  loss:  0.09301320910053504  accuracy:  96.51467144234744\n",
            "epoch:  1688  loss:  0.10053164727256095  accuracy:  95.86719933875189\n",
            "epoch:  1689  loss:  0.08864442050099816  accuracy:  96.75575148092024\n",
            "epoch:  1690  loss:  0.09922050632498434  accuracy:  96.16338338614135\n",
            "epoch:  1691  loss:  0.09974874566585125  accuracy:  96.06006336961013\n",
            "epoch:  1692  loss:  0.09711270555053257  accuracy:  96.08761537401845\n",
            "epoch:  1693  loss:  0.0907962474043638  accuracy:  96.5215594434495\n",
            "epoch:  1694  loss:  0.10301508210350009  accuracy:  95.88786334205814\n",
            "epoch:  1695  loss:  0.09884427618227652  accuracy:  95.95674335307893\n",
            "epoch:  1696  loss:  0.09399844847649298  accuracy:  96.45267943242871\n",
            "epoch:  1697  loss:  0.11080579469110013  accuracy:  95.57101529136244\n",
            "epoch:  1698  loss:  0.11137331035981199  accuracy:  95.89475134316021\n",
            "epoch:  1699  loss:  0.12474229868554285  accuracy:  95.00619920099187\n",
            "epoch:  1700  loss:  0.11472383649427793  accuracy:  95.71566331450613\n",
            "epoch:  1701  loss:  0.09468343501333479  accuracy:  96.63176746108279\n",
            "epoch:  1702  loss:  0.08760464364486484  accuracy:  96.59043945447031\n",
            "epoch:  1703  loss:  0.08724928204956044  accuracy:  96.60421545667447\n",
            "epoch:  1704  loss:  0.09313560815104392  accuracy:  96.26670340267255\n",
            "epoch:  1705  loss:  0.08716373614744143  accuracy:  96.74886347981816\n",
            "epoch:  1706  loss:  0.09230925074458647  accuracy:  96.48711943793911\n",
            "epoch:  1707  loss:  0.08905872719431403  accuracy:  96.53533544565367\n",
            "epoch:  1708  loss:  0.09175619352385679  accuracy:  96.3837994214079\n",
            "epoch:  1709  loss:  0.10054733078218078  accuracy:  95.94296735087478\n",
            "epoch:  1710  loss:  0.104675130922471  accuracy:  95.91541534646646\n",
            "epoch:  1711  loss:  0.10308006368828947  accuracy:  96.23226339716214\n",
            "epoch:  1712  loss:  0.10183828765890013  accuracy:  95.82587133213941\n",
            "epoch:  1713  loss:  0.12960133192677656  accuracy:  94.82022317123571\n",
            "epoch:  1714  loss:  0.12240166147088755  accuracy:  95.50902328144373\n",
            "epoch:  1715  loss:  0.09405549998517157  accuracy:  96.3149194103871\n",
            "epoch:  1716  loss:  0.08817450940492996  accuracy:  96.76263948202232\n",
            "epoch:  1717  loss:  0.08612987233133647  accuracy:  96.75575148092024\n",
            "epoch:  1718  loss:  0.09347627545038618  accuracy:  96.30803140928502\n",
            "epoch:  1719  loss:  0.08725004344726991  accuracy:  96.72131147540983\n",
            "epoch:  1720  loss:  0.08619924012085577  accuracy:  96.81085548973688\n",
            "epoch:  1721  loss:  0.08477527358460023  accuracy:  96.74886347981816\n",
            "epoch:  1722  loss:  0.09687535235775553  accuracy:  96.09450337512054\n",
            "epoch:  1723  loss:  0.10151364904229085  accuracy:  96.05317536850806\n",
            "epoch:  1724  loss:  0.09751770184324668  accuracy:  96.24603939936631\n",
            "epoch:  1725  loss:  0.09484013805545909  accuracy:  96.37002341920375\n",
            "epoch:  1726  loss:  0.11589398023645844  accuracy:  95.47458327593333\n",
            "epoch:  1727  loss:  0.11145662659588539  accuracy:  95.62611930017908\n",
            "epoch:  1728  loss:  0.10696683330316405  accuracy:  96.01184736189558\n",
            "epoch:  1729  loss:  0.10019452693250032  accuracy:  96.01873536299766\n",
            "epoch:  1730  loss:  0.1010511351551977  accuracy:  96.03251136520181\n",
            "epoch:  1731  loss:  0.08490864573299828  accuracy:  96.8728474996556\n",
            "epoch:  1732  loss:  0.09359112826465558  accuracy:  96.30114340818295\n",
            "epoch:  1733  loss:  0.08492517843637228  accuracy:  96.85907149745144\n",
            "epoch:  1734  loss:  0.08697478677181932  accuracy:  96.69375947100151\n",
            "epoch:  1735  loss:  0.08493167493466192  accuracy:  96.65243146438904\n",
            "epoch:  1736  loss:  0.08796777811405875  accuracy:  96.74197547871607\n",
            "epoch:  1737  loss:  0.08518843094041187  accuracy:  96.67998346879736\n",
            "epoch:  1738  loss:  0.0881647255904444  accuracy:  96.51467144234744\n",
            "epoch:  1739  loss:  0.10405883561593472  accuracy:  95.72255131560821\n",
            "epoch:  1740  loss:  0.09677666740602067  accuracy:  96.05317536850806\n",
            "epoch:  1741  loss:  0.08833866641294909  accuracy:  96.54911144785783\n",
            "epoch:  1742  loss:  0.1389451861075666  accuracy:  94.97864719658355\n",
            "epoch:  1743  loss:  0.13535940372360067  accuracy:  94.75823116131698\n",
            "epoch:  1744  loss:  0.09705419260518398  accuracy:  96.18404738944758\n",
            "epoch:  1745  loss:  0.08257995332682457  accuracy:  97.02438352390136\n",
            "epoch:  1746  loss:  0.08392807964468021  accuracy:  96.92106350737016\n",
            "epoch:  1747  loss:  0.09010313593240164  accuracy:  96.51467144234744\n",
            "epoch:  1748  loss:  0.08688421399971641  accuracy:  96.76952748312439\n",
            "epoch:  1749  loss:  0.08728100332343097  accuracy:  96.63865546218487\n",
            "epoch:  1750  loss:  0.07794369151911996  accuracy:  97.16214354594297\n",
            "epoch:  1751  loss:  0.08612006685330505  accuracy:  96.7006474721036\n",
            "epoch:  1752  loss:  0.09109065702942255  accuracy:  96.44579143132663\n",
            "epoch:  1753  loss:  0.08104145803703948  accuracy:  97.12081553933048\n",
            "epoch:  1754  loss:  0.08518908209949917  accuracy:  96.91417550626808\n",
            "epoch:  1755  loss:  0.10970396816346628  accuracy:  95.54346328695412\n",
            "epoch:  1756  loss:  0.10592718796353191  accuracy:  95.9705193552831\n",
            "epoch:  1757  loss:  0.08886711642901535  accuracy:  96.60421545667447\n",
            "epoch:  1758  loss:  0.0923000113695515  accuracy:  96.3562474169996\n",
            "epoch:  1759  loss:  0.08660920812831895  accuracy:  96.67309546769528\n",
            "epoch:  1760  loss:  0.08170573025549767  accuracy:  96.81774349083896\n",
            "epoch:  1761  loss:  0.0787012237067052  accuracy:  97.07259953161592\n",
            "epoch:  1762  loss:  0.08507633835533004  accuracy:  96.86595949855352\n",
            "epoch:  1763  loss:  0.07818182268660946  accuracy:  97.16214354594297\n",
            "epoch:  1764  loss:  0.09043269878337248  accuracy:  96.55599944895991\n",
            "epoch:  1765  loss:  0.0944078271311248  accuracy:  96.16338338614135\n",
            "epoch:  1766  loss:  0.08798913410253426  accuracy:  96.70753547320568\n",
            "epoch:  1767  loss:  0.0892806189635853  accuracy:  96.47334343573495\n",
            "epoch:  1768  loss:  0.09645069783694867  accuracy:  96.22537539606006\n",
            "epoch:  1769  loss:  0.0989477393874404  accuracy:  96.06006336961013\n",
            "epoch:  1770  loss:  0.09440561904702686  accuracy:  96.54911144785783\n",
            "epoch:  1771  loss:  0.09957141544039148  accuracy:  96.12894338063094\n",
            "epoch:  1772  loss:  0.11747819536847588  accuracy:  95.62611930017908\n",
            "epoch:  1773  loss:  0.09968941982921235  accuracy:  96.18404738944758\n",
            "epoch:  1774  loss:  0.10435255870884041  accuracy:  95.98429535748726\n",
            "epoch:  1775  loss:  0.07708653585246557  accuracy:  97.10703953712633\n",
            "epoch:  1776  loss:  0.07930564765209895  accuracy:  97.2241355558617\n",
            "epoch:  1777  loss:  0.08460709982478376  accuracy:  96.75575148092024\n",
            "epoch:  1778  loss:  0.07981415858274403  accuracy:  97.05882352941177\n",
            "epoch:  1779  loss:  0.07921664421921969  accuracy:  97.02438352390136\n",
            "epoch:  1780  loss:  0.08752260482156059  accuracy:  96.54222344675576\n",
            "epoch:  1781  loss:  0.08287298692233028  accuracy:  96.8384074941452\n",
            "epoch:  1782  loss:  0.08131573800182831  accuracy:  96.95550351288057\n",
            "epoch:  1783  loss:  0.0812851507339859  accuracy:  97.13459154153465\n",
            "epoch:  1784  loss:  0.08550193832725603  accuracy:  96.8384074941452\n",
            "epoch:  1785  loss:  0.1114732176465738  accuracy:  95.50902328144373\n",
            "epoch:  1786  loss:  0.1259520905450826  accuracy:  95.21972723515636\n",
            "epoch:  1787  loss:  0.0903823026492504  accuracy:  96.61110345777655\n",
            "epoch:  1788  loss:  0.07984785282583313  accuracy:  97.17591954814712\n",
            "epoch:  1789  loss:  0.07328184066361625  accuracy:  97.43766359002618\n",
            "epoch:  1790  loss:  0.09877141528313958  accuracy:  96.42512742802039\n",
            "epoch:  1791  loss:  0.08197756174231778  accuracy:  96.86595949855352\n",
            "epoch:  1792  loss:  0.08351334011384132  accuracy:  96.79019148643064\n",
            "epoch:  1793  loss:  0.09043153842754856  accuracy:  96.3149194103871\n",
            "epoch:  1794  loss:  0.08380865863070071  accuracy:  96.68687146989943\n",
            "epoch:  1795  loss:  0.07725511680796325  accuracy:  97.24479955916793\n",
            "epoch:  1796  loss:  0.08990409599422365  accuracy:  96.55599944895991\n",
            "epoch:  1797  loss:  0.103144750903811  accuracy:  96.08761537401845\n",
            "epoch:  1798  loss:  0.1370828892239683  accuracy:  94.71690315470451\n",
            "epoch:  1799  loss:  0.09443651411345197  accuracy:  96.28736740597878\n",
            "epoch:  1800  loss:  0.0909282002079206  accuracy:  96.83151949304312\n",
            "epoch:  1801  loss:  0.09332514338771129  accuracy:  96.72131147540983\n",
            "epoch:  1802  loss:  0.08061767100388723  accuracy:  97.27923956467833\n",
            "epoch:  1803  loss:  0.07538617682007  accuracy:  97.15525554484088\n",
            "epoch:  1804  loss:  0.0801982316144251  accuracy:  96.82463149194103\n",
            "epoch:  1805  loss:  0.0923635773255524  accuracy:  96.41135142581622\n",
            "epoch:  1806  loss:  0.08483079692726293  accuracy:  96.8039674886348\n",
            "epoch:  1807  loss:  0.07268716018369316  accuracy:  97.51343160214905\n",
            "epoch:  1808  loss:  0.073533435001762  accuracy:  97.4652155944345\n",
            "epoch:  1809  loss:  0.07109910375083883  accuracy:  97.40322358451577\n",
            "epoch:  1810  loss:  0.07956496710431142  accuracy:  96.907287505166\n",
            "epoch:  1811  loss:  0.07861216421818862  accuracy:  96.96927951508472\n",
            "epoch:  1812  loss:  0.07634167600115693  accuracy:  97.08637553382009\n",
            "epoch:  1813  loss:  0.07648005586244265  accuracy:  97.21724755475961\n",
            "epoch:  1814  loss:  0.07759510865531229  accuracy:  97.2861275657804\n",
            "epoch:  1815  loss:  0.07430049178593004  accuracy:  97.24479955916793\n",
            "epoch:  1816  loss:  0.09506860286441819  accuracy:  96.15649538503926\n",
            "epoch:  1817  loss:  0.15318198782371448  accuracy:  94.3725030996005\n",
            "epoch:  1818  loss:  0.16541961634862373  accuracy:  93.80079900812784\n",
            "epoch:  1819  loss:  0.07792734262718365  accuracy:  97.34123157459705\n",
            "epoch:  1820  loss:  0.07124621548833211  accuracy:  97.47899159663865\n",
            "epoch:  1821  loss:  0.07051357045053269  accuracy:  97.50654360104697\n",
            "epoch:  1822  loss:  0.07082238450173234  accuracy:  97.32056757129081\n",
            "epoch:  1823  loss:  0.07246166582622547  accuracy:  97.41011158561786\n",
            "epoch:  1824  loss:  0.07518034224978475  accuracy:  97.23102355696376\n",
            "epoch:  1825  loss:  0.07206338056469526  accuracy:  97.38944758231162\n",
            "epoch:  1826  loss:  0.07170176279492074  accuracy:  97.52031960325114\n",
            "epoch:  1827  loss:  0.07755793971736366  accuracy:  97.15525554484088\n",
            "epoch:  1828  loss:  0.07463015208231473  accuracy:  97.27235156357625\n",
            "epoch:  1829  loss:  0.08267091422142002  accuracy:  96.69375947100151\n",
            "epoch:  1830  loss:  0.07428946643262047  accuracy:  97.23102355696376\n",
            "epoch:  1831  loss:  0.07118617525863852  accuracy:  97.4652155944345\n",
            "epoch:  1832  loss:  0.08380545902176655  accuracy:  96.89351150296184\n",
            "epoch:  1833  loss:  0.14099696347648275  accuracy:  94.84777517564403\n",
            "epoch:  1834  loss:  0.09989141605877568  accuracy:  96.20471139275382\n",
            "epoch:  1835  loss:  0.08988317366951687  accuracy:  96.562887450062\n",
            "epoch:  1836  loss:  0.08178745564045098  accuracy:  96.91417550626808\n",
            "epoch:  1837  loss:  0.07226820649787781  accuracy:  97.52720760435322\n",
            "epoch:  1838  loss:  0.0773222786716307  accuracy:  97.24479955916793\n",
            "epoch:  1839  loss:  0.07340456213699974  accuracy:  97.27235156357625\n",
            "epoch:  1840  loss:  0.0728511850098524  accuracy:  97.2241355558617\n",
            "epoch:  1841  loss:  0.07393317156818874  accuracy:  97.2861275657804\n",
            "epoch:  1842  loss:  0.07712869018260844  accuracy:  97.1483675437388\n",
            "epoch:  1843  loss:  0.07333188724064772  accuracy:  97.27923956467833\n",
            "epoch:  1844  loss:  0.10771515087845125  accuracy:  95.78454332552693\n",
            "epoch:  1845  loss:  0.10588727816056656  accuracy:  96.26670340267255\n",
            "epoch:  1846  loss:  0.09130747872991722  accuracy:  96.48711943793911\n",
            "epoch:  1847  loss:  0.0826053654764503  accuracy:  97.03815952610553\n",
            "epoch:  1848  loss:  0.0716016996217724  accuracy:  97.43766359002618\n",
            "epoch:  1849  loss:  0.08380819522388375  accuracy:  96.67998346879736\n",
            "epoch:  1850  loss:  0.0779096678957571  accuracy:  97.25168756027001\n",
            "epoch:  1851  loss:  0.07990942709609807  accuracy:  96.79019148643064\n",
            "epoch:  1852  loss:  0.07035894083986394  accuracy:  97.58231161316986\n",
            "epoch:  1853  loss:  0.07179509052722714  accuracy:  97.35500757680121\n",
            "epoch:  1854  loss:  0.07243148004475795  accuracy:  97.48587959774073\n",
            "epoch:  1855  loss:  0.07547591139851999  accuracy:  97.21724755475961\n",
            "epoch:  1856  loss:  0.07487191092148515  accuracy:  97.20347155255544\n",
            "epoch:  1857  loss:  0.08407032988628854  accuracy:  96.64554346328696\n",
            "epoch:  1858  loss:  0.0973988357701207  accuracy:  96.26670340267255\n",
            "epoch:  1859  loss:  0.11145626885280421  accuracy:  95.85342333654773\n",
            "epoch:  1860  loss:  0.08470896267956825  accuracy:  96.85907149745144\n",
            "epoch:  1861  loss:  0.09112280716123718  accuracy:  96.50778344124535\n",
            "epoch:  1862  loss:  0.07397325598124278  accuracy:  97.39633558341369\n",
            "epoch:  1863  loss:  0.0703974178933066  accuracy:  97.44455159112826\n",
            "epoch:  1864  loss:  0.07912010916515534  accuracy:  97.00371952059513\n",
            "epoch:  1865  loss:  0.06895347316018731  accuracy:  97.4652155944345\n",
            "epoch:  1866  loss:  0.07032938523417925  accuracy:  97.40322358451577\n",
            "epoch:  1867  loss:  0.06992141603279095  accuracy:  97.45832759333241\n",
            "epoch:  1868  loss:  0.08118127456122455  accuracy:  96.77641548422648\n",
            "epoch:  1869  loss:  0.08008935090674277  accuracy:  96.91417550626808\n",
            "epoch:  1870  loss:  0.07652986011547291  accuracy:  97.12081553933048\n",
            "epoch:  1871  loss:  0.0721338369626614  accuracy:  97.40322358451577\n",
            "epoch:  1872  loss:  0.10081348088260098  accuracy:  96.01873536299766\n",
            "epoch:  1873  loss:  0.1634321143954093  accuracy:  93.5046149607384\n",
            "epoch:  1874  loss:  0.09045150893468233  accuracy:  96.63865546218487\n",
            "epoch:  1875  loss:  0.07075347550103513  accuracy:  97.50654360104697\n",
            "epoch:  1876  loss:  0.0662394010425045  accuracy:  97.62363961978234\n",
            "epoch:  1877  loss:  0.06882248516986769  accuracy:  97.52720760435322\n",
            "epoch:  1878  loss:  0.06482181876291214  accuracy:  97.79583964733435\n",
            "epoch:  1879  loss:  0.06619923805194686  accuracy:  97.6374156219865\n",
            "epoch:  1880  loss:  0.07236559102769757  accuracy:  97.49276759884282\n",
            "epoch:  1881  loss:  0.07915315181242728  accuracy:  96.96239151398264\n",
            "epoch:  1882  loss:  0.08009740502593693  accuracy:  97.09326353492217\n",
            "epoch:  1883  loss:  0.0761956129680366  accuracy:  97.10015153602424\n",
            "epoch:  1884  loss:  0.09828329058360184  accuracy:  96.2115993938559\n",
            "epoch:  1885  loss:  0.07401194138613297  accuracy:  97.2861275657804\n",
            "epoch:  1886  loss:  0.06937824434175202  accuracy:  97.52031960325114\n",
            "epoch:  1887  loss:  0.07865455827325118  accuracy:  96.98994351839096\n",
            "epoch:  1888  loss:  0.08666781376816875  accuracy:  96.9761675161868\n",
            "epoch:  1889  loss:  0.08022799477071485  accuracy:  96.92106350737016\n",
            "epoch:  1890  loss:  0.0793453092074974  accuracy:  97.1828075492492\n",
            "epoch:  1891  loss:  0.09310275451696506  accuracy:  96.54911144785783\n",
            "epoch:  1892  loss:  0.08889392601565514  accuracy:  96.63865546218487\n",
            "epoch:  1893  loss:  0.06781295978814827  accuracy:  97.7062956330073\n",
            "epoch:  1894  loss:  0.07235711083233866  accuracy:  97.29990356798457\n",
            "epoch:  1895  loss:  0.06486185106193129  accuracy:  97.59608761537402\n",
            "epoch:  1896  loss:  0.0668298291035519  accuracy:  97.50654360104697\n",
            "epoch:  1897  loss:  0.06544402088235562  accuracy:  97.7062956330073\n",
            "epoch:  1898  loss:  0.0689627799245383  accuracy:  97.52720760435322\n",
            "epoch:  1899  loss:  0.06817850927954568  accuracy:  97.66496762639483\n",
            "epoch:  1900  loss:  0.06441891675127047  accuracy:  97.88538366166138\n",
            "epoch:  1901  loss:  0.08142297152844995  accuracy:  96.99683151949304\n",
            "epoch:  1902  loss:  0.11531241972038923  accuracy:  95.67433530789364\n",
            "epoch:  1903  loss:  0.10790736765441265  accuracy:  95.81898333103733\n",
            "epoch:  1904  loss:  0.07255949297508543  accuracy:  97.38944758231162\n",
            "epoch:  1905  loss:  0.0749404182992973  accuracy:  97.16903154704505\n",
            "epoch:  1906  loss:  0.06959710862830883  accuracy:  97.61675161868025\n",
            "epoch:  1907  loss:  0.07545671345418947  accuracy:  97.06571153051385\n",
            "epoch:  1908  loss:  0.06784307052495395  accuracy:  97.52031960325114\n",
            "epoch:  1909  loss:  0.06187472148076211  accuracy:  97.74762363961979\n",
            "epoch:  1910  loss:  0.0682272206620357  accuracy:  97.52031960325114\n",
            "epoch:  1911  loss:  0.07395659524956129  accuracy:  97.32745557239289\n",
            "epoch:  1912  loss:  0.06529396497696445  accuracy:  97.62363961978234\n",
            "epoch:  1913  loss:  0.06955981145831389  accuracy:  97.34123157459705\n",
            "epoch:  1914  loss:  0.1036579584894528  accuracy:  96.06695137071222\n",
            "epoch:  1915  loss:  0.1166582677463581  accuracy:  95.68811131009781\n",
            "epoch:  1916  loss:  0.07677959831374287  accuracy:  97.24479955916793\n",
            "epoch:  1917  loss:  0.06500013436717195  accuracy:  97.63052762088442\n",
            "epoch:  1918  loss:  0.07273414929914834  accuracy:  97.2241355558617\n",
            "epoch:  1919  loss:  0.06459379170763786  accuracy:  97.71318363410938\n",
            "epoch:  1920  loss:  0.06188118120034194  accuracy:  97.8440556550489\n",
            "epoch:  1921  loss:  0.0616212626312296  accuracy:  97.92671166827387\n",
            "epoch:  1922  loss:  0.061987589398623005  accuracy:  97.82339165174267\n",
            "epoch:  1923  loss:  0.06511247426452084  accuracy:  97.62363961978234\n",
            "epoch:  1924  loss:  0.06470278762758214  accuracy:  97.62363961978234\n",
            "epoch:  1925  loss:  0.062057802122882255  accuracy:  97.8440556550489\n",
            "epoch:  1926  loss:  0.08196871842019428  accuracy:  97.01060752169721\n",
            "epoch:  1927  loss:  0.08633206338295925  accuracy:  96.76952748312439\n",
            "epoch:  1928  loss:  0.12303023926584267  accuracy:  95.79143132662901\n",
            "epoch:  1929  loss:  0.11008630223050847  accuracy:  95.78454332552693\n",
            "epoch:  1930  loss:  0.07642814627666253  accuracy:  97.15525554484088\n",
            "epoch:  1931  loss:  0.05784504664342074  accuracy:  98.15401570464252\n",
            "epoch:  1932  loss:  0.060169419732274784  accuracy:  98.00247968039675\n",
            "epoch:  1933  loss:  0.06869454472001787  accuracy:  97.49276759884282\n",
            "epoch:  1934  loss:  0.06220555175180474  accuracy:  97.67874362859898\n",
            "epoch:  1935  loss:  0.06507927930860878  accuracy:  97.60986361757818\n",
            "epoch:  1936  loss:  0.07429811075116291  accuracy:  97.10015153602424\n",
            "epoch:  1937  loss:  0.07101691960759861  accuracy:  97.32056757129081\n",
            "epoch:  1938  loss:  0.0602071899918136  accuracy:  97.86471965835514\n",
            "epoch:  1939  loss:  0.06922822492408849  accuracy:  97.39633558341369\n",
            "epoch:  1940  loss:  0.07311454025048567  accuracy:  97.2861275657804\n",
            "epoch:  1941  loss:  0.0689339378269017  accuracy:  97.34123157459705\n",
            "epoch:  1942  loss:  0.08861185842181987  accuracy:  96.81774349083896\n",
            "epoch:  1943  loss:  0.1253805814447162  accuracy:  95.35059925609588\n",
            "epoch:  1944  loss:  0.09218846407659555  accuracy:  96.39068742250998\n",
            "epoch:  1945  loss:  0.06534097786109577  accuracy:  97.76828764292603\n",
            "epoch:  1946  loss:  0.06392633043437937  accuracy:  97.72007163521147\n",
            "epoch:  1947  loss:  0.05660921006184674  accuracy:  98.04380768700923\n",
            "epoch:  1948  loss:  0.06570215059416339  accuracy:  97.68563162970106\n",
            "epoch:  1949  loss:  0.06018432981281639  accuracy:  97.87849566055931\n",
            "epoch:  1950  loss:  0.06418376290286223  accuracy:  97.72695963631354\n",
            "epoch:  1951  loss:  0.06007304838134297  accuracy:  97.79583964733435\n",
            "epoch:  1952  loss:  0.0581427985495145  accuracy:  98.08513569362171\n",
            "epoch:  1953  loss:  0.0704700477364319  accuracy:  97.32056757129081\n",
            "epoch:  1954  loss:  0.06565020489246617  accuracy:  97.57542361206778\n",
            "epoch:  1955  loss:  0.06894299254013309  accuracy:  97.45832759333241\n",
            "epoch:  1956  loss:  0.06358908922637949  accuracy:  97.6029756164761\n",
            "epoch:  1957  loss:  0.08694650816347156  accuracy:  96.67309546769528\n",
            "epoch:  1958  loss:  0.11242422311091936  accuracy:  95.85342333654773\n",
            "epoch:  1959  loss:  0.12014512075766878  accuracy:  95.66055930568949\n",
            "epoch:  1960  loss:  0.08374280591828527  accuracy:  96.84529549524729\n",
            "epoch:  1961  loss:  0.06395389670425292  accuracy:  97.78895164623226\n",
            "epoch:  1962  loss:  0.0615725860134114  accuracy:  97.6718556274969\n",
            "epoch:  1963  loss:  0.06107878845756229  accuracy:  97.78206364513018\n",
            "epoch:  1964  loss:  0.0573351278973974  accuracy:  98.07824769251962\n",
            "epoch:  1965  loss:  0.07445268144589602  accuracy:  97.0450475272076\n",
            "epoch:  1966  loss:  0.06453733133412061  accuracy:  97.4996555999449\n",
            "epoch:  1967  loss:  0.06110476445584241  accuracy:  97.8440556550489\n",
            "epoch:  1968  loss:  0.05686768124020901  accuracy:  98.10579969692795\n",
            "epoch:  1969  loss:  0.06191670258618909  accuracy:  97.80272764843643\n",
            "epoch:  1970  loss:  0.08229842802266155  accuracy:  96.76263948202232\n",
            "epoch:  1971  loss:  0.07485009011952226  accuracy:  97.41011158561786\n",
            "epoch:  1972  loss:  0.0813164522424638  accuracy:  96.95550351288057\n",
            "epoch:  1973  loss:  0.08110274192505688  accuracy:  96.98305551728889\n",
            "epoch:  1974  loss:  0.06843395930469726  accuracy:  97.62363961978234\n",
            "epoch:  1975  loss:  0.06296116880608592  accuracy:  97.80272764843643\n",
            "epoch:  1976  loss:  0.06392103032623257  accuracy:  97.78895164623226\n",
            "epoch:  1977  loss:  0.06596128234311575  accuracy:  97.52031960325114\n",
            "epoch:  1978  loss:  0.056954736357295886  accuracy:  98.07135969141756\n",
            "epoch:  1979  loss:  0.05502523004778786  accuracy:  98.03003168480507\n",
            "epoch:  1980  loss:  0.06244110566246877  accuracy:  97.76139964182394\n",
            "epoch:  1981  loss:  0.061027516939750816  accuracy:  97.79583964733435\n",
            "epoch:  1982  loss:  0.07779390305662504  accuracy:  97.12770354043256\n",
            "epoch:  1983  loss:  0.12163703260477055  accuracy:  95.39881526381045\n",
            "epoch:  1984  loss:  0.08846366864592269  accuracy:  96.65243146438904\n",
            "epoch:  1985  loss:  0.07949798234460899  accuracy:  97.18969555035129\n",
            "epoch:  1986  loss:  0.07377807850374558  accuracy:  97.38255958120953\n",
            "epoch:  1987  loss:  0.05757106671794656  accuracy:  97.98870367819259\n",
            "epoch:  1988  loss:  0.06154933896694265  accuracy:  97.72695963631354\n",
            "epoch:  1989  loss:  0.057515128563387995  accuracy:  98.13335170133627\n",
            "epoch:  1990  loss:  0.0587969955892389  accuracy:  97.9129356660697\n",
            "epoch:  1991  loss:  0.05515594456721016  accuracy:  98.14023970243835\n",
            "epoch:  1992  loss:  0.058522476474053356  accuracy:  97.87849566055931\n",
            "epoch:  1993  loss:  0.05665519834488511  accuracy:  97.96115167378427\n",
            "epoch:  1994  loss:  0.06605568193058318  accuracy:  97.63052762088442\n",
            "epoch:  1995  loss:  0.06367741865447844  accuracy:  97.74762363961979\n",
            "epoch:  1996  loss:  0.06801864161408995  accuracy:  97.65119162419066\n",
            "epoch:  1997  loss:  0.07710313798613638  accuracy:  97.36878357900537\n",
            "epoch:  1998  loss:  0.09265159929582018  accuracy:  96.54222344675576\n",
            "epoch:  1999  loss:  0.0734268168049306  accuracy:  97.45143959223033\n",
            "epoch:  2000  loss:  0.06110306734452441  accuracy:  97.8096156495385\n",
            "epoch:  2001  loss:  0.05705668861956074  accuracy:  97.96803967488634\n",
            "epoch:  2002  loss:  0.05748903687249442  accuracy:  97.92671166827387\n",
            "epoch:  2003  loss:  0.05820370036947003  accuracy:  97.9473756715801\n",
            "epoch:  2004  loss:  0.06337918893435775  accuracy:  97.77517564402811\n",
            "epoch:  2005  loss:  0.06740609934662045  accuracy:  97.45143959223033\n",
            "epoch:  2006  loss:  0.06911972701731202  accuracy:  97.55475960876154\n",
            "epoch:  2007  loss:  0.11314172128130498  accuracy:  96.18404738944758\n",
            "epoch:  2008  loss:  0.13601717707485614  accuracy:  95.41947926711669\n",
            "epoch:  2009  loss:  0.06029824959916063  accuracy:  97.78895164623226\n",
            "epoch:  2010  loss:  0.05564023325260036  accuracy:  98.09202369472379\n",
            "epoch:  2011  loss:  0.05422722929217489  accuracy:  98.1264637002342\n",
            "epoch:  2012  loss:  0.052135642708006816  accuracy:  98.32621573219451\n",
            "epoch:  2013  loss:  0.05390220566278467  accuracy:  98.03003168480507\n",
            "epoch:  2014  loss:  0.05454111983223401  accuracy:  97.98870367819259\n",
            "epoch:  2015  loss:  0.05281200845493485  accuracy:  98.25733572117372\n",
            "epoch:  2016  loss:  0.05803327901048435  accuracy:  98.00247968039675\n",
            "epoch:  2017  loss:  0.06871569940348453  accuracy:  97.58231161316986\n",
            "epoch:  2018  loss:  0.06856496982098874  accuracy:  97.29990356798457\n",
            "epoch:  2019  loss:  0.08137533977758106  accuracy:  96.98994351839096\n",
            "epoch:  2020  loss:  0.10690678350339006  accuracy:  96.06695137071222\n",
            "epoch:  2021  loss:  0.065684825686946  accuracy:  97.58919961427193\n",
            "epoch:  2022  loss:  0.055305138776364414  accuracy:  98.09202369472379\n",
            "epoch:  2023  loss:  0.09161912717457842  accuracy:  96.81085548973688\n",
            "epoch:  2024  loss:  0.08089346919639337  accuracy:  97.21035955365753\n",
            "epoch:  2025  loss:  0.06284052283233815  accuracy:  97.93359966937595\n",
            "epoch:  2026  loss:  0.059155514260171765  accuracy:  97.90604766496763\n",
            "epoch:  2027  loss:  0.056533849469569124  accuracy:  97.98181567709051\n",
            "epoch:  2028  loss:  0.051325047177877545  accuracy:  98.25044772007163\n",
            "epoch:  2029  loss:  0.05832744997730144  accuracy:  97.83027965284474\n",
            "epoch:  2030  loss:  0.07321774945656595  accuracy:  97.41699958671994\n",
            "epoch:  2031  loss:  0.06991162322698188  accuracy:  97.31367957018873\n",
            "epoch:  2032  loss:  0.05486584564752775  accuracy:  98.16779170684667\n",
            "epoch:  2033  loss:  0.06315379172811426  accuracy:  97.72695963631354\n",
            "epoch:  2034  loss:  0.06444602068023529  accuracy:  97.59608761537402\n",
            "epoch:  2035  loss:  0.05928051037033131  accuracy:  97.92671166827387\n",
            "epoch:  2036  loss:  0.05635250236080552  accuracy:  98.09202369472379\n",
            "epoch:  2037  loss:  0.09061293638005846  accuracy:  96.72131147540983\n",
            "epoch:  2038  loss:  0.07005151979551325  accuracy:  97.42388758782201\n",
            "epoch:  2039  loss:  0.05163844553441967  accuracy:  98.29866372778619\n",
            "epoch:  2040  loss:  0.05331530222813709  accuracy:  98.09891169582588\n",
            "epoch:  2041  loss:  0.06211956502272622  accuracy:  98.04380768700923\n",
            "epoch:  2042  loss:  0.061185585127309226  accuracy:  97.88538366166138\n",
            "epoch:  2043  loss:  0.05772215852449503  accuracy:  97.9473756715801\n",
            "epoch:  2044  loss:  0.09470807935697166  accuracy:  96.59043945447031\n",
            "epoch:  2045  loss:  0.10115811345247645  accuracy:  96.3562474169996\n",
            "epoch:  2046  loss:  0.07505914164579536  accuracy:  97.23791155806585\n",
            "epoch:  2047  loss:  0.057405090154516725  accuracy:  97.93359966937595\n",
            "epoch:  2048  loss:  0.059871812682444354  accuracy:  97.78206364513018\n",
            "epoch:  2049  loss:  0.057002878715549106  accuracy:  98.10579969692795\n",
            "epoch:  2050  loss:  0.05764178532369579  accuracy:  97.98181567709051\n",
            "epoch:  2051  loss:  0.05814587419568047  accuracy:  97.9473756715801\n",
            "epoch:  2052  loss:  0.06395611664420654  accuracy:  97.6718556274969\n",
            "epoch:  2053  loss:  0.05804170452223564  accuracy:  97.89227166276346\n",
            "epoch:  2054  loss:  0.0571070458840839  accuracy:  98.07824769251962\n",
            "epoch:  2055  loss:  0.06787665040101505  accuracy:  97.54787160765946\n",
            "epoch:  2056  loss:  0.07372571957733969  accuracy:  97.33434357349498\n",
            "epoch:  2057  loss:  0.06869222551742309  accuracy:  97.35500757680121\n",
            "epoch:  2058  loss:  0.06295052421962957  accuracy:  97.78206364513018\n",
            "epoch:  2059  loss:  0.05844847097575155  accuracy:  98.03003168480507\n",
            "epoch:  2060  loss:  0.05856239274213454  accuracy:  97.95426367268219\n",
            "epoch:  2061  loss:  0.052207043680553185  accuracy:  98.2297837167654\n",
            "epoch:  2062  loss:  0.07585481527917172  accuracy:  96.99683151949304\n",
            "epoch:  2063  loss:  0.09304592165701324  accuracy:  96.62487945998072\n",
            "epoch:  2064  loss:  0.0656167565169972  accuracy:  97.69251963080315\n",
            "epoch:  2065  loss:  0.06180302367034649  accuracy:  97.87849566055931\n",
            "epoch:  2066  loss:  0.07094917765480212  accuracy:  97.41011158561786\n",
            "epoch:  2067  loss:  0.06461990446638496  accuracy:  97.6374156219865\n",
            "epoch:  2068  loss:  0.05165644015994717  accuracy:  98.2642237222758\n",
            "epoch:  2069  loss:  0.056422384671342404  accuracy:  98.00936768149883\n",
            "epoch:  2070  loss:  0.06525591105034872  accuracy:  97.54098360655738\n",
            "epoch:  2071  loss:  0.04937639265722899  accuracy:  98.39509574321532\n",
            "epoch:  2072  loss:  0.04692495696876316  accuracy:  98.51219176195069\n",
            "epoch:  2073  loss:  0.0501410679484741  accuracy:  98.28488772558204\n",
            "epoch:  2074  loss:  0.0679391855720386  accuracy:  97.4652155944345\n",
            "epoch:  2075  loss:  0.07206839336771818  accuracy:  97.2861275657804\n",
            "epoch:  2076  loss:  0.06861769525381196  accuracy:  97.47899159663865\n",
            "epoch:  2077  loss:  0.07604123872783965  accuracy:  97.20347155255544\n",
            "epoch:  2078  loss:  0.07209364420750126  accuracy:  97.43766359002618\n",
            "epoch:  2079  loss:  0.0733071962947018  accuracy:  97.47899159663865\n",
            "epoch:  2080  loss:  0.05411730094474486  accuracy:  98.21600771456123\n",
            "epoch:  2081  loss:  0.05110966743223183  accuracy:  98.2297837167654\n",
            "epoch:  2082  loss:  0.05120105167291725  accuracy:  98.27111172337787\n",
            "epoch:  2083  loss:  0.049814841678341173  accuracy:  98.33999173439868\n",
            "epoch:  2084  loss:  0.04931649005030006  accuracy:  98.51907976305276\n",
            "epoch:  2085  loss:  0.053305773771036825  accuracy:  98.15401570464252\n",
            "epoch:  2086  loss:  0.07621463908482753  accuracy:  97.17591954814712\n",
            "epoch:  2087  loss:  0.08293862497817121  accuracy:  96.79707948753271\n",
            "epoch:  2088  loss:  0.05739750256301315  accuracy:  98.00247968039675\n",
            "epoch:  2089  loss:  0.05282276621023466  accuracy:  98.19534371125499\n",
            "epoch:  2090  loss:  0.052757213095656966  accuracy:  98.09202369472379\n",
            "epoch:  2091  loss:  0.0613294495550631  accuracy:  97.85094365615099\n",
            "epoch:  2092  loss:  0.05412960115715991  accuracy:  98.11268769803003\n",
            "epoch:  2093  loss:  0.050695519277499816  accuracy:  98.38131974101115\n",
            "epoch:  2094  loss:  0.05622193634454615  accuracy:  98.07824769251962\n",
            "epoch:  2095  loss:  0.06757866744789058  accuracy:  97.57542361206778\n",
            "epoch:  2096  loss:  0.10813116434797848  accuracy:  96.0393993663039\n",
            "epoch:  2097  loss:  0.115161128608757  accuracy:  96.3837994214079\n",
            "epoch:  2098  loss:  0.06078865645058942  accuracy:  97.75451164072186\n",
            "epoch:  2099  loss:  0.07030809324356352  accuracy:  97.43077558892409\n",
            "epoch:  2100  loss:  0.050140909962089225  accuracy:  98.4708637553382\n",
            "epoch:  2101  loss:  0.05050001919840749  accuracy:  98.03691968590715\n",
            "epoch:  2102  loss:  0.05085972623207021  accuracy:  98.29177572668412\n",
            "epoch:  2103  loss:  0.051654726130607405  accuracy:  98.11957569913211\n",
            "epoch:  2104  loss:  0.0483196096007001  accuracy:  98.31932773109244\n",
            "epoch:  2105  loss:  0.04828765220724057  accuracy:  98.4019837443174\n",
            "epoch:  2106  loss:  0.0535145923840417  accuracy:  98.16779170684667\n",
            "epoch:  2107  loss:  0.07017027634990283  accuracy:  97.37567158010745\n",
            "epoch:  2108  loss:  0.06527175118689704  accuracy:  97.54098360655738\n",
            "epoch:  2109  loss:  0.055374485567055064  accuracy:  97.87160765945723\n",
            "epoch:  2110  loss:  0.05913468941102911  accuracy:  97.87160765945723\n",
            "epoch:  2111  loss:  0.056597486609457806  accuracy:  97.97492767598843\n",
            "epoch:  2112  loss:  0.049821436788411055  accuracy:  98.31932773109244\n",
            "epoch:  2113  loss:  0.05332485621071195  accuracy:  98.17467970794875\n",
            "epoch:  2114  loss:  0.07739936369817017  accuracy:  97.14147954263673\n",
            "epoch:  2115  loss:  0.08159926509091284  accuracy:  96.9761675161868\n",
            "epoch:  2116  loss:  0.08314280721477887  accuracy:  97.03815952610553\n",
            "epoch:  2117  loss:  0.059403533037848906  accuracy:  98.07135969141756\n",
            "epoch:  2118  loss:  0.05323736545007421  accuracy:  98.27799972447995\n",
            "epoch:  2119  loss:  0.05236484264840225  accuracy:  98.24355971896955\n",
            "epoch:  2120  loss:  0.050142372258875856  accuracy:  98.21600771456123\n",
            "epoch:  2121  loss:  0.051940873115541464  accuracy:  98.22289571566331\n",
            "epoch:  2122  loss:  0.04727226623169383  accuracy:  98.367543738807\n",
            "epoch:  2123  loss:  0.049220943466272295  accuracy:  98.29866372778619\n",
            "epoch:  2124  loss:  0.05437153653257218  accuracy:  98.07824769251962\n",
            "epoch:  2125  loss:  0.0514175918239103  accuracy:  98.16779170684667\n",
            "epoch:  2126  loss:  0.04537886748379572  accuracy:  98.51219176195069\n",
            "epoch:  2127  loss:  0.04789594931337833  accuracy:  98.4019837443174\n",
            "epoch:  2128  loss:  0.07102674731882352  accuracy:  97.32745557239289\n",
            "epoch:  2129  loss:  0.10392377228478801  accuracy:  95.9360793497727\n",
            "epoch:  2130  loss:  0.11590545411569501  accuracy:  95.84653533544565\n",
            "epoch:  2131  loss:  0.07567474553660472  accuracy:  97.17591954814712\n",
            "epoch:  2132  loss:  0.05256980929468794  accuracy:  98.33999173439868\n",
            "epoch:  2133  loss:  0.04555943387199128  accuracy:  98.45708775313405\n",
            "epoch:  2134  loss:  0.04488969673028616  accuracy:  98.44331175092988\n",
            "epoch:  2135  loss:  0.04135093026895721  accuracy:  98.76704780272765\n",
            "epoch:  2136  loss:  0.04191888101542127  accuracy:  98.64306378289021\n",
            "epoch:  2137  loss:  0.05735207950373805  accuracy:  97.81650365064058\n",
            "epoch:  2138  loss:  0.05338532657569467  accuracy:  98.18845571015291\n",
            "epoch:  2139  loss:  0.09412769296038848  accuracy:  96.81085548973688\n",
            "epoch:  2140  loss:  0.08134639978381614  accuracy:  97.10703953712633\n",
            "epoch:  2141  loss:  0.06756333202710739  accuracy:  97.58231161316986\n",
            "epoch:  2142  loss:  0.0566510681770121  accuracy:  98.07135969141756\n",
            "epoch:  2143  loss:  0.04334428141945374  accuracy:  98.59484777517564\n",
            "epoch:  2144  loss:  0.054409960154990535  accuracy:  98.1264637002342\n",
            "epoch:  2145  loss:  0.048250063692370566  accuracy:  98.30555172888828\n",
            "epoch:  2146  loss:  0.04450003475844778  accuracy:  98.53285576525693\n",
            "epoch:  2147  loss:  0.04466219863197843  accuracy:  98.58795977407357\n",
            "epoch:  2148  loss:  0.0438731176426365  accuracy:  98.62239977958396\n",
            "epoch:  2149  loss:  0.04592559775184901  accuracy:  98.45708775313405\n",
            "epoch:  2150  loss:  0.046357508908630336  accuracy:  98.31932773109244\n",
            "epoch:  2151  loss:  0.051068721447134334  accuracy:  98.11957569913211\n",
            "epoch:  2152  loss:  0.06157070126388089  accuracy:  97.59608761537402\n",
            "epoch:  2153  loss:  0.06322333178087661  accuracy:  97.85783165725306\n",
            "epoch:  2154  loss:  0.09890759314195745  accuracy:  96.37691142030583\n",
            "epoch:  2155  loss:  0.08527046499407182  accuracy:  96.81085548973688\n",
            "epoch:  2156  loss:  0.06741713366277115  accuracy:  97.33434357349498\n",
            "epoch:  2157  loss:  0.049831244775073176  accuracy:  98.2642237222758\n",
            "epoch:  2158  loss:  0.04251946027378214  accuracy:  98.61551177848189\n",
            "epoch:  2159  loss:  0.04366234309877931  accuracy:  98.53974376635901\n",
            "epoch:  2160  loss:  0.048972922905751996  accuracy:  98.19534371125499\n",
            "epoch:  2161  loss:  0.039432800843088256  accuracy:  98.75327180052349\n",
            "epoch:  2162  loss:  0.049070951768124885  accuracy:  98.31932773109244\n",
            "epoch:  2163  loss:  0.04818211695432605  accuracy:  98.38820774211324\n",
            "epoch:  2164  loss:  0.04673796316873339  accuracy:  98.58795977407357\n",
            "epoch:  2165  loss:  0.05925592692356692  accuracy:  97.88538366166138\n",
            "epoch:  2166  loss:  0.12272110501673  accuracy:  95.68811131009781\n",
            "epoch:  2167  loss:  0.08923872414463675  accuracy:  96.79707948753271\n",
            "epoch:  2168  loss:  0.06181311881304904  accuracy:  97.82339165174267\n",
            "epoch:  2169  loss:  0.05007035621595988  accuracy:  98.34687973550076\n",
            "epoch:  2170  loss:  0.04772601971465117  accuracy:  98.4708637553382\n",
            "epoch:  2171  loss:  0.054813422694458956  accuracy:  98.07824769251962\n",
            "epoch:  2172  loss:  0.0441178140118985  accuracy:  98.64306378289021\n",
            "epoch:  2173  loss:  0.04796288096601148  accuracy:  98.40887174541948\n",
            "epoch:  2174  loss:  0.04060546844032209  accuracy:  98.76704780272765\n",
            "epoch:  2175  loss:  0.053749339466570435  accuracy:  98.11957569913211\n",
            "epoch:  2176  loss:  0.047478228417163724  accuracy:  98.49152775864444\n",
            "epoch:  2177  loss:  0.04940592374381657  accuracy:  98.32621573219451\n",
            "epoch:  2178  loss:  0.06414487606594715  accuracy:  97.52031960325114\n",
            "epoch:  2179  loss:  0.0629291795335278  accuracy:  97.78206364513018\n",
            "epoch:  2180  loss:  0.054186781112785666  accuracy:  98.16779170684667\n",
            "epoch:  2181  loss:  0.05298721051555143  accuracy:  98.06447169031547\n",
            "epoch:  2182  loss:  0.05297556671286101  accuracy:  98.05758368921339\n",
            "epoch:  2183  loss:  0.05249797972297661  accuracy:  98.1264637002342\n",
            "epoch:  2184  loss:  0.046988512551403516  accuracy:  98.42953574872573\n",
            "epoch:  2185  loss:  0.05026420927616145  accuracy:  98.10579969692795\n",
            "epoch:  2186  loss:  0.14582320428021658  accuracy:  95.35748725719796\n",
            "epoch:  2187  loss:  0.08482582800609667  accuracy:  97.01749552279928\n",
            "epoch:  2188  loss:  0.06784704105549032  accuracy:  97.41699958671994\n",
            "epoch:  2189  loss:  0.04347514244294781  accuracy:  98.58795977407357\n",
            "epoch:  2190  loss:  0.042248554292330855  accuracy:  98.711943793911\n",
            "epoch:  2191  loss:  0.038056395842214805  accuracy:  98.88414382146301\n",
            "epoch:  2192  loss:  0.04188883648270528  accuracy:  98.68439178950268\n",
            "epoch:  2193  loss:  0.04419779446489728  accuracy:  98.56729577076732\n",
            "epoch:  2194  loss:  0.04669939485542914  accuracy:  98.42264774762364\n",
            "epoch:  2195  loss:  0.0513966269685921  accuracy:  98.16090370574459\n",
            "epoch:  2196  loss:  0.06509254815782836  accuracy:  97.48587959774073\n",
            "epoch:  2197  loss:  0.04449775235624533  accuracy:  98.52596776415484\n",
            "epoch:  2198  loss:  0.053782119006811464  accuracy:  98.06447169031547\n",
            "epoch:  2199  loss:  0.09392749470967672  accuracy:  96.81774349083896\n",
            "epoch:  2200  loss:  0.06552678863666125  accuracy:  97.55475960876154\n",
            "epoch:  2201  loss:  0.05704468355544516  accuracy:  98.22289571566331\n",
            "epoch:  2202  loss:  0.05423186835502524  accuracy:  98.14023970243835\n",
            "epoch:  2203  loss:  0.05642762615543384  accuracy:  98.18156770905084\n",
            "epoch:  2204  loss:  0.049019803231594106  accuracy:  98.2297837167654\n",
            "epoch:  2205  loss:  0.0488611653126147  accuracy:  98.20223171235708\n",
            "epoch:  2206  loss:  0.04151160932755561  accuracy:  98.64995178399228\n",
            "epoch:  2207  loss:  0.042850436211809596  accuracy:  98.711943793911\n",
            "epoch:  2208  loss:  0.047588019528907226  accuracy:  98.5053037608486\n",
            "epoch:  2209  loss:  0.06332506245110692  accuracy:  97.76828764292603\n",
            "epoch:  2210  loss:  0.045984746975779846  accuracy:  98.45019975203196\n",
            "epoch:  2211  loss:  0.06136409091549067  accuracy:  97.75451164072186\n",
            "epoch:  2212  loss:  0.08709607911499542  accuracy:  97.27235156357625\n",
            "epoch:  2213  loss:  0.09798872173843486  accuracy:  96.63176746108279\n",
            "epoch:  2214  loss:  0.059619457145965796  accuracy:  97.82339165174267\n",
            "epoch:  2215  loss:  0.05157643622335266  accuracy:  98.36065573770492\n",
            "epoch:  2216  loss:  0.0423744264115092  accuracy:  98.62239977958396\n",
            "epoch:  2217  loss:  0.042493528607303335  accuracy:  98.46397575423612\n",
            "epoch:  2218  loss:  0.04201855958737192  accuracy:  98.61551177848189\n",
            "epoch:  2219  loss:  0.0407876818992412  accuracy:  98.711943793911\n",
            "epoch:  2220  loss:  0.04005567531918285  accuracy:  98.62928778068604\n",
            "epoch:  2221  loss:  0.05267643053887764  accuracy:  98.17467970794875\n",
            "epoch:  2222  loss:  0.05337282724782182  accuracy:  98.06447169031547\n",
            "epoch:  2223  loss:  0.04138022809676731  accuracy:  98.711943793911\n",
            "epoch:  2224  loss:  0.03870229510360009  accuracy:  98.84281581485052\n",
            "epoch:  2225  loss:  0.04487659163128486  accuracy:  98.4364237498278\n",
            "epoch:  2226  loss:  0.05205309070094564  accuracy:  98.16779170684667\n",
            "epoch:  2227  loss:  0.08893512372034758  accuracy:  96.61110345777655\n",
            "epoch:  2228  loss:  0.1312665034035219  accuracy:  95.59856729577076\n",
            "epoch:  2229  loss:  0.0782230617731239  accuracy:  97.41699958671994\n",
            "epoch:  2230  loss:  0.05595218529417969  accuracy:  98.0506956881113\n",
            "epoch:  2231  loss:  0.039843490230000896  accuracy:  98.67061578729853\n",
            "epoch:  2232  loss:  0.04428842426783837  accuracy:  98.45019975203196\n",
            "epoch:  2233  loss:  0.03803990550368987  accuracy:  98.82903981264637\n",
            "epoch:  2234  loss:  0.03885414632364958  accuracy:  98.8152638104422\n",
            "epoch:  2235  loss:  0.039160979666377264  accuracy:  98.77393580382973\n",
            "epoch:  2236  loss:  0.045067315090451254  accuracy:  98.49152775864444\n",
            "epoch:  2237  loss:  0.039084166945138527  accuracy:  98.711943793911\n",
            "epoch:  2238  loss:  0.03791697452031871  accuracy:  98.83592781374846\n",
            "epoch:  2239  loss:  0.03707167890704455  accuracy:  98.84281581485052\n",
            "epoch:  2240  loss:  0.047694185781797474  accuracy:  98.30555172888828\n",
            "epoch:  2241  loss:  0.05706095712046179  accuracy:  98.25733572117372\n",
            "epoch:  2242  loss:  0.0689626377830822  accuracy:  97.62363961978234\n",
            "epoch:  2243  loss:  0.07347454894670222  accuracy:  97.44455159112826\n",
            "epoch:  2244  loss:  0.11385954220839925  accuracy:  96.06695137071222\n",
            "epoch:  2245  loss:  0.06197498931085945  accuracy:  97.74762363961979\n",
            "epoch:  2246  loss:  0.04089690550940065  accuracy:  98.70505579280892\n",
            "epoch:  2247  loss:  0.04447596223455501  accuracy:  98.5053037608486\n",
            "epoch:  2248  loss:  0.04934629454004307  accuracy:  98.18156770905084\n",
            "epoch:  2249  loss:  0.03768706650328584  accuracy:  98.82215181154429\n",
            "epoch:  2250  loss:  0.038058131301339615  accuracy:  98.85659181705469\n",
            "epoch:  2251  loss:  0.040901853605583446  accuracy:  98.64306378289021\n",
            "epoch:  2252  loss:  0.05240710327582146  accuracy:  98.00247968039675\n",
            "epoch:  2253  loss:  0.05189574657582575  accuracy:  98.07135969141756\n",
            "epoch:  2254  loss:  0.04706120404919946  accuracy:  98.38820774211324\n",
            "epoch:  2255  loss:  0.03986788047358285  accuracy:  98.70505579280892\n",
            "epoch:  2256  loss:  0.08536099020034005  accuracy:  96.735087477614\n",
            "epoch:  2257  loss:  0.07964321957032022  accuracy:  97.10015153602424\n",
            "epoch:  2258  loss:  0.054120489986330365  accuracy:  98.06447169031547\n",
            "epoch:  2259  loss:  0.040764669527971094  accuracy:  98.70505579280892\n",
            "epoch:  2260  loss:  0.038345797109683326  accuracy:  98.88414382146301\n",
            "epoch:  2261  loss:  0.03596224826055587  accuracy:  98.87036781925885\n",
            "epoch:  2262  loss:  0.03594043743024928  accuracy:  98.98057583689213\n",
            "epoch:  2263  loss:  0.0390754473907687  accuracy:  98.70505579280892\n",
            "epoch:  2264  loss:  0.05140409612996607  accuracy:  98.07824769251962\n",
            "epoch:  2265  loss:  0.04781735266972847  accuracy:  98.41575974652156\n",
            "epoch:  2266  loss:  0.07208978886010295  accuracy:  97.36878357900537\n",
            "epoch:  2267  loss:  0.12133160037123142  accuracy:  95.99118335858934\n",
            "epoch:  2268  loss:  0.0885164766068329  accuracy:  96.93483950957432\n",
            "epoch:  2269  loss:  0.06162860195322714  accuracy:  98.17467970794875\n",
            "epoch:  2270  loss:  0.05035581516687256  accuracy:  98.31243972999036\n",
            "epoch:  2271  loss:  0.05280646013565806  accuracy:  98.31932773109244\n",
            "epoch:  2272  loss:  0.03636692155497427  accuracy:  98.95302383248381\n",
            "epoch:  2273  loss:  0.04134405226365732  accuracy:  98.51907976305276\n",
            "epoch:  2274  loss:  0.03481360923986149  accuracy:  98.90480782476925\n",
            "epoch:  2275  loss:  0.033088288806868434  accuracy:  99.00812784130045\n",
            "epoch:  2276  loss:  0.047388719209924164  accuracy:  98.38820774211324\n",
            "epoch:  2277  loss:  0.03709921948657924  accuracy:  98.82903981264637\n",
            "epoch:  2278  loss:  0.035002511476563886  accuracy:  98.89791982366717\n",
            "epoch:  2279  loss:  0.03996117782121762  accuracy:  98.67061578729853\n",
            "epoch:  2280  loss:  0.03748259418131456  accuracy:  98.80148780823805\n",
            "epoch:  2281  loss:  0.04381520146394221  accuracy:  98.51219176195069\n",
            "epoch:  2282  loss:  0.0622771929356524  accuracy:  97.7407356385177\n",
            "epoch:  2283  loss:  0.05482253669344791  accuracy:  98.15401570464252\n",
            "epoch:  2284  loss:  0.09463034623332926  accuracy:  96.72131147540983\n",
            "epoch:  2285  loss:  0.0880216723863502  accuracy:  96.72131147540983\n",
            "epoch:  2286  loss:  0.06927647505415867  accuracy:  97.65119162419066\n",
            "epoch:  2287  loss:  0.03887319898268485  accuracy:  98.67061578729853\n",
            "epoch:  2288  loss:  0.04219894356258908  accuracy:  98.60173577627772\n",
            "epoch:  2289  loss:  0.04117072833580597  accuracy:  98.5741837718694\n",
            "epoch:  2290  loss:  0.038076176177358756  accuracy:  98.74638379942141\n",
            "epoch:  2291  loss:  0.03526968532091129  accuracy:  98.8910318225651\n",
            "epoch:  2292  loss:  0.04151252951518672  accuracy:  98.55351976856316\n",
            "epoch:  2293  loss:  0.04066628280011977  accuracy:  98.62928778068604\n",
            "epoch:  2294  loss:  0.04019810647331255  accuracy:  98.71883179501309\n",
            "epoch:  2295  loss:  0.047037404355157963  accuracy:  98.27111172337787\n",
            "epoch:  2296  loss:  0.04424065380802532  accuracy:  98.40887174541948\n",
            "epoch:  2297  loss:  0.06403054749840242  accuracy:  97.6374156219865\n",
            "epoch:  2298  loss:  0.05811641269245043  accuracy:  97.96803967488634\n",
            "epoch:  2299  loss:  0.10096764368165342  accuracy:  96.51467144234744\n",
            "epoch:  2300  loss:  0.07580559983344541  accuracy:  97.32056757129081\n",
            "epoch:  2301  loss:  0.06543968352606568  accuracy:  97.98181567709051\n",
            "epoch:  2302  loss:  0.04332216620152216  accuracy:  98.711943793911\n",
            "epoch:  2303  loss:  0.04189397667972534  accuracy:  98.66372778619645\n",
            "epoch:  2304  loss:  0.034709866118121734  accuracy:  99.00123984019838\n",
            "epoch:  2305  loss:  0.03140541531013681  accuracy:  99.08389585342334\n",
            "epoch:  2306  loss:  0.035730977614289235  accuracy:  98.84281581485052\n",
            "epoch:  2307  loss:  0.03250564286590006  accuracy:  99.00812784130045\n",
            "epoch:  2308  loss:  0.03778555802436411  accuracy:  98.73260779721724\n",
            "epoch:  2309  loss:  0.052034499949553295  accuracy:  98.25733572117372\n",
            "epoch:  2310  loss:  0.05486527631165264  accuracy:  97.98870367819259\n",
            "epoch:  2311  loss:  0.04113823048632378  accuracy:  98.6086237773798\n",
            "epoch:  2312  loss:  0.04766771216551054  accuracy:  98.39509574321532\n",
            "epoch:  2313  loss:  0.08670101875513957  accuracy:  96.98994351839096\n",
            "epoch:  2314  loss:  0.07441784629788399  accuracy:  97.35500757680121\n",
            "epoch:  2315  loss:  0.05561877876306667  accuracy:  98.13335170133627\n",
            "epoch:  2316  loss:  0.06948645172002009  accuracy:  97.64430362308858\n",
            "epoch:  2317  loss:  0.03662594216053977  accuracy:  98.78082380493181\n",
            "epoch:  2318  loss:  0.03755918642646362  accuracy:  98.68439178950268\n",
            "epoch:  2319  loss:  0.03505433274239029  accuracy:  98.86347981815678\n",
            "epoch:  2320  loss:  0.04276203524905335  accuracy:  98.58107177297148\n",
            "epoch:  2321  loss:  0.03549235290850926  accuracy:  98.93235982917757\n",
            "epoch:  2322  loss:  0.03610580262140041  accuracy:  98.8910318225651\n",
            "epoch:  2323  loss:  0.03871483466816205  accuracy:  98.69127979060477\n",
            "epoch:  2324  loss:  0.06026811076281714  accuracy:  97.73384763741562\n",
            "epoch:  2325  loss:  0.06464363939873849  accuracy:  97.65807962529274\n",
            "epoch:  2326  loss:  0.07462448900572433  accuracy:  97.31367957018873\n",
            "epoch:  2327  loss:  0.049207403877256604  accuracy:  98.27111172337787\n",
            "epoch:  2328  loss:  0.044189488398120834  accuracy:  98.42264774762364\n",
            "epoch:  2329  loss:  0.03741812798830822  accuracy:  98.79459980713597\n",
            "epoch:  2330  loss:  0.03535135436193939  accuracy:  98.87725582036093\n",
            "epoch:  2331  loss:  0.03463351217736565  accuracy:  98.91169582587133\n",
            "epoch:  2332  loss:  0.03554348444882003  accuracy:  98.8152638104422\n",
            "epoch:  2333  loss:  0.03407480317536284  accuracy:  98.93235982917757\n",
            "epoch:  2334  loss:  0.06759707495184772  accuracy:  97.53409560545529\n",
            "epoch:  2335  loss:  0.07990586192425757  accuracy:  97.11392753822841\n",
            "epoch:  2336  loss:  0.046068614625895066  accuracy:  98.59484777517564\n",
            "epoch:  2337  loss:  0.06446557957332626  accuracy:  97.69251963080315\n",
            "epoch:  2338  loss:  0.07292075683253087  accuracy:  97.54787160765946\n",
            "epoch:  2339  loss:  0.05105768430814864  accuracy:  98.38820774211324\n",
            "epoch:  2340  loss:  0.0465331245608908  accuracy:  98.4364237498278\n",
            "epoch:  2341  loss:  0.04076045627083118  accuracy:  98.58795977407357\n",
            "epoch:  2342  loss:  0.040516567833460936  accuracy:  98.63617578178813\n",
            "epoch:  2343  loss:  0.03225022008613559  accuracy:  99.05634384901502\n",
            "epoch:  2344  loss:  0.03418417866538709  accuracy:  98.85659181705469\n",
            "epoch:  2345  loss:  0.04043121892396417  accuracy:  98.68439178950268\n",
            "epoch:  2346  loss:  0.04112300624382477  accuracy:  98.68439178950268\n",
            "epoch:  2347  loss:  0.03425158661183209  accuracy:  98.82215181154429\n",
            "epoch:  2348  loss:  0.04144285019627758  accuracy:  98.64995178399228\n",
            "epoch:  2349  loss:  0.03943722888651298  accuracy:  98.60173577627772\n",
            "epoch:  2350  loss:  0.04248973410045424  accuracy:  98.5053037608486\n",
            "epoch:  2351  loss:  0.04869982599544942  accuracy:  98.29866372778619\n",
            "epoch:  2352  loss:  0.1407863781998507  accuracy:  95.66744730679157\n",
            "epoch:  2353  loss:  0.07938829249325066  accuracy:  97.21724755475961\n",
            "epoch:  2354  loss:  0.04974988844635188  accuracy:  98.27111172337787\n",
            "epoch:  2355  loss:  0.028745140030108703  accuracy:  99.20787987326078\n",
            "epoch:  2356  loss:  0.03295127205125488  accuracy:  98.96679983468798\n",
            "epoch:  2357  loss:  0.03390061831247266  accuracy:  99.00812784130045\n",
            "epoch:  2358  loss:  0.03456014120418341  accuracy:  98.97368783579006\n",
            "epoch:  2359  loss:  0.03805072107059153  accuracy:  98.80148780823805\n",
            "epoch:  2360  loss:  0.03717300508857463  accuracy:  98.73949579831933\n",
            "epoch:  2361  loss:  0.05422855553426745  accuracy:  98.01625568260091\n",
            "epoch:  2362  loss:  0.05290085438761836  accuracy:  98.18156770905084\n",
            "epoch:  2363  loss:  0.046651008806790156  accuracy:  98.25733572117372\n",
            "epoch:  2364  loss:  0.06289880806662297  accuracy:  97.58231161316986\n",
            "epoch:  2365  loss:  0.04547464063285628  accuracy:  98.41575974652156\n",
            "epoch:  2366  loss:  0.07150388221741534  accuracy:  97.56164760986361\n",
            "epoch:  2367  loss:  0.05268296369553261  accuracy:  98.16779170684667\n",
            "epoch:  2368  loss:  0.049522114242141584  accuracy:  98.39509574321532\n",
            "epoch:  2369  loss:  0.04096371602312701  accuracy:  98.51219176195069\n",
            "epoch:  2370  loss:  0.030343256059684808  accuracy:  99.07011985121918\n",
            "epoch:  2371  loss:  0.03176318343360819  accuracy:  99.11833585893373\n",
            "epoch:  2372  loss:  0.037913594718171635  accuracy:  98.72571979611517\n",
            "epoch:  2373  loss:  0.03908163502366931  accuracy:  98.64995178399228\n",
            "epoch:  2374  loss:  0.03479678159083631  accuracy:  98.87036781925885\n",
            "epoch:  2375  loss:  0.04014469887217077  accuracy:  98.69127979060477\n",
            "epoch:  2376  loss:  0.06269245159139086  accuracy:  97.6718556274969\n",
            "epoch:  2377  loss:  0.09911651397194497  accuracy:  96.60421545667447\n",
            "epoch:  2378  loss:  0.04727473827909033  accuracy:  98.53974376635901\n",
            "epoch:  2379  loss:  0.042986736037961  accuracy:  98.63617578178813\n",
            "epoch:  2380  loss:  0.032921556925819606  accuracy:  98.96679983468798\n",
            "epoch:  2381  loss:  0.03841405599160583  accuracy:  98.70505579280892\n",
            "epoch:  2382  loss:  0.031333754620091296  accuracy:  98.98746383799421\n",
            "epoch:  2383  loss:  0.03803196971301251  accuracy:  98.71883179501309\n",
            "epoch:  2384  loss:  0.053608640649024035  accuracy:  97.95426367268219\n",
            "epoch:  2385  loss:  0.03803857879792467  accuracy:  98.89791982366717\n",
            "epoch:  2386  loss:  0.039632592795057216  accuracy:  98.8152638104422\n",
            "epoch:  2387  loss:  0.04172481385661762  accuracy:  98.66372778619645\n",
            "epoch:  2388  loss:  0.03329303508060175  accuracy:  98.97368783579006\n",
            "epoch:  2389  loss:  0.03855700976601355  accuracy:  98.6775037884006\n",
            "epoch:  2390  loss:  0.03843725378542855  accuracy:  98.64995178399228\n",
            "epoch:  2391  loss:  0.12983131718841454  accuracy:  95.9705193552831\n",
            "epoch:  2392  loss:  0.059983145420310344  accuracy:  97.8096156495385\n",
            "epoch:  2393  loss:  0.03801852049744048  accuracy:  98.62928778068604\n",
            "epoch:  2394  loss:  0.04004977253358182  accuracy:  98.62928778068604\n",
            "epoch:  2395  loss:  0.03551025068874156  accuracy:  98.92547182807549\n",
            "epoch:  2396  loss:  0.04784006131578143  accuracy:  98.46397575423612\n",
            "epoch:  2397  loss:  0.07736247034394711  accuracy:  97.53409560545529\n",
            "epoch:  2398  loss:  0.07361676095533136  accuracy:  97.71318363410938\n",
            "epoch:  2399  loss:  0.054901263045480896  accuracy:  98.19534371125499\n",
            "epoch:  2400  loss:  0.032755676348017404  accuracy:  98.95991183358589\n",
            "epoch:  2401  loss:  0.032353332909566934  accuracy:  98.95302383248381\n",
            "epoch:  2402  loss:  0.03297510607253269  accuracy:  98.93924783027965\n",
            "epoch:  2403  loss:  0.03288992744797225  accuracy:  98.93924783027965\n",
            "epoch:  2404  loss:  0.04666902723948351  accuracy:  98.42953574872573\n",
            "epoch:  2405  loss:  0.041295519507079416  accuracy:  98.60173577627772\n",
            "epoch:  2406  loss:  0.030472927260566576  accuracy:  99.13899986223998\n",
            "epoch:  2407  loss:  0.031767950749930794  accuracy:  99.05634384901502\n",
            "epoch:  2408  loss:  0.04995509895520062  accuracy:  98.35376773660283\n",
            "epoch:  2409  loss:  0.04201827609112515  accuracy:  98.49152775864444\n",
            "epoch:  2410  loss:  0.03200686448061884  accuracy:  98.98057583689213\n",
            "epoch:  2411  loss:  0.038788598393635215  accuracy:  98.68439178950268\n",
            "epoch:  2412  loss:  0.05137221063206898  accuracy:  98.09202369472379\n",
            "epoch:  2413  loss:  0.033316861938047275  accuracy:  98.94613583138174\n",
            "epoch:  2414  loss:  0.038552336150890404  accuracy:  98.69127979060477\n",
            "epoch:  2415  loss:  0.039345022523551175  accuracy:  98.70505579280892\n",
            "epoch:  2416  loss:  0.03902174715566746  accuracy:  98.6775037884006\n",
            "epoch:  2417  loss:  0.13948534508682875  accuracy:  95.60545529687285\n",
            "epoch:  2418  loss:  0.08715419071484144  accuracy:  97.11392753822841\n",
            "epoch:  2419  loss:  0.048981780060177574  accuracy:  98.31243972999036\n",
            "epoch:  2420  loss:  0.03084778594507954  accuracy:  99.07011985121918\n",
            "epoch:  2421  loss:  0.03206100463926205  accuracy:  99.01501584240253\n",
            "epoch:  2422  loss:  0.036778002651620005  accuracy:  98.69816779170685\n",
            "epoch:  2423  loss:  0.029668620433712246  accuracy:  99.14588786334205\n",
            "epoch:  2424  loss:  0.03498570979744112  accuracy:  98.8152638104422\n",
            "epoch:  2425  loss:  0.038826731150054576  accuracy:  98.68439178950268\n",
            "epoch:  2426  loss:  0.035726178827372106  accuracy:  98.84281581485052\n",
            "epoch:  2427  loss:  0.04020849337394886  accuracy:  98.64995178399228\n",
            "epoch:  2428  loss:  0.034875794051733126  accuracy:  98.92547182807549\n",
            "epoch:  2429  loss:  0.03793193854931457  accuracy:  98.73949579831933\n",
            "epoch:  2430  loss:  0.05699416628010691  accuracy:  97.91982366717178\n",
            "epoch:  2431  loss:  0.043882896494131136  accuracy:  98.4708637553382\n",
            "epoch:  2432  loss:  0.04008933626052969  accuracy:  98.65683978509436\n",
            "epoch:  2433  loss:  0.030956799053564053  accuracy:  98.94613583138174\n",
            "epoch:  2434  loss:  0.0271072157979769  accuracy:  99.19410387105663\n",
            "epoch:  2435  loss:  0.043648367309395  accuracy:  98.54663176746108\n",
            "epoch:  2436  loss:  0.13689662345376763  accuracy:  95.72255131560821\n",
            "epoch:  2437  loss:  0.06562935769376281  accuracy:  97.63052762088442\n",
            "epoch:  2438  loss:  0.045703172580050216  accuracy:  98.59484777517564\n",
            "epoch:  2439  loss:  0.03366083924095749  accuracy:  98.93924783027965\n",
            "epoch:  2440  loss:  0.0327739014067931  accuracy:  99.01501584240253\n",
            "epoch:  2441  loss:  0.03703929833428379  accuracy:  98.79459980713597\n",
            "epoch:  2442  loss:  0.03349502893823698  accuracy:  98.83592781374846\n",
            "epoch:  2443  loss:  0.02793692799128786  accuracy:  99.09078385452541\n",
            "epoch:  2444  loss:  0.0300558106093636  accuracy:  99.11144785783166\n",
            "epoch:  2445  loss:  0.03350548576902306  accuracy:  99.00812784130045\n",
            "epoch:  2446  loss:  0.07874531754497698  accuracy:  97.25168756027001\n",
            "epoch:  2447  loss:  0.07674541970965623  accuracy:  97.55475960876154\n",
            "epoch:  2448  loss:  0.045826708701522466  accuracy:  98.53974376635901\n",
            "epoch:  2449  loss:  0.0433243267811765  accuracy:  98.56729577076732\n",
            "epoch:  2450  loss:  0.03444440400527867  accuracy:  98.80148780823805\n",
            "epoch:  2451  loss:  0.03414980953629587  accuracy:  98.8152638104422\n",
            "epoch:  2452  loss:  0.029761361324897168  accuracy:  99.11833585893373\n",
            "epoch:  2453  loss:  0.02970463984818722  accuracy:  99.10455985672958\n",
            "epoch:  2454  loss:  0.02776385010105283  accuracy:  99.15277586444414\n",
            "epoch:  2455  loss:  0.04108848136517792  accuracy:  98.56729577076732\n",
            "epoch:  2456  loss:  0.03578636867116984  accuracy:  98.87036781925885\n",
            "epoch:  2457  loss:  0.061406745619246667  accuracy:  97.78895164623226\n",
            "epoch:  2458  loss:  0.05962951661384328  accuracy:  97.98181567709051\n",
            "epoch:  2459  loss:  0.06632787958113394  accuracy:  97.97492767598843\n",
            "epoch:  2460  loss:  0.05153772851226682  accuracy:  98.2642237222758\n",
            "epoch:  2461  loss:  0.06961175410521148  accuracy:  97.85783165725306\n",
            "epoch:  2462  loss:  0.044912639936196944  accuracy:  98.5053037608486\n",
            "epoch:  2463  loss:  0.04183375831229738  accuracy:  98.6086237773798\n",
            "epoch:  2464  loss:  0.02767015409629311  accuracy:  99.19410387105663\n",
            "epoch:  2465  loss:  0.037780563062923433  accuracy:  98.711943793911\n",
            "epoch:  2466  loss:  0.032813227687796716  accuracy:  98.88414382146301\n",
            "epoch:  2467  loss:  0.027548691226529472  accuracy:  99.13899986223998\n",
            "epoch:  2468  loss:  0.02897577110801381  accuracy:  99.09078385452541\n",
            "epoch:  2469  loss:  0.03590421786603397  accuracy:  98.78082380493181\n",
            "epoch:  2470  loss:  0.02987517030816769  accuracy:  99.05634384901502\n",
            "epoch:  2471  loss:  0.03335264393050577  accuracy:  98.89791982366717\n",
            "epoch:  2472  loss:  0.03747335801003438  accuracy:  98.71883179501309\n",
            "epoch:  2473  loss:  0.0371299205538548  accuracy:  98.83592781374846\n",
            "epoch:  2474  loss:  0.04803182893355826  accuracy:  98.07135969141756\n",
            "epoch:  2475  loss:  0.028811848477539606  accuracy:  99.10455985672958\n",
            "epoch:  2476  loss:  0.028249760224562298  accuracy:  99.18032786885246\n",
            "epoch:  2477  loss:  0.04892090940957047  accuracy:  98.27111172337787\n",
            "epoch:  2478  loss:  0.07034553101414334  accuracy:  97.48587959774073\n",
            "epoch:  2479  loss:  0.09305789700938553  accuracy:  96.92795150847225\n",
            "epoch:  2480  loss:  0.1268873206584956  accuracy:  95.64678330348534\n",
            "epoch:  2481  loss:  0.07441242526932362  accuracy:  97.61675161868025\n",
            "epoch:  2482  loss:  0.029751184412418977  accuracy:  99.15277586444414\n",
            "epoch:  2483  loss:  0.026729198039321656  accuracy:  99.21476787436286\n",
            "epoch:  2484  loss:  0.025953979620002832  accuracy:  99.25609588097534\n",
            "epoch:  2485  loss:  0.025200093070740236  accuracy:  99.2009918721587\n",
            "epoch:  2486  loss:  0.027106066783850354  accuracy:  99.1321118611379\n",
            "epoch:  2487  loss:  0.03419949679203996  accuracy:  98.88414382146301\n",
            "epoch:  2488  loss:  0.03187825051493628  accuracy:  98.98746383799421\n",
            "epoch:  2489  loss:  0.02846943252576372  accuracy:  99.04256784681085\n",
            "epoch:  2490  loss:  0.027646364746359977  accuracy:  99.1665518666483\n",
            "epoch:  2491  loss:  0.03882148689143272  accuracy:  98.6775037884006\n",
            "epoch:  2492  loss:  0.036420989495254706  accuracy:  98.77393580382973\n",
            "epoch:  2493  loss:  0.03550107924758778  accuracy:  98.87036781925885\n",
            "epoch:  2494  loss:  0.04977368063984031  accuracy:  98.10579969692795\n",
            "epoch:  2495  loss:  0.04843686574707964  accuracy:  98.10579969692795\n",
            "epoch:  2496  loss:  0.03128204853195024  accuracy:  99.09078385452541\n",
            "epoch:  2497  loss:  0.03898469341599618  accuracy:  98.66372778619645\n",
            "epoch:  2498  loss:  0.061012039429087714  accuracy:  98.00247968039675\n",
            "epoch:  2499  loss:  0.1474342691284974  accuracy:  95.63989530238325\n",
            "epoch:  2500  loss:  0.06443332420552478  accuracy:  97.78895164623226\n",
            "epoch:  2501  loss:  0.027925922354201646  accuracy:  99.15966386554622\n",
            "epoch:  2502  loss:  0.031222915517958888  accuracy:  99.04256784681085\n",
            "epoch:  2503  loss:  0.029832329395963444  accuracy:  99.03567984570877\n",
            "epoch:  2504  loss:  0.03231485266096552  accuracy:  99.0287918446067\n",
            "epoch:  2505  loss:  0.033728139364073484  accuracy:  98.85659181705469\n",
            "epoch:  2506  loss:  0.027195676774651793  accuracy:  99.1321118611379\n",
            "epoch:  2507  loss:  0.029328737069213337  accuracy:  98.96679983468798\n",
            "epoch:  2508  loss:  0.033586191758038744  accuracy:  98.80837580934013\n",
            "epoch:  2509  loss:  0.03635088498300635  accuracy:  98.84281581485052\n",
            "epoch:  2510  loss:  0.03053538514073322  accuracy:  99.11833585893373\n",
            "epoch:  2511  loss:  0.03185375171575866  accuracy:  99.05634384901502\n",
            "epoch:  2512  loss:  0.031342939820929894  accuracy:  99.00123984019838\n",
            "epoch:  2513  loss:  0.0405332123464786  accuracy:  98.6775037884006\n",
            "epoch:  2514  loss:  0.10430406567075189  accuracy:  96.34247141479543\n",
            "epoch:  2515  loss:  0.08030535533466394  accuracy:  97.1483675437388\n",
            "epoch:  2516  loss:  0.04044637805689242  accuracy:  98.63617578178813\n",
            "epoch:  2517  loss:  0.031754490249369556  accuracy:  99.03567984570877\n",
            "epoch:  2518  loss:  0.040234376184193524  accuracy:  98.53285576525693\n",
            "epoch:  2519  loss:  0.03116411833389711  accuracy:  99.04945584791294\n",
            "epoch:  2520  loss:  0.029415729641170233  accuracy:  99.1321118611379\n",
            "epoch:  2521  loss:  0.03165452407412811  accuracy:  99.05634384901502\n",
            "epoch:  2522  loss:  0.04262549397928859  accuracy:  98.58107177297148\n",
            "epoch:  2523  loss:  0.05923870008183254  accuracy:  97.86471965835514\n",
            "epoch:  2524  loss:  0.08198874172651177  accuracy:  97.76139964182394\n",
            "epoch:  2525  loss:  0.07058038365263669  accuracy:  97.62363961978234\n",
            "epoch:  2526  loss:  0.03269087916708644  accuracy:  98.91858382697342\n",
            "epoch:  2527  loss:  0.029470588952505133  accuracy:  99.09078385452541\n",
            "epoch:  2528  loss:  0.026096148324249186  accuracy:  99.24231987877118\n",
            "epoch:  2529  loss:  0.041852540131142556  accuracy:  98.53974376635901\n",
            "epoch:  2530  loss:  0.02879593275202086  accuracy:  99.08389585342334\n",
            "epoch:  2531  loss:  0.02862680059824822  accuracy:  99.11144785783166\n",
            "epoch:  2532  loss:  0.043345367232714024  accuracy:  98.4708637553382\n",
            "epoch:  2533  loss:  0.05211853716362851  accuracy:  98.0506956881113\n",
            "epoch:  2534  loss:  0.03150589824277604  accuracy:  98.9943518390963\n",
            "epoch:  2535  loss:  0.037476291986756345  accuracy:  98.70505579280892\n",
            "epoch:  2536  loss:  0.042323405259738024  accuracy:  98.62928778068604\n",
            "epoch:  2537  loss:  0.06932652892210261  accuracy:  97.64430362308858\n",
            "epoch:  2538  loss:  0.060958307164200684  accuracy:  98.10579969692795\n",
            "epoch:  2539  loss:  0.04873997720918358  accuracy:  98.15401570464252\n",
            "epoch:  2540  loss:  0.03359422089170471  accuracy:  98.83592781374846\n",
            "epoch:  2541  loss:  0.026935884395482376  accuracy:  99.17343986775037\n",
            "epoch:  2542  loss:  0.025107446642017  accuracy:  99.3043118886899\n",
            "epoch:  2543  loss:  0.031076707593421293  accuracy:  99.00123984019838\n",
            "epoch:  2544  loss:  0.0277186464211674  accuracy:  99.13899986223998\n",
            "epoch:  2545  loss:  0.056696195994586036  accuracy:  98.13335170133627\n",
            "epoch:  2546  loss:  0.08628600140830048  accuracy:  97.079487532718\n",
            "epoch:  2547  loss:  0.05426418220113441  accuracy:  97.99559167929466\n",
            "epoch:  2548  loss:  0.034708483375386706  accuracy:  98.89791982366717\n",
            "epoch:  2549  loss:  0.027032935614363415  accuracy:  99.18721586995454\n",
            "epoch:  2550  loss:  0.03935124015045291  accuracy:  98.71883179501309\n",
            "epoch:  2551  loss:  0.03676062489848598  accuracy:  98.75327180052349\n",
            "epoch:  2552  loss:  0.028383008459908033  accuracy:  99.18032786885246\n",
            "epoch:  2553  loss:  0.030176271022861828  accuracy:  99.04945584791294\n",
            "epoch:  2554  loss:  0.03866249298556119  accuracy:  98.87725582036093\n",
            "epoch:  2555  loss:  0.042148627883947506  accuracy:  98.56040776966525\n",
            "epoch:  2556  loss:  0.031297609702361825  accuracy:  98.85659181705469\n",
            "epoch:  2557  loss:  0.03969679914989919  accuracy:  98.51907976305276\n",
            "epoch:  2558  loss:  0.043843714067118914  accuracy:  98.49152775864444\n",
            "epoch:  2559  loss:  0.04462455824748316  accuracy:  98.4019837443174\n",
            "epoch:  2560  loss:  0.029585646447972055  accuracy:  99.06323185011709\n",
            "epoch:  2561  loss:  0.027027887865382152  accuracy:  99.2009918721587\n",
            "epoch:  2562  loss:  0.028790378814337606  accuracy:  98.98057583689213\n",
            "epoch:  2563  loss:  0.030422158560656984  accuracy:  99.02190384350462\n",
            "epoch:  2564  loss:  0.053616165691933566  accuracy:  98.0506956881113\n",
            "epoch:  2565  loss:  0.11804728444759585  accuracy:  96.19093539054967\n",
            "epoch:  2566  loss:  0.08568869349611521  accuracy:  97.12770354043256\n",
            "epoch:  2567  loss:  0.03660347043511072  accuracy:  98.87725582036093\n",
            "epoch:  2568  loss:  0.02919404853240809  accuracy:  99.07700785232126\n",
            "epoch:  2569  loss:  0.023061599864178346  accuracy:  99.31808789089406\n",
            "epoch:  2570  loss:  0.023305623321382776  accuracy:  99.29053588648574\n",
            "epoch:  2571  loss:  0.023119728286719952  accuracy:  99.34563989530238\n",
            "epoch:  2572  loss:  0.027751570349893534  accuracy:  99.11833585893373\n",
            "epoch:  2573  loss:  0.030289119913433023  accuracy:  98.93924783027965\n",
            "epoch:  2574  loss:  0.025834096683209032  accuracy:  99.18721586995454\n",
            "epoch:  2575  loss:  0.0267404867465736  accuracy:  99.2009918721587\n",
            "epoch:  2576  loss:  0.02936661629349338  accuracy:  98.9943518390963\n",
            "epoch:  2577  loss:  0.031095552454106095  accuracy:  98.97368783579006\n",
            "epoch:  2578  loss:  0.028022016931562806  accuracy:  99.09078385452541\n",
            "epoch:  2579  loss:  0.10445423281100712  accuracy:  96.7006474721036\n",
            "epoch:  2580  loss:  0.07764993580490585  accuracy:  97.3618955779033\n",
            "epoch:  2581  loss:  0.053269287436147984  accuracy:  98.07135969141756\n",
            "epoch:  2582  loss:  0.03126466148489947  accuracy:  99.06323185011709\n",
            "epoch:  2583  loss:  0.03351923087433459  accuracy:  98.92547182807549\n",
            "epoch:  2584  loss:  0.026153658844765625  accuracy:  99.24920787987327\n",
            "epoch:  2585  loss:  0.027524999997568682  accuracy:  99.0287918446067\n",
            "epoch:  2586  loss:  0.024580819891897348  accuracy:  99.19410387105663\n",
            "epoch:  2587  loss:  0.02463637183029433  accuracy:  99.33186389309822\n",
            "epoch:  2588  loss:  0.045579049455671414  accuracy:  98.29866372778619\n",
            "epoch:  2589  loss:  0.027938633363009863  accuracy:  99.11144785783166\n",
            "epoch:  2590  loss:  0.024633274530942644  accuracy:  99.27675988428157\n",
            "epoch:  2591  loss:  0.030172536781942722  accuracy:  99.0287918446067\n",
            "epoch:  2592  loss:  0.037806377273126315  accuracy:  98.73260779721724\n",
            "epoch:  2593  loss:  0.07264959938731289  accuracy:  97.78206364513018\n",
            "epoch:  2594  loss:  0.10495724713932485  accuracy:  96.66620746659319\n",
            "epoch:  2595  loss:  0.04161056840797687  accuracy:  98.73949579831933\n",
            "epoch:  2596  loss:  0.027935115554676492  accuracy:  99.14588786334205\n",
            "epoch:  2597  loss:  0.023008477796222705  accuracy:  99.33186389309822\n",
            "epoch:  2598  loss:  0.03087928400842342  accuracy:  99.01501584240253\n",
            "epoch:  2599  loss:  0.02559720243000542  accuracy:  99.15966386554622\n",
            "epoch:  2600  loss:  0.025877066421419903  accuracy:  99.19410387105663\n",
            "epoch:  2601  loss:  0.026481082714901127  accuracy:  99.13899986223998\n",
            "epoch:  2602  loss:  0.029609506818404175  accuracy:  99.04945584791294\n",
            "epoch:  2603  loss:  0.027601661383956855  accuracy:  99.07011985121918\n",
            "epoch:  2604  loss:  0.024534800037998773  accuracy:  99.26298388207742\n",
            "epoch:  2605  loss:  0.0319713068819247  accuracy:  98.92547182807549\n",
            "epoch:  2606  loss:  0.043213807093242566  accuracy:  98.4019837443174\n",
            "epoch:  2607  loss:  0.04505960650315845  accuracy:  98.45708775313405\n",
            "epoch:  2608  loss:  0.04279136864122304  accuracy:  98.51219176195069\n",
            "epoch:  2609  loss:  0.07117073853923703  accuracy:  97.43766359002618\n",
            "epoch:  2610  loss:  0.07618094755923994  accuracy:  97.76139964182394\n",
            "epoch:  2611  loss:  0.07205404370049645  accuracy:  97.52720760435322\n",
            "epoch:  2612  loss:  0.029787034492076002  accuracy:  99.0976718556275\n",
            "epoch:  2613  loss:  0.023154962684534246  accuracy:  99.3043118886899\n",
            "epoch:  2614  loss:  0.02277517613729934  accuracy:  99.38007990081279\n",
            "epoch:  2615  loss:  0.02339521078993303  accuracy:  99.21476787436286\n",
            "epoch:  2616  loss:  0.02262699347542234  accuracy:  99.3387518942003\n",
            "epoch:  2617  loss:  0.02470420435174144  accuracy:  99.27675988428157\n",
            "epoch:  2618  loss:  0.026197111174185304  accuracy:  99.15277586444414\n",
            "epoch:  2619  loss:  0.027274906898874757  accuracy:  99.17343986775037\n",
            "epoch:  2620  loss:  0.02286819768746239  accuracy:  99.33186389309822\n",
            "epoch:  2621  loss:  0.031100757578704754  accuracy:  98.98746383799421\n",
            "epoch:  2622  loss:  0.03841113422266376  accuracy:  98.63617578178813\n",
            "epoch:  2623  loss:  0.06064127991226159  accuracy:  97.90604766496763\n",
            "epoch:  2624  loss:  0.14345893378490496  accuracy:  95.57790329246453\n",
            "epoch:  2625  loss:  0.06598145210773435  accuracy:  97.82339165174267\n",
            "epoch:  2626  loss:  0.041222919207561534  accuracy:  98.76704780272765\n",
            "epoch:  2627  loss:  0.03188214910731493  accuracy:  99.00123984019838\n",
            "epoch:  2628  loss:  0.03478801951227002  accuracy:  98.97368783579006\n",
            "epoch:  2629  loss:  0.02481764323176373  accuracy:  99.32497589199615\n",
            "epoch:  2630  loss:  0.022481103660635018  accuracy:  99.31119988979198\n",
            "epoch:  2631  loss:  0.029779298942744472  accuracy:  98.95991183358589\n",
            "epoch:  2632  loss:  0.023013517026341596  accuracy:  99.31808789089406\n",
            "epoch:  2633  loss:  0.02486449799880556  accuracy:  99.18032786885246\n",
            "epoch:  2634  loss:  0.023217630665184796  accuracy:  99.25609588097534\n",
            "epoch:  2635  loss:  0.02539055307184961  accuracy:  99.19410387105663\n",
            "epoch:  2636  loss:  0.026137248932853914  accuracy:  99.20787987326078\n",
            "epoch:  2637  loss:  0.02510181057006059  accuracy:  99.2698718831795\n",
            "epoch:  2638  loss:  0.030057114186023266  accuracy:  98.98057583689213\n",
            "epoch:  2639  loss:  0.08725321820981617  accuracy:  97.37567158010745\n",
            "epoch:  2640  loss:  0.10280571919307165  accuracy:  96.48711943793911\n",
            "epoch:  2641  loss:  0.05439204141627964  accuracy:  98.11957569913211\n",
            "epoch:  2642  loss:  0.02862386482049671  accuracy:  99.10455985672958\n",
            "epoch:  2643  loss:  0.026576130098161236  accuracy:  99.13899986223998\n",
            "epoch:  2644  loss:  0.023792522008875792  accuracy:  99.25609588097534\n",
            "epoch:  2645  loss:  0.02109989469443946  accuracy:  99.4420719107315\n",
            "epoch:  2646  loss:  0.021844924385230235  accuracy:  99.3387518942003\n",
            "epoch:  2647  loss:  0.030346305725492004  accuracy:  98.98746383799421\n",
            "epoch:  2648  loss:  0.030268931965828496  accuracy:  98.9943518390963\n",
            "epoch:  2649  loss:  0.02450726764936209  accuracy:  99.22165587546495\n",
            "epoch:  2650  loss:  0.037431774515261404  accuracy:  98.80148780823805\n",
            "epoch:  2651  loss:  0.035392031407404295  accuracy:  98.80148780823805\n",
            "epoch:  2652  loss:  0.055986928207001005  accuracy:  98.11957569913211\n",
            "epoch:  2653  loss:  0.1142090766483212  accuracy:  96.27359140377463\n",
            "epoch:  2654  loss:  0.054656830726760794  accuracy:  98.11957569913211\n",
            "epoch:  2655  loss:  0.026553542338971642  accuracy:  99.2009918721587\n",
            "epoch:  2656  loss:  0.02619249772665095  accuracy:  99.21476787436286\n",
            "epoch:  2657  loss:  0.022737843115554993  accuracy:  99.3043118886899\n",
            "epoch:  2658  loss:  0.023699778762473714  accuracy:  99.25609588097534\n",
            "epoch:  2659  loss:  0.021615008139419075  accuracy:  99.33186389309822\n",
            "epoch:  2660  loss:  0.023249566822590797  accuracy:  99.3387518942003\n",
            "epoch:  2661  loss:  0.02191534529273701  accuracy:  99.38007990081279\n",
            "epoch:  2662  loss:  0.02423776304264626  accuracy:  99.3043118886899\n",
            "epoch:  2663  loss:  0.04040632885582473  accuracy:  98.84281581485052\n",
            "epoch:  2664  loss:  0.15643145012235488  accuracy:  95.3437112549938\n",
            "epoch:  2665  loss:  0.05320114546959273  accuracy:  98.13335170133627\n",
            "epoch:  2666  loss:  0.026642885016394696  accuracy:  99.24231987877118\n",
            "epoch:  2667  loss:  0.03205464984444774  accuracy:  99.09078385452541\n",
            "epoch:  2668  loss:  0.027548076924286093  accuracy:  99.15966386554622\n",
            "epoch:  2669  loss:  0.021950755635815805  accuracy:  99.34563989530238\n",
            "epoch:  2670  loss:  0.021371022481126177  accuracy:  99.40763190522111\n",
            "epoch:  2671  loss:  0.025869925752298052  accuracy:  99.09078385452541\n",
            "epoch:  2672  loss:  0.026158445812841328  accuracy:  99.20787987326078\n",
            "epoch:  2673  loss:  0.025315238154214992  accuracy:  99.2698718831795\n",
            "epoch:  2674  loss:  0.030222110274883033  accuracy:  98.92547182807549\n",
            "epoch:  2675  loss:  0.0269163197492389  accuracy:  99.18032786885246\n",
            "epoch:  2676  loss:  0.025941266653704415  accuracy:  99.17343986775037\n",
            "epoch:  2677  loss:  0.026768241245733227  accuracy:  99.18032786885246\n",
            "epoch:  2678  loss:  0.03695366325113219  accuracy:  98.6775037884006\n",
            "epoch:  2679  loss:  0.06081039283551889  accuracy:  97.73384763741562\n",
            "epoch:  2680  loss:  0.1019770525329668  accuracy:  96.51467144234744\n",
            "epoch:  2681  loss:  0.05048742696498154  accuracy:  98.32621573219451\n",
            "epoch:  2682  loss:  0.03425054558852893  accuracy:  98.98057583689213\n",
            "epoch:  2683  loss:  0.05070547947927207  accuracy:  98.47775175644028\n",
            "epoch:  2684  loss:  0.033364506288585415  accuracy:  98.91858382697342\n",
            "epoch:  2685  loss:  0.02619049491193738  accuracy:  99.24231987877118\n",
            "epoch:  2686  loss:  0.02479767765301222  accuracy:  99.26298388207742\n",
            "epoch:  2687  loss:  0.01993011020987796  accuracy:  99.4420719107315\n",
            "epoch:  2688  loss:  0.021667444332978642  accuracy:  99.3387518942003\n",
            "epoch:  2689  loss:  0.02110340325443431  accuracy:  99.42140790742526\n",
            "epoch:  2690  loss:  0.024302953184995545  accuracy:  99.22854387656702\n",
            "epoch:  2691  loss:  0.03846924040546862  accuracy:  98.66372778619645\n",
            "epoch:  2692  loss:  0.03639316265565579  accuracy:  98.84970381595261\n",
            "epoch:  2693  loss:  0.03288142958109143  accuracy:  98.95302383248381\n",
            "epoch:  2694  loss:  0.037025940495774505  accuracy:  98.65683978509436\n",
            "epoch:  2695  loss:  0.05390261386150761  accuracy:  98.2642237222758\n",
            "epoch:  2696  loss:  0.06609934524514058  accuracy:  97.6718556274969\n",
            "epoch:  2697  loss:  0.055519027304700264  accuracy:  97.91982366717178\n",
            "epoch:  2698  loss:  0.03769623031667808  accuracy:  98.80837580934013\n",
            "epoch:  2699  loss:  0.04009848009584027  accuracy:  98.61551177848189\n",
            "epoch:  2700  loss:  0.03636506000498546  accuracy:  98.8152638104422\n",
            "epoch:  2701  loss:  0.029801654255225227  accuracy:  99.17343986775037\n",
            "epoch:  2702  loss:  0.027165905350195953  accuracy:  99.13899986223998\n",
            "epoch:  2703  loss:  0.023054424027782353  accuracy:  99.3387518942003\n",
            "epoch:  2704  loss:  0.021687579655661596  accuracy:  99.35941589750654\n",
            "epoch:  2705  loss:  0.024457667986950246  accuracy:  99.1665518666483\n",
            "epoch:  2706  loss:  0.030726714029816832  accuracy:  98.87036781925885\n",
            "epoch:  2707  loss:  0.024303779668412167  accuracy:  99.22854387656702\n",
            "epoch:  2708  loss:  0.02758697954983875  accuracy:  99.05634384901502\n",
            "epoch:  2709  loss:  0.025135567185364666  accuracy:  99.25609588097534\n",
            "epoch:  2710  loss:  0.02597095406289519  accuracy:  99.19410387105663\n",
            "epoch:  2711  loss:  0.0291011397666405  accuracy:  98.98057583689213\n",
            "epoch:  2712  loss:  0.09667508008684961  accuracy:  96.81774349083896\n",
            "epoch:  2713  loss:  0.1649663984231042  accuracy:  95.274831243973\n",
            "epoch:  2714  loss:  0.044919883565024465  accuracy:  98.5741837718694\n",
            "epoch:  2715  loss:  0.023588412495070557  accuracy:  99.33186389309822\n",
            "epoch:  2716  loss:  0.022448242030640594  accuracy:  99.31808789089406\n",
            "epoch:  2717  loss:  0.020904339671869845  accuracy:  99.36630389860862\n",
            "epoch:  2718  loss:  0.01951873219787037  accuracy:  99.44895991183358\n",
            "epoch:  2719  loss:  0.02218696200013631  accuracy:  99.38696790191486\n",
            "epoch:  2720  loss:  0.030622220069440965  accuracy:  98.90480782476925\n",
            "epoch:  2721  loss:  0.030306503418981844  accuracy:  99.12522386003582\n",
            "epoch:  2722  loss:  0.02907147286008191  accuracy:  99.08389585342334\n",
            "epoch:  2723  loss:  0.023891677203808734  accuracy:  99.21476787436286\n",
            "epoch:  2724  loss:  0.030699077449900122  accuracy:  99.00812784130045\n",
            "epoch:  2725  loss:  0.026041786817692397  accuracy:  99.10455985672958\n",
            "epoch:  2726  loss:  0.03092627241560387  accuracy:  99.05634384901502\n",
            "epoch:  2727  loss:  0.026962801102917825  accuracy:  99.04945584791294\n",
            "epoch:  2728  loss:  0.10385066394264733  accuracy:  96.8384074941452\n",
            "epoch:  2729  loss:  0.08616569886023323  accuracy:  97.16214354594297\n",
            "epoch:  2730  loss:  0.04259396778612832  accuracy:  98.711943793911\n",
            "epoch:  2731  loss:  0.0361781526396195  accuracy:  98.79459980713597\n",
            "epoch:  2732  loss:  0.027118343354284532  accuracy:  99.10455985672958\n",
            "epoch:  2733  loss:  0.025521426079690844  accuracy:  99.2698718831795\n",
            "epoch:  2734  loss:  0.020861350183372228  accuracy:  99.35252789640447\n",
            "epoch:  2735  loss:  0.028516497098554538  accuracy:  99.04256784681085\n",
            "epoch:  2736  loss:  0.027347317851012676  accuracy:  99.10455985672958\n",
            "epoch:  2737  loss:  0.03465405016048782  accuracy:  98.71883179501309\n",
            "epoch:  2738  loss:  0.02446066601573831  accuracy:  99.21476787436286\n",
            "epoch:  2739  loss:  0.026385808405254042  accuracy:  99.11833585893373\n",
            "epoch:  2740  loss:  0.049230317705194  accuracy:  98.41575974652156\n",
            "epoch:  2741  loss:  0.07029465524062005  accuracy:  97.52031960325114\n",
            "epoch:  2742  loss:  0.04236232430522358  accuracy:  98.56040776966525\n",
            "epoch:  2743  loss:  0.023540466783128454  accuracy:  99.19410387105663\n",
            "epoch:  2744  loss:  0.019469502164128686  accuracy:  99.46273591403775\n",
            "epoch:  2745  loss:  0.022481814703577827  accuracy:  99.26298388207742\n",
            "epoch:  2746  loss:  0.022368706100671522  accuracy:  99.24920787987327\n",
            "epoch:  2747  loss:  0.020782906502174278  accuracy:  99.33186389309822\n",
            "epoch:  2748  loss:  0.020896289507845753  accuracy:  99.42140790742526\n",
            "epoch:  2749  loss:  0.021686070852084537  accuracy:  99.2354318776691\n",
            "epoch:  2750  loss:  0.030951391990480137  accuracy:  99.00812784130045\n",
            "epoch:  2751  loss:  0.030982327143805246  accuracy:  98.9943518390963\n",
            "epoch:  2752  loss:  0.038500384009929604  accuracy:  98.54663176746108\n",
            "epoch:  2753  loss:  0.10336645846212143  accuracy:  96.72819947651192\n",
            "epoch:  2754  loss:  0.05816360996793101  accuracy:  98.00936768149883\n",
            "epoch:  2755  loss:  0.028187972326360243  accuracy:  99.07700785232126\n",
            "epoch:  2756  loss:  0.023640908306906672  accuracy:  99.3043118886899\n",
            "epoch:  2757  loss:  0.028256249019393973  accuracy:  98.9943518390963\n",
            "epoch:  2758  loss:  0.023498405361986722  accuracy:  99.28364788538366\n",
            "epoch:  2759  loss:  0.02122876981498715  accuracy:  99.3731918997107\n",
            "epoch:  2760  loss:  0.02085642820806772  accuracy:  99.35941589750654\n",
            "epoch:  2761  loss:  0.020097335471473618  accuracy:  99.42140790742526\n",
            "epoch:  2762  loss:  0.02190959444200898  accuracy:  99.31808789089406\n",
            "epoch:  2763  loss:  0.029005868585051782  accuracy:  98.98057583689213\n",
            "epoch:  2764  loss:  0.038023093219177795  accuracy:  98.5741837718694\n",
            "epoch:  2765  loss:  0.08287615091885685  accuracy:  97.27235156357625\n",
            "epoch:  2766  loss:  0.0654749578051808  accuracy:  97.60986361757818\n",
            "epoch:  2767  loss:  0.04683142869495536  accuracy:  98.41575974652156\n",
            "epoch:  2768  loss:  0.04111094014985477  accuracy:  98.72571979611517\n",
            "epoch:  2769  loss:  0.030025682938819537  accuracy:  99.03567984570877\n",
            "epoch:  2770  loss:  0.02436503355627009  accuracy:  99.21476787436286\n",
            "epoch:  2771  loss:  0.02581960937962293  accuracy:  99.26298388207742\n",
            "epoch:  2772  loss:  0.023149285070285845  accuracy:  99.2354318776691\n",
            "epoch:  2773  loss:  0.01936083390550794  accuracy:  99.46273591403775\n",
            "epoch:  2774  loss:  0.02326188679677535  accuracy:  99.2698718831795\n",
            "epoch:  2775  loss:  0.02718687469771183  accuracy:  99.14588786334205\n",
            "epoch:  2776  loss:  0.08663025542101674  accuracy:  97.21035955365753\n",
            "epoch:  2777  loss:  0.06764689352324088  accuracy:  97.78206364513018\n",
            "epoch:  2778  loss:  0.030604632294791073  accuracy:  98.96679983468798\n",
            "epoch:  2779  loss:  0.030160687582723604  accuracy:  99.00123984019838\n",
            "epoch:  2780  loss:  0.025719024116648864  accuracy:  99.29742388758783\n",
            "epoch:  2781  loss:  0.026839945185826896  accuracy:  99.12522386003582\n",
            "epoch:  2782  loss:  0.03296925052098508  accuracy:  98.90480782476925\n",
            "epoch:  2783  loss:  0.026769520600596685  accuracy:  99.11833585893373\n",
            "epoch:  2784  loss:  0.01986830167246941  accuracy:  99.42829590852735\n",
            "epoch:  2785  loss:  0.021958831307865842  accuracy:  99.3043118886899\n",
            "epoch:  2786  loss:  0.02132866717849344  accuracy:  99.31119988979198\n",
            "epoch:  2787  loss:  0.03628113907318599  accuracy:  98.78771180603388\n",
            "epoch:  2788  loss:  0.06522737731856891  accuracy:  97.80272764843643\n",
            "epoch:  2789  loss:  0.026091249647372847  accuracy:  99.19410387105663\n",
            "epoch:  2790  loss:  0.026090401480812694  accuracy:  99.14588786334205\n",
            "epoch:  2791  loss:  0.02868454801183636  accuracy:  99.04256784681085\n",
            "epoch:  2792  loss:  0.02269291773208542  accuracy:  99.28364788538366\n",
            "epoch:  2793  loss:  0.021371830047429877  accuracy:  99.3731918997107\n",
            "epoch:  2794  loss:  0.022218297510804952  accuracy:  99.32497589199615\n",
            "epoch:  2795  loss:  0.02167311143328286  accuracy:  99.40763190522111\n",
            "epoch:  2796  loss:  0.04095997927405832  accuracy:  98.69127979060477\n",
            "epoch:  2797  loss:  0.0933518500034834  accuracy:  97.27923956467833\n",
            "epoch:  2798  loss:  0.07523620840434546  accuracy:  97.5685356109657\n",
            "epoch:  2799  loss:  0.024810661555628777  accuracy:  99.20787987326078\n",
            "epoch:  2800  loss:  0.02497484684360621  accuracy:  99.09078385452541\n",
            "epoch:  2801  loss:  0.02019611944750214  accuracy:  99.40763190522111\n",
            "epoch:  2802  loss:  0.021054431420478536  accuracy:  99.3731918997107\n",
            "epoch:  2803  loss:  0.021333823234843837  accuracy:  99.32497589199615\n",
            "epoch:  2804  loss:  0.023173108042500307  accuracy:  99.3043118886899\n",
            "epoch:  2805  loss:  0.028374234604357878  accuracy:  98.95991183358589\n",
            "epoch:  2806  loss:  0.02397681710031615  accuracy:  99.27675988428157\n",
            "epoch:  2807  loss:  0.05193935500868183  accuracy:  98.30555172888828\n",
            "epoch:  2808  loss:  0.07249984083260214  accuracy:  97.48587959774073\n",
            "epoch:  2809  loss:  0.08178745569420827  accuracy:  97.2861275657804\n",
            "epoch:  2810  loss:  0.04063822534143153  accuracy:  98.66372778619645\n",
            "epoch:  2811  loss:  0.021082012855039453  accuracy:  99.40074390411903\n",
            "epoch:  2812  loss:  0.022600265139973562  accuracy:  99.22854387656702\n",
            "epoch:  2813  loss:  0.01948519653586417  accuracy:  99.42140790742526\n",
            "epoch:  2814  loss:  0.019458667952140102  accuracy:  99.43518390962943\n",
            "epoch:  2815  loss:  0.023473154890213333  accuracy:  99.24231987877118\n",
            "epoch:  2816  loss:  0.022644946689971888  accuracy:  99.31808789089406\n",
            "epoch:  2817  loss:  0.026800791206940924  accuracy:  99.11144785783166\n",
            "epoch:  2818  loss:  0.026890400375153205  accuracy:  99.10455985672958\n",
            "epoch:  2819  loss:  0.026416107499035404  accuracy:  99.15966386554622\n",
            "epoch:  2820  loss:  0.023675682818364928  accuracy:  99.3387518942003\n",
            "epoch:  2821  loss:  0.02382834743597265  accuracy:  99.21476787436286\n",
            "epoch:  2822  loss:  0.023176158198329563  accuracy:  99.2698718831795\n",
            "epoch:  2823  loss:  0.0532462937053781  accuracy:  98.03691968590715\n",
            "epoch:  2824  loss:  0.04843767914406053  accuracy:  98.24355971896955\n",
            "epoch:  2825  loss:  0.0732043135495794  accuracy:  97.69251963080315\n",
            "epoch:  2826  loss:  0.07532533710056005  accuracy:  97.83027965284474\n",
            "epoch:  2827  loss:  0.039657003457941147  accuracy:  98.61551177848189\n",
            "epoch:  2828  loss:  0.01966159207693014  accuracy:  99.42829590852735\n",
            "epoch:  2829  loss:  0.030854327515519992  accuracy:  99.0976718556275\n",
            "epoch:  2830  loss:  0.03389102565213799  accuracy:  98.74638379942141\n",
            "epoch:  2831  loss:  0.022363452855954345  accuracy:  99.33186389309822\n",
            "epoch:  2832  loss:  0.01989693886172301  accuracy:  99.35252789640447\n",
            "epoch:  2833  loss:  0.02957644426804136  accuracy:  99.07011985121918\n",
            "epoch:  2834  loss:  0.03151329051522185  accuracy:  99.02190384350462\n",
            "epoch:  2835  loss:  0.06168934115481834  accuracy:  98.29866372778619\n",
            "epoch:  2836  loss:  0.04653938502850267  accuracy:  98.42953574872573\n",
            "epoch:  2837  loss:  0.027635055329497452  accuracy:  99.08389585342334\n",
            "epoch:  2838  loss:  0.020287929752709186  accuracy:  99.40074390411903\n",
            "epoch:  2839  loss:  0.05438349890384224  accuracy:  98.48463975754237\n",
            "epoch:  2840  loss:  0.05303029029563794  accuracy:  98.32621573219451\n",
            "epoch:  2841  loss:  0.025701315324270606  accuracy:  99.25609588097534\n",
            "epoch:  2842  loss:  0.018325077057016144  accuracy:  99.46273591403775\n",
            "epoch:  2843  loss:  0.023227692184788113  accuracy:  99.18032786885246\n",
            "epoch:  2844  loss:  0.020800136452369347  accuracy:  99.45584791293567\n",
            "epoch:  2845  loss:  0.019074101750707485  accuracy:  99.44895991183358\n",
            "epoch:  2846  loss:  0.0252347164995838  accuracy:  99.12522386003582\n",
            "epoch:  2847  loss:  0.020685510546492984  accuracy:  99.3387518942003\n",
            "epoch:  2848  loss:  0.02696203509330768  accuracy:  99.02190384350462\n",
            "epoch:  2849  loss:  0.027638642352553196  accuracy:  99.04256784681085\n",
            "epoch:  2850  loss:  0.03426212447239716  accuracy:  98.76015980162556\n",
            "epoch:  2851  loss:  0.029065411200587546  accuracy:  98.94613583138174\n",
            "epoch:  2852  loss:  0.023646450572041455  accuracy:  99.29742388758783\n",
            "epoch:  2853  loss:  0.03424721113780755  accuracy:  98.80148780823805\n",
            "epoch:  2854  loss:  0.06618239964549802  accuracy:  97.62363961978234\n",
            "epoch:  2855  loss:  0.131095665949137  accuracy:  96.0738393718143\n",
            "epoch:  2856  loss:  0.03393282067776855  accuracy:  98.91169582587133\n",
            "epoch:  2857  loss:  0.01904076278084723  accuracy:  99.36630389860862\n",
            "epoch:  2858  loss:  0.01765588642849072  accuracy:  99.54539192726271\n",
            "epoch:  2859  loss:  0.016081310394284846  accuracy:  99.49717591954814\n",
            "epoch:  2860  loss:  0.017324988087409558  accuracy:  99.49028791844607\n",
            "epoch:  2861  loss:  0.025427231523869703  accuracy:  99.22854387656702\n",
            "epoch:  2862  loss:  0.021439361871227997  accuracy:  99.29053588648574\n",
            "epoch:  2863  loss:  0.017531617104654094  accuracy:  99.53161592505855\n",
            "epoch:  2864  loss:  0.023486264123329756  accuracy:  99.24231987877118\n",
            "epoch:  2865  loss:  0.02125068762386994  accuracy:  99.27675988428157\n",
            "epoch:  2866  loss:  0.022944236997520608  accuracy:  99.2698718831795\n",
            "epoch:  2867  loss:  0.028646377395627576  accuracy:  99.02190384350462\n",
            "epoch:  2868  loss:  0.043248237234162185  accuracy:  98.38820774211324\n",
            "epoch:  2869  loss:  0.08445300313449482  accuracy:  97.38255958120953\n",
            "epoch:  2870  loss:  0.09464574776954753  accuracy:  97.16903154704505\n",
            "epoch:  2871  loss:  0.034103897316356956  accuracy:  98.93235982917757\n",
            "epoch:  2872  loss:  0.025836017345815882  accuracy:  99.15277586444414\n",
            "epoch:  2873  loss:  0.02238105295680413  accuracy:  99.40763190522111\n",
            "epoch:  2874  loss:  0.019489077258114048  accuracy:  99.39385590301694\n",
            "epoch:  2875  loss:  0.021883709325717756  accuracy:  99.35252789640447\n",
            "epoch:  2876  loss:  0.02334656234000395  accuracy:  99.2009918721587\n",
            "epoch:  2877  loss:  0.028828580375692282  accuracy:  98.98746383799421\n",
            "epoch:  2878  loss:  0.01879824404288476  accuracy:  99.43518390962943\n",
            "epoch:  2879  loss:  0.020336792877751975  accuracy:  99.33186389309822\n",
            "epoch:  2880  loss:  0.02301857540217018  accuracy:  99.14588786334205\n",
            "epoch:  2881  loss:  0.022474014605438478  accuracy:  99.2354318776691\n",
            "epoch:  2882  loss:  0.04532151164853041  accuracy:  98.48463975754237\n",
            "epoch:  2883  loss:  0.14626390543586829  accuracy:  95.74321531891445\n",
            "epoch:  2884  loss:  0.07447932037014378  accuracy:  97.74762363961979\n",
            "epoch:  2885  loss:  0.023934716363046803  accuracy:  99.18032786885246\n",
            "epoch:  2886  loss:  0.018236206267905328  accuracy:  99.46962391513982\n",
            "epoch:  2887  loss:  0.021673918459832592  accuracy:  99.3387518942003\n",
            "epoch:  2888  loss:  0.019346808152027477  accuracy:  99.4420719107315\n",
            "epoch:  2889  loss:  0.018847409960539133  accuracy:  99.4765119162419\n",
            "epoch:  2890  loss:  0.020727747991498402  accuracy:  99.36630389860862\n",
            "epoch:  2891  loss:  0.018609464492599828  accuracy:  99.49717591954814\n",
            "epoch:  2892  loss:  0.017957381313933693  accuracy:  99.4420719107315\n",
            "epoch:  2893  loss:  0.021799054214428588  accuracy:  99.29053588648574\n",
            "epoch:  2894  loss:  0.024405746404105318  accuracy:  99.18032786885246\n",
            "epoch:  2895  loss:  0.02222937446954002  accuracy:  99.31808789089406\n",
            "epoch:  2896  loss:  0.020290540361008823  accuracy:  99.35252789640447\n",
            "epoch:  2897  loss:  0.021416970577929028  accuracy:  99.31119988979198\n",
            "epoch:  2898  loss:  0.022950110791232076  accuracy:  99.19410387105663\n",
            "epoch:  2899  loss:  0.05676520249362045  accuracy:  98.00247968039675\n",
            "epoch:  2900  loss:  0.09085120620876488  accuracy:  97.02438352390136\n",
            "epoch:  2901  loss:  0.07161951528460286  accuracy:  97.56164760986361\n",
            "epoch:  2902  loss:  0.044829144258678726  accuracy:  98.51219176195069\n",
            "epoch:  2903  loss:  0.04212151446354959  accuracy:  98.59484777517564\n",
            "epoch:  2904  loss:  0.024210721588182802  accuracy:  99.31119988979198\n",
            "epoch:  2905  loss:  0.025294089458527676  accuracy:  99.20787987326078\n",
            "epoch:  2906  loss:  0.018669518548629603  accuracy:  99.40763190522111\n",
            "epoch:  2907  loss:  0.017759516182507488  accuracy:  99.39385590301694\n",
            "epoch:  2908  loss:  0.01843877660686912  accuracy:  99.39385590301694\n",
            "epoch:  2909  loss:  0.021544337315303468  accuracy:  99.2698718831795\n",
            "epoch:  2910  loss:  0.021151864695970756  accuracy:  99.24920787987327\n",
            "epoch:  2911  loss:  0.021168789341170786  accuracy:  99.35941589750654\n",
            "epoch:  2912  loss:  0.02552785091547321  accuracy:  99.22854387656702\n",
            "epoch:  2913  loss:  0.031016597141569343  accuracy:  98.93924783027965\n",
            "epoch:  2914  loss:  0.02025807214531222  accuracy:  99.39385590301694\n",
            "epoch:  2915  loss:  0.023280357998981968  accuracy:  99.27675988428157\n",
            "epoch:  2916  loss:  0.03135234031335899  accuracy:  98.95302383248381\n",
            "epoch:  2917  loss:  0.09301287245263506  accuracy:  97.10703953712633\n",
            "epoch:  2918  loss:  0.08965061312538286  accuracy:  96.99683151949304\n",
            "epoch:  2919  loss:  0.03779549496546018  accuracy:  98.83592781374846\n",
            "epoch:  2920  loss:  0.017968166984742417  accuracy:  99.53161592505855\n",
            "epoch:  2921  loss:  0.016976732536336966  accuracy:  99.55227992836478\n",
            "epoch:  2922  loss:  0.018344704823233346  accuracy:  99.39385590301694\n",
            "epoch:  2923  loss:  0.017831046967567675  accuracy:  99.43518390962943\n",
            "epoch:  2924  loss:  0.01799474237647094  accuracy:  99.49028791844607\n",
            "epoch:  2925  loss:  0.021506583991267154  accuracy:  99.34563989530238\n",
            "epoch:  2926  loss:  0.019473602521275727  accuracy:  99.46273591403775\n",
            "epoch:  2927  loss:  0.019284219520759514  accuracy:  99.45584791293567\n",
            "epoch:  2928  loss:  0.020766230507881192  accuracy:  99.29053588648574\n",
            "epoch:  2929  loss:  0.023310745859069344  accuracy:  99.17343986775037\n",
            "epoch:  2930  loss:  0.027283611656390493  accuracy:  99.07700785232126\n",
            "epoch:  2931  loss:  0.0490408420561397  accuracy:  98.36065573770492\n",
            "epoch:  2932  loss:  0.059233250690977964  accuracy:  98.06447169031547\n",
            "epoch:  2933  loss:  0.05639817417314565  accuracy:  98.3331037332966\n",
            "epoch:  2934  loss:  0.04055705820779926  accuracy:  98.77393580382973\n",
            "epoch:  2935  loss:  0.027930152991560535  accuracy:  99.21476787436286\n",
            "epoch:  2936  loss:  0.024518723942203165  accuracy:  99.18032786885246\n",
            "epoch:  2937  loss:  0.0202763142662857  accuracy:  99.33186389309822\n",
            "epoch:  2938  loss:  0.02080356747764293  accuracy:  99.35252789640447\n",
            "epoch:  2939  loss:  0.019500954087745624  accuracy:  99.45584791293567\n",
            "epoch:  2940  loss:  0.020742662241341137  accuracy:  99.43518390962943\n",
            "epoch:  2941  loss:  0.02066040073661538  accuracy:  99.38696790191486\n",
            "epoch:  2942  loss:  0.026781860817639988  accuracy:  99.1321118611379\n",
            "epoch:  2943  loss:  0.020919667479902492  accuracy:  99.34563989530238\n",
            "epoch:  2944  loss:  0.018933773702441595  accuracy:  99.40763190522111\n",
            "epoch:  2945  loss:  0.022091482080727556  accuracy:  99.29053588648574\n",
            "epoch:  2946  loss:  0.02495683270065469  accuracy:  99.1665518666483\n",
            "epoch:  2947  loss:  0.07574054587646274  accuracy:  97.41011158561786\n",
            "epoch:  2948  loss:  0.12131828983676267  accuracy:  96.42512742802039\n",
            "epoch:  2949  loss:  0.04601184771606502  accuracy:  98.46397575423612\n",
            "epoch:  2950  loss:  0.02573898127734895  accuracy:  99.1321118611379\n",
            "epoch:  2951  loss:  0.018968748202143802  accuracy:  99.35941589750654\n",
            "epoch:  2952  loss:  0.016702141934638336  accuracy:  99.46962391513982\n",
            "epoch:  2953  loss:  0.017704725712336337  accuracy:  99.46962391513982\n",
            "epoch:  2954  loss:  0.01890010754606041  accuracy:  99.46273591403775\n",
            "epoch:  2955  loss:  0.018883645368047406  accuracy:  99.38007990081279\n",
            "epoch:  2956  loss:  0.0185400518661339  accuracy:  99.4765119162419\n",
            "epoch:  2957  loss:  0.018685024260186745  accuracy:  99.42140790742526\n",
            "epoch:  2958  loss:  0.016914567906349973  accuracy:  99.46962391513982\n",
            "epoch:  2959  loss:  0.019607778333923208  accuracy:  99.3731918997107\n",
            "epoch:  2960  loss:  0.018711519524751953  accuracy:  99.43518390962943\n",
            "epoch:  2961  loss:  0.01813654095767894  accuracy:  99.4420719107315\n",
            "epoch:  2962  loss:  0.036282967740457125  accuracy:  98.70505579280892\n",
            "epoch:  2963  loss:  0.03841968452737412  accuracy:  98.65683978509436\n",
            "epoch:  2964  loss:  0.0921907987522444  accuracy:  97.32056757129081\n",
            "epoch:  2965  loss:  0.07387178742731836  accuracy:  97.4996555999449\n",
            "epoch:  2966  loss:  0.04963577021568201  accuracy:  98.24355971896955\n",
            "epoch:  2967  loss:  0.019098992242105383  accuracy:  99.48339991734399\n",
            "epoch:  2968  loss:  0.01848445035315658  accuracy:  99.41451990632318\n",
            "epoch:  2969  loss:  0.018064507954466673  accuracy:  99.4765119162419\n",
            "epoch:  2970  loss:  0.017825973604168505  accuracy:  99.51783992285439\n",
            "epoch:  2971  loss:  0.020244813075075897  accuracy:  99.4420719107315\n",
            "epoch:  2972  loss:  0.018430342224812362  accuracy:  99.45584791293567\n",
            "epoch:  2973  loss:  0.018664951253555873  accuracy:  99.42829590852735\n",
            "epoch:  2974  loss:  0.018067691727773737  accuracy:  99.4420719107315\n",
            "epoch:  2975  loss:  0.02078115724349572  accuracy:  99.35941589750654\n",
            "epoch:  2976  loss:  0.023141721265644805  accuracy:  99.35941589750654\n",
            "epoch:  2977  loss:  0.018001959446776197  accuracy:  99.42829590852735\n",
            "epoch:  2978  loss:  0.07992033620241412  accuracy:  97.10015153602424\n",
            "epoch:  2979  loss:  0.10309492656826369  accuracy:  96.85907149745144\n",
            "epoch:  2980  loss:  0.02643105273482312  accuracy:  99.09078385452541\n",
            "epoch:  2981  loss:  0.018960477005308517  accuracy:  99.46962391513982\n",
            "epoch:  2982  loss:  0.019979685697386885  accuracy:  99.46273591403775\n",
            "epoch:  2983  loss:  0.017403017965526842  accuracy:  99.49028791844607\n",
            "epoch:  2984  loss:  0.014658339426080788  accuracy:  99.55916792946687\n",
            "epoch:  2985  loss:  0.0170019500076623  accuracy:  99.44895991183358\n",
            "epoch:  2986  loss:  0.0191750815794791  accuracy:  99.3731918997107\n",
            "epoch:  2987  loss:  0.024235658360019587  accuracy:  99.2009918721587\n",
            "epoch:  2988  loss:  0.03562155940681814  accuracy:  98.87036781925885\n",
            "epoch:  2989  loss:  0.042755272710881385  accuracy:  98.60173577627772\n",
            "epoch:  2990  loss:  0.028659257712824144  accuracy:  99.12522386003582\n",
            "epoch:  2991  loss:  0.017535202108796485  accuracy:  99.49028791844607\n",
            "epoch:  2992  loss:  0.017821124201283945  accuracy:  99.46273591403775\n",
            "epoch:  2993  loss:  0.01761996575768738  accuracy:  99.49028791844607\n",
            "epoch:  2994  loss:  0.016524082056174467  accuracy:  99.51095192175231\n",
            "epoch:  2995  loss:  0.039411215268715424  accuracy:  98.45708775313405\n",
            "epoch:  2996  loss:  0.09819056078604815  accuracy:  97.03127152500345\n",
            "epoch:  2997  loss:  0.07785019432844366  accuracy:  97.75451164072186\n",
            "epoch:  2998  loss:  0.024380137186433556  accuracy:  99.28364788538366\n",
            "epoch:  2999  loss:  0.017208737632643852  accuracy:  99.54539192726271\n",
            "epoch:  3000  loss:  0.016093115398693916  accuracy:  99.5798319327731\n",
            "epoch:  3001  loss:  0.01955792922608068  accuracy:  99.39385590301694\n",
            "epoch:  3002  loss:  0.019341516107057  accuracy:  99.40074390411903\n",
            "epoch:  3003  loss:  0.024666276926033376  accuracy:  99.20787987326078\n",
            "epoch:  3004  loss:  0.04140804198223885  accuracy:  98.47775175644028\n",
            "epoch:  3005  loss:  0.03561578587641603  accuracy:  98.83592781374846\n",
            "epoch:  3006  loss:  0.02044347068330165  accuracy:  99.35252789640447\n",
            "epoch:  3007  loss:  0.022220709895533448  accuracy:  99.33186389309822\n",
            "epoch:  3008  loss:  0.02497731271478419  accuracy:  99.24920787987327\n",
            "epoch:  3009  loss:  0.021889023221967625  accuracy:  99.3731918997107\n",
            "epoch:  3010  loss:  0.025791258850598197  accuracy:  99.15277586444414\n",
            "epoch:  3011  loss:  0.02524578049168235  accuracy:  99.27675988428157\n",
            "epoch:  3012  loss:  0.016772584277575314  accuracy:  99.53161592505855\n",
            "epoch:  3013  loss:  0.017239106487220286  accuracy:  99.51095192175231\n",
            "epoch:  3014  loss:  0.019605184606743334  accuracy:  99.4420719107315\n",
            "epoch:  3015  loss:  0.027055528522128468  accuracy:  99.11144785783166\n",
            "epoch:  3016  loss:  0.07836451162842649  accuracy:  97.79583964733435\n",
            "epoch:  3017  loss:  0.13818915096027046  accuracy:  96.02562336409974\n",
            "epoch:  3018  loss:  0.03543777223140153  accuracy:  98.84970381595261\n",
            "epoch:  3019  loss:  0.021475311058540964  accuracy:  99.40763190522111\n",
            "epoch:  3020  loss:  0.01635783933588568  accuracy:  99.55916792946687\n",
            "epoch:  3021  loss:  0.015309095253140496  accuracy:  99.51095192175231\n",
            "epoch:  3022  loss:  0.0159517458189966  accuracy:  99.50406392065022\n",
            "epoch:  3023  loss:  0.017383547119016473  accuracy:  99.49717591954814\n",
            "epoch:  3024  loss:  0.019223052314124033  accuracy:  99.3731918997107\n",
            "epoch:  3025  loss:  0.024071961184727514  accuracy:  99.22165587546495\n",
            "epoch:  3026  loss:  0.016435360036607418  accuracy:  99.46962391513982\n",
            "epoch:  3027  loss:  0.017799898661749535  accuracy:  99.49717591954814\n",
            "epoch:  3028  loss:  0.018943371026782375  accuracy:  99.42829590852735\n",
            "epoch:  3029  loss:  0.01867809014340737  accuracy:  99.48339991734399\n",
            "epoch:  3030  loss:  0.02902874427501542  accuracy:  99.07011985121918\n",
            "epoch:  3031  loss:  0.02984889603404292  accuracy:  99.07011985121918\n",
            "epoch:  3032  loss:  0.028637204033003554  accuracy:  99.00812784130045\n",
            "epoch:  3033  loss:  0.03510846040621662  accuracy:  98.91169582587133\n",
            "epoch:  3034  loss:  0.05345721004364255  accuracy:  98.16779170684667\n",
            "epoch:  3035  loss:  0.03796858239613852  accuracy:  98.6086237773798\n",
            "epoch:  3036  loss:  0.045311716862490144  accuracy:  98.38820774211324\n",
            "epoch:  3037  loss:  0.02627996618314584  accuracy:  99.18032786885246\n",
            "epoch:  3038  loss:  0.023972708313634926  accuracy:  99.22165587546495\n",
            "epoch:  3039  loss:  0.021119857561142166  accuracy:  99.34563989530238\n",
            "epoch:  3040  loss:  0.02545912909698173  accuracy:  99.26298388207742\n",
            "epoch:  3041  loss:  0.03096329144092862  accuracy:  98.9943518390963\n",
            "epoch:  3042  loss:  0.03727585075605049  accuracy:  98.83592781374846\n",
            "epoch:  3043  loss:  0.030663639651954004  accuracy:  98.90480782476925\n",
            "epoch:  3044  loss:  0.017701475087831414  accuracy:  99.44895991183358\n",
            "epoch:  3045  loss:  0.018125309487297347  accuracy:  99.49028791844607\n",
            "epoch:  3046  loss:  0.016867866091784804  accuracy:  99.43518390962943\n",
            "epoch:  3047  loss:  0.01655172553415205  accuracy:  99.45584791293567\n",
            "epoch:  3048  loss:  0.02960846717585505  accuracy:  99.20787987326078\n",
            "epoch:  3049  loss:  0.02333060223364158  accuracy:  99.29053588648574\n",
            "epoch:  3050  loss:  0.027046295470823815  accuracy:  99.00123984019838\n",
            "epoch:  3051  loss:  0.02229158589090071  accuracy:  99.27675988428157\n",
            "epoch:  3052  loss:  0.05359185227271329  accuracy:  98.20911971345916\n",
            "epoch:  3053  loss:  0.08976856752204215  accuracy:  97.03815952610553\n",
            "epoch:  3054  loss:  0.09279219532878906  accuracy:  96.81085548973688\n",
            "epoch:  3055  loss:  0.025908310970458027  accuracy:  99.29053588648574\n",
            "epoch:  3056  loss:  0.018812153148020302  accuracy:  99.46273591403775\n",
            "epoch:  3057  loss:  0.015526256233300818  accuracy:  99.55916792946687\n",
            "epoch:  3058  loss:  0.017203130758689383  accuracy:  99.45584791293567\n",
            "epoch:  3059  loss:  0.013722850568316706  accuracy:  99.5798319327731\n",
            "epoch:  3060  loss:  0.01695743580625274  accuracy:  99.45584791293567\n",
            "epoch:  3061  loss:  0.016527766064499644  accuracy:  99.49717591954814\n",
            "epoch:  3062  loss:  0.01416210696360481  accuracy:  99.60738393718142\n",
            "epoch:  3063  loss:  0.017603924513774852  accuracy:  99.44895991183358\n",
            "epoch:  3064  loss:  0.035941227388603246  accuracy:  98.80837580934013\n",
            "epoch:  3065  loss:  0.07841658378721725  accuracy:  97.43766359002618\n",
            "epoch:  3066  loss:  0.03742871971781422  accuracy:  98.8152638104422\n",
            "epoch:  3067  loss:  0.02579787648850027  accuracy:  99.21476787436286\n",
            "epoch:  3068  loss:  0.019205917477476093  accuracy:  99.48339991734399\n",
            "epoch:  3069  loss:  0.02041792216679826  accuracy:  99.42829590852735\n",
            "epoch:  3070  loss:  0.016519447350005958  accuracy:  99.46273591403775\n",
            "epoch:  3071  loss:  0.01508986445570798  accuracy:  99.54539192726271\n",
            "epoch:  3072  loss:  0.014877659560044306  accuracy:  99.53161592505855\n",
            "epoch:  3073  loss:  0.018035845863849043  accuracy:  99.50406392065022\n",
            "epoch:  3074  loss:  0.02671588336012104  accuracy:  99.10455985672958\n",
            "epoch:  3075  loss:  0.03847668096039535  accuracy:  98.63617578178813\n",
            "epoch:  3076  loss:  0.033578592316773674  accuracy:  98.98746383799421\n",
            "epoch:  3077  loss:  0.028254404732743738  accuracy:  99.07700785232126\n",
            "epoch:  3078  loss:  0.04696126933502633  accuracy:  98.45708775313405\n",
            "epoch:  3079  loss:  0.04440681649593169  accuracy:  98.59484777517564\n",
            "epoch:  3080  loss:  0.02718771005197918  accuracy:  99.1665518666483\n",
            "epoch:  3081  loss:  0.07194699283062135  accuracy:  97.48587959774073\n",
            "epoch:  3082  loss:  0.029088124245051604  accuracy:  99.0287918446067\n",
            "epoch:  3083  loss:  0.018815548365101995  accuracy:  99.43518390962943\n",
            "epoch:  3084  loss:  0.015818604746047484  accuracy:  99.51095192175231\n",
            "epoch:  3085  loss:  0.02725791041826849  accuracy:  99.1665518666483\n",
            "epoch:  3086  loss:  0.042213801409601306  accuracy:  98.72571979611517\n",
            "epoch:  3087  loss:  0.019356307434700744  accuracy:  99.38696790191486\n",
            "epoch:  3088  loss:  0.015749576215361293  accuracy:  99.53161592505855\n",
            "epoch:  3089  loss:  0.01486725843707691  accuracy:  99.53850392616063\n",
            "epoch:  3090  loss:  0.01736484275627735  accuracy:  99.46962391513982\n",
            "epoch:  3091  loss:  0.014511918185950034  accuracy:  99.57294393167103\n",
            "epoch:  3092  loss:  0.020616601300776725  accuracy:  99.31808789089406\n",
            "epoch:  3093  loss:  0.017891408013639722  accuracy:  99.42829590852735\n",
            "epoch:  3094  loss:  0.05031975125961308  accuracy:  98.18156770905084\n",
            "epoch:  3095  loss:  0.11296091375035727  accuracy:  96.39068742250998\n",
            "epoch:  3096  loss:  0.0575322102926459  accuracy:  98.09202369472379\n",
            "epoch:  3097  loss:  0.020577752714514022  accuracy:  99.3731918997107\n",
            "epoch:  3098  loss:  0.019900333945854845  accuracy:  99.3387518942003\n",
            "epoch:  3099  loss:  0.016179303252136273  accuracy:  99.46962391513982\n",
            "epoch:  3100  loss:  0.013610077878445662  accuracy:  99.60738393718142\n",
            "epoch:  3101  loss:  0.01751089248175841  accuracy:  99.49028791844607\n",
            "epoch:  3102  loss:  0.01694565584228384  accuracy:  99.51783992285439\n",
            "epoch:  3103  loss:  0.02434459159283894  accuracy:  99.09078385452541\n",
            "epoch:  3104  loss:  0.018400394971363008  accuracy:  99.44895991183358\n",
            "epoch:  3105  loss:  0.017038456972231435  accuracy:  99.38007990081279\n",
            "epoch:  3106  loss:  0.019020288936842045  accuracy:  99.3731918997107\n",
            "epoch:  3107  loss:  0.016358566638964962  accuracy:  99.50406392065022\n",
            "epoch:  3108  loss:  0.01708886493310137  accuracy:  99.45584791293567\n",
            "epoch:  3109  loss:  0.016975951078963696  accuracy:  99.49028791844607\n",
            "epoch:  3110  loss:  0.02423769105111615  accuracy:  99.13899986223998\n",
            "epoch:  3111  loss:  0.05568826185032712  accuracy:  98.21600771456123\n",
            "epoch:  3112  loss:  0.1505055010399841  accuracy:  95.64678330348534\n",
            "epoch:  3113  loss:  0.05297573453375054  accuracy:  98.31932773109244\n",
            "epoch:  3114  loss:  0.026955119113743566  accuracy:  99.3387518942003\n",
            "epoch:  3115  loss:  0.01569510374128352  accuracy:  99.46273591403775\n",
            "epoch:  3116  loss:  0.015613771844929195  accuracy:  99.50406392065022\n",
            "epoch:  3117  loss:  0.013407021560345036  accuracy:  99.59360793497727\n",
            "epoch:  3118  loss:  0.013090441953335669  accuracy:  99.64182394269183\n",
            "epoch:  3119  loss:  0.01679744620839287  accuracy:  99.49717591954814\n",
            "epoch:  3120  loss:  0.019003356092276272  accuracy:  99.33186389309822\n",
            "epoch:  3121  loss:  0.015237717315431965  accuracy:  99.51783992285439\n",
            "epoch:  3122  loss:  0.018133472820084717  accuracy:  99.4420719107315\n",
            "epoch:  3123  loss:  0.01481159082412456  accuracy:  99.5798319327731\n",
            "epoch:  3124  loss:  0.016573546243226458  accuracy:  99.48339991734399\n",
            "epoch:  3125  loss:  0.017185938434009722  accuracy:  99.48339991734399\n",
            "epoch:  3126  loss:  0.01427996077245446  accuracy:  99.57294393167103\n",
            "epoch:  3127  loss:  0.03427491337336771  accuracy:  98.70505579280892\n",
            "epoch:  3128  loss:  0.08377137326832103  accuracy:  97.29301556688249\n",
            "epoch:  3129  loss:  0.06888785337566619  accuracy:  97.66496762639483\n",
            "epoch:  3130  loss:  0.025090878565577228  accuracy:  99.20787987326078\n",
            "epoch:  3131  loss:  0.015825815715910827  accuracy:  99.58671993387519\n",
            "epoch:  3132  loss:  0.02060078128321446  accuracy:  99.3731918997107\n",
            "epoch:  3133  loss:  0.015537875871544694  accuracy:  99.53161592505855\n",
            "epoch:  3134  loss:  0.019173615205798716  accuracy:  99.31119988979198\n",
            "epoch:  3135  loss:  0.018020608099114613  accuracy:  99.4420719107315\n",
            "epoch:  3136  loss:  0.018216963422991863  accuracy:  99.38696790191486\n",
            "epoch:  3137  loss:  0.02457383053562278  accuracy:  99.2009918721587\n",
            "epoch:  3138  loss:  0.034881988309578074  accuracy:  98.87725582036093\n",
            "epoch:  3139  loss:  0.03948990960411326  accuracy:  98.66372778619645\n",
            "epoch:  3140  loss:  0.02456057221572723  accuracy:  99.21476787436286\n",
            "epoch:  3141  loss:  0.06081144862315234  accuracy:  98.18845571015291\n",
            "epoch:  3142  loss:  0.04247905806784433  accuracy:  98.5053037608486\n",
            "epoch:  3143  loss:  0.019883136646637344  accuracy:  99.38696790191486\n",
            "epoch:  3144  loss:  0.016336742324207017  accuracy:  99.50406392065022\n",
            "epoch:  3145  loss:  0.019177740712728767  accuracy:  99.40074390411903\n",
            "epoch:  3146  loss:  0.02279119345883349  accuracy:  99.31808789089406\n",
            "epoch:  3147  loss:  0.021170975657672363  accuracy:  99.22854387656702\n",
            "epoch:  3148  loss:  0.01985730183736952  accuracy:  99.33186389309822\n",
            "epoch:  3149  loss:  0.021270392284083114  accuracy:  99.29742388758783\n",
            "epoch:  3150  loss:  0.01850458135633233  accuracy:  99.39385590301694\n",
            "epoch:  3151  loss:  0.014419657307195721  accuracy:  99.60049593607935\n",
            "epoch:  3152  loss:  0.014147767674683127  accuracy:  99.63493594158975\n",
            "epoch:  3153  loss:  0.02516403823470247  accuracy:  99.1665518666483\n",
            "epoch:  3154  loss:  0.09231828650035491  accuracy:  96.8384074941452\n",
            "epoch:  3155  loss:  0.07339665041213904  accuracy:  97.66496762639483\n",
            "epoch:  3156  loss:  0.031848851251388324  accuracy:  98.93924783027965\n",
            "epoch:  3157  loss:  0.017191762126922423  accuracy:  99.55227992836478\n",
            "epoch:  3158  loss:  0.023829927068113366  accuracy:  99.36630389860862\n",
            "epoch:  3159  loss:  0.020777855062912312  accuracy:  99.35941589750654\n",
            "epoch:  3160  loss:  0.021321507868133634  accuracy:  99.2354318776691\n",
            "epoch:  3161  loss:  0.014822074030783223  accuracy:  99.50406392065022\n",
            "epoch:  3162  loss:  0.014506266272721374  accuracy:  99.52472792395646\n",
            "epoch:  3163  loss:  0.02216290341920351  accuracy:  99.3043118886899\n",
            "epoch:  3164  loss:  0.016982404111101527  accuracy:  99.43518390962943\n",
            "epoch:  3165  loss:  0.01463335401377674  accuracy:  99.54539192726271\n",
            "epoch:  3166  loss:  0.014480943892699981  accuracy:  99.58671993387519\n",
            "epoch:  3167  loss:  0.02167571337174425  accuracy:  99.27675988428157\n",
            "epoch:  3168  loss:  0.018487697994099904  accuracy:  99.36630389860862\n",
            "epoch:  3169  loss:  0.033875320838466144  accuracy:  98.78082380493181\n",
            "epoch:  3170  loss:  0.08090363806035339  accuracy:  97.34123157459705\n",
            "epoch:  3171  loss:  0.10000622111796935  accuracy:  96.93483950957432\n",
            "epoch:  3172  loss:  0.04027979435210062  accuracy:  98.87725582036093\n",
            "epoch:  3173  loss:  0.036816070903013594  accuracy:  99.03567984570877\n",
            "epoch:  3174  loss:  0.018453754696282704  accuracy:  99.46962391513982\n",
            "epoch:  3175  loss:  0.012282194763727107  accuracy:  99.69003995040639\n",
            "epoch:  3176  loss:  0.013342367426757469  accuracy:  99.58671993387519\n",
            "epoch:  3177  loss:  0.014950391889099078  accuracy:  99.57294393167103\n",
            "epoch:  3178  loss:  0.013634967681310839  accuracy:  99.55916792946687\n",
            "epoch:  3179  loss:  0.027155115696023455  accuracy:  99.00812784130045\n",
            "epoch:  3180  loss:  0.013467064807102323  accuracy:  99.62115993938559\n",
            "epoch:  3181  loss:  0.013619536226162415  accuracy:  99.62115993938559\n",
            "epoch:  3182  loss:  0.020286960680425712  accuracy:  99.34563989530238\n",
            "epoch:  3183  loss:  0.014953838518067203  accuracy:  99.52472792395646\n",
            "epoch:  3184  loss:  0.02325921663189496  accuracy:  99.26298388207742\n",
            "epoch:  3185  loss:  0.01811846274575792  accuracy:  99.46962391513982\n",
            "epoch:  3186  loss:  0.02897843043326296  accuracy:  98.93924783027965\n",
            "epoch:  3187  loss:  0.02408245335339336  accuracy:  99.13899986223998\n",
            "epoch:  3188  loss:  0.018511735101593915  accuracy:  99.40763190522111\n",
            "epoch:  3189  loss:  0.016783777122366682  accuracy:  99.50406392065022\n",
            "epoch:  3190  loss:  0.016602535093690595  accuracy:  99.35252789640447\n",
            "epoch:  3191  loss:  0.021436304505475026  accuracy:  99.29742388758783\n",
            "epoch:  3192  loss:  0.04433894840338928  accuracy:  98.42953574872573\n",
            "epoch:  3193  loss:  0.1694660728175323  accuracy:  95.32304725168756\n",
            "epoch:  3194  loss:  0.03836097384453126  accuracy:  98.66372778619645\n",
            "epoch:  3195  loss:  0.016600612558415235  accuracy:  99.4420719107315\n",
            "epoch:  3196  loss:  0.014100171536879357  accuracy:  99.60049593607935\n",
            "epoch:  3197  loss:  0.01668319908195378  accuracy:  99.51783992285439\n",
            "epoch:  3198  loss:  0.014841010401608918  accuracy:  99.51783992285439\n",
            "epoch:  3199  loss:  0.019477504094048602  accuracy:  99.38007990081279\n",
            "epoch:  3200  loss:  0.01496587468645153  accuracy:  99.55916792946687\n",
            "epoch:  3201  loss:  0.014690689436860669  accuracy:  99.54539192726271\n",
            "epoch:  3202  loss:  0.013207493844823245  accuracy:  99.58671993387519\n",
            "epoch:  3203  loss:  0.015190303091218695  accuracy:  99.51783992285439\n",
            "epoch:  3204  loss:  0.018070267116886238  accuracy:  99.44895991183358\n",
            "epoch:  3205  loss:  0.015477685878358788  accuracy:  99.53850392616063\n",
            "epoch:  3206  loss:  0.017339055295650007  accuracy:  99.50406392065022\n",
            "epoch:  3207  loss:  0.018095332132412482  accuracy:  99.42829590852735\n",
            "epoch:  3208  loss:  0.019907161495128074  accuracy:  99.3731918997107\n",
            "epoch:  3209  loss:  0.045112211582906375  accuracy:  98.45708775313405\n",
            "epoch:  3210  loss:  0.14799752034247435  accuracy:  96.11516737842678\n",
            "epoch:  3211  loss:  0.10048751160451114  accuracy:  96.44579143132663\n",
            "epoch:  3212  loss:  0.02506465568419026  accuracy:  99.31119988979198\n",
            "epoch:  3213  loss:  0.018745470201334373  accuracy:  99.48339991734399\n",
            "epoch:  3214  loss:  0.012978131512575389  accuracy:  99.63493594158975\n",
            "epoch:  3215  loss:  0.013362334846327255  accuracy:  99.62804794048768\n",
            "epoch:  3216  loss:  0.014790540038277516  accuracy:  99.55227992836478\n",
            "epoch:  3217  loss:  0.013787508645495352  accuracy:  99.5798319327731\n",
            "epoch:  3218  loss:  0.01430680796611856  accuracy:  99.5798319327731\n",
            "epoch:  3219  loss:  0.013227195128895863  accuracy:  99.60738393718142\n",
            "epoch:  3220  loss:  0.01734721862433181  accuracy:  99.42829590852735\n",
            "epoch:  3221  loss:  0.01632133990378399  accuracy:  99.49028791844607\n",
            "epoch:  3222  loss:  0.013769969071824432  accuracy:  99.60738393718142\n",
            "epoch:  3223  loss:  0.013897927972532496  accuracy:  99.58671993387519\n",
            "epoch:  3224  loss:  0.019539888245797082  accuracy:  99.42140790742526\n",
            "epoch:  3225  loss:  0.022035720976152195  accuracy:  99.26298388207742\n",
            "epoch:  3226  loss:  0.02365015870090284  accuracy:  99.13899986223998\n",
            "epoch:  3227  loss:  0.018244814462512002  accuracy:  99.46962391513982\n",
            "epoch:  3228  loss:  0.022335225192099687  accuracy:  99.3043118886899\n",
            "epoch:  3229  loss:  0.11438333215707723  accuracy:  96.61110345777655\n",
            "epoch:  3230  loss:  0.11452216547501368  accuracy:  96.45267943242871\n",
            "epoch:  3231  loss:  0.022487314305856994  accuracy:  99.2354318776691\n",
            "epoch:  3232  loss:  0.014297368797581509  accuracy:  99.56605593056895\n",
            "epoch:  3233  loss:  0.014479882729417842  accuracy:  99.55227992836478\n",
            "epoch:  3234  loss:  0.015876306240871663  accuracy:  99.58671993387519\n",
            "epoch:  3235  loss:  0.01462754326270677  accuracy:  99.61427193828351\n",
            "epoch:  3236  loss:  0.014978078724350715  accuracy:  99.54539192726271\n",
            "epoch:  3237  loss:  0.01196677518412825  accuracy:  99.60049593607935\n",
            "epoch:  3238  loss:  0.014077662112644086  accuracy:  99.55227992836478\n",
            "epoch:  3239  loss:  0.016462433445930045  accuracy:  99.51095192175231\n",
            "epoch:  3240  loss:  0.01558393027726702  accuracy:  99.53850392616063\n",
            "epoch:  3241  loss:  0.022686000224544145  accuracy:  99.27675988428157\n",
            "epoch:  3242  loss:  0.019360481189070047  accuracy:  99.3731918997107\n",
            "epoch:  3243  loss:  0.02562368937344912  accuracy:  99.11144785783166\n",
            "epoch:  3244  loss:  0.03778112328940786  accuracy:  98.70505579280892\n",
            "epoch:  3245  loss:  0.024307263834144853  accuracy:  99.2354318776691\n",
            "epoch:  3246  loss:  0.03110359848039062  accuracy:  98.94613583138174\n",
            "epoch:  3247  loss:  0.05791936486942522  accuracy:  98.08513569362171\n",
            "epoch:  3248  loss:  0.05687036659107442  accuracy:  98.28488772558204\n",
            "epoch:  3249  loss:  0.025103707763248752  accuracy:  99.17343986775037\n",
            "epoch:  3250  loss:  0.018241000364883915  accuracy:  99.49028791844607\n",
            "epoch:  3251  loss:  0.014720898295985824  accuracy:  99.58671993387519\n",
            "epoch:  3252  loss:  0.01597168506902542  accuracy:  99.4765119162419\n",
            "epoch:  3253  loss:  0.015872630418857805  accuracy:  99.56605593056895\n",
            "epoch:  3254  loss:  0.013560922693838122  accuracy:  99.59360793497727\n",
            "epoch:  3255  loss:  0.015000522007170374  accuracy:  99.53850392616063\n",
            "epoch:  3256  loss:  0.0197222557164937  accuracy:  99.35252789640447\n",
            "epoch:  3257  loss:  0.017922049345806438  accuracy:  99.36630389860862\n",
            "epoch:  3258  loss:  0.019988779623449138  accuracy:  99.34563989530238\n",
            "epoch:  3259  loss:  0.01889628778006943  accuracy:  99.48339991734399\n",
            "epoch:  3260  loss:  0.0811740927932442  accuracy:  97.30679156908666\n",
            "epoch:  3261  loss:  0.09187624447947343  accuracy:  96.95550351288057\n",
            "epoch:  3262  loss:  0.051548756992640436  accuracy:  98.2642237222758\n",
            "epoch:  3263  loss:  0.01425045175252826  accuracy:  99.54539192726271\n",
            "epoch:  3264  loss:  0.014783739079088117  accuracy:  99.53850392616063\n",
            "epoch:  3265  loss:  0.015750569203640263  accuracy:  99.49717591954814\n",
            "epoch:  3266  loss:  0.012979628238243229  accuracy:  99.655599944896\n",
            "epoch:  3267  loss:  0.015507232760030965  accuracy:  99.56605593056895\n",
            "epoch:  3268  loss:  0.014143888859918904  accuracy:  99.59360793497727\n",
            "epoch:  3269  loss:  0.01660259189729516  accuracy:  99.48339991734399\n",
            "epoch:  3270  loss:  0.017968681758621336  accuracy:  99.36630389860862\n",
            "epoch:  3271  loss:  0.016802784950325  accuracy:  99.46962391513982\n",
            "epoch:  3272  loss:  0.013227239619948346  accuracy:  99.60738393718142\n",
            "epoch:  3273  loss:  0.02238317537644935  accuracy:  99.3731918997107\n",
            "epoch:  3274  loss:  0.08120601988568305  accuracy:  97.57542361206778\n",
            "epoch:  3275  loss:  0.07765694469861908  accuracy:  97.49276759884282\n",
            "epoch:  3276  loss:  0.04750653322391445  accuracy:  98.66372778619645\n",
            "epoch:  3277  loss:  0.02862513763021782  accuracy:  99.20787987326078\n",
            "epoch:  3278  loss:  0.023033836259669455  accuracy:  99.3387518942003\n",
            "epoch:  3279  loss:  0.013838947873666753  accuracy:  99.60049593607935\n",
            "epoch:  3280  loss:  0.014114340533246957  accuracy:  99.60738393718142\n",
            "epoch:  3281  loss:  0.014527589934847901  accuracy:  99.49717591954814\n",
            "epoch:  3282  loss:  0.017238247461174618  accuracy:  99.38696790191486\n",
            "epoch:  3283  loss:  0.013517176901919963  accuracy:  99.60738393718142\n",
            "epoch:  3284  loss:  0.018791814661516283  accuracy:  99.45584791293567\n",
            "epoch:  3285  loss:  0.016921354745639012  accuracy:  99.43518390962943\n",
            "epoch:  3286  loss:  0.015104580018355034  accuracy:  99.5798319327731\n",
            "epoch:  3287  loss:  0.0148636216681456  accuracy:  99.51095192175231\n",
            "epoch:  3288  loss:  0.021826743073950064  accuracy:  99.32497589199615\n",
            "epoch:  3289  loss:  0.022140391912161977  accuracy:  99.31119988979198\n",
            "epoch:  3290  loss:  0.016765605557112956  accuracy:  99.51095192175231\n",
            "epoch:  3291  loss:  0.015827017101456127  accuracy:  99.49028791844607\n",
            "epoch:  3292  loss:  0.025371145043104636  accuracy:  99.22854387656702\n",
            "epoch:  3293  loss:  0.09211399223644429  accuracy:  97.47899159663865\n",
            "epoch:  3294  loss:  0.061254630121566025  accuracy:  98.1264637002342\n",
            "epoch:  3295  loss:  0.02616046159435179  accuracy:  99.2354318776691\n",
            "epoch:  3296  loss:  0.017624108946868333  accuracy:  99.38696790191486\n",
            "epoch:  3297  loss:  0.013482023225181172  accuracy:  99.59360793497727\n",
            "epoch:  3298  loss:  0.012557950430368907  accuracy:  99.68315194930432\n",
            "epoch:  3299  loss:  0.01129108220362236  accuracy:  99.66937594710015\n",
            "epoch:  3300  loss:  0.013363499238438296  accuracy:  99.57294393167103\n",
            "epoch:  3301  loss:  0.014100642667345334  accuracy:  99.5798319327731\n",
            "epoch:  3302  loss:  0.01895103958749176  accuracy:  99.39385590301694\n",
            "epoch:  3303  loss:  0.024997784048907755  accuracy:  99.1665518666483\n",
            "epoch:  3304  loss:  0.029576357936802602  accuracy:  99.15277586444414\n",
            "epoch:  3305  loss:  0.016526189407372605  accuracy:  99.44895991183358\n",
            "epoch:  3306  loss:  0.014966448903398648  accuracy:  99.58671993387519\n",
            "epoch:  3307  loss:  0.016098101603614332  accuracy:  99.4765119162419\n",
            "epoch:  3308  loss:  0.04346092744748503  accuracy:  98.46397575423612\n",
            "epoch:  3309  loss:  0.07190877375590539  accuracy:  97.58919961427193\n",
            "epoch:  3310  loss:  0.05510046145927999  accuracy:  98.27111172337787\n",
            "epoch:  3311  loss:  0.03679870543909726  accuracy:  98.82903981264637\n",
            "epoch:  3312  loss:  0.023387921273630465  accuracy:  99.34563989530238\n",
            "epoch:  3313  loss:  0.01765082152577032  accuracy:  99.48339991734399\n",
            "epoch:  3314  loss:  0.01636371039612241  accuracy:  99.60738393718142\n",
            "epoch:  3315  loss:  0.01489368741162417  accuracy:  99.57294393167103\n",
            "epoch:  3316  loss:  0.013486943144237314  accuracy:  99.58671993387519\n",
            "epoch:  3317  loss:  0.01614247708698653  accuracy:  99.42140790742526\n",
            "epoch:  3318  loss:  0.018002200342536707  accuracy:  99.42829590852735\n",
            "epoch:  3319  loss:  0.016282245612183395  accuracy:  99.58671993387519\n",
            "epoch:  3320  loss:  0.014277132562829179  accuracy:  99.55227992836478\n",
            "epoch:  3321  loss:  0.015179894608297922  accuracy:  99.50406392065022\n",
            "epoch:  3322  loss:  0.015795905315616792  accuracy:  99.48339991734399\n",
            "epoch:  3323  loss:  0.014984042041011659  accuracy:  99.55227992836478\n",
            "epoch:  3324  loss:  0.019346438799520953  accuracy:  99.35252789640447\n",
            "epoch:  3325  loss:  0.04268880417129251  accuracy:  98.59484777517564\n",
            "epoch:  3326  loss:  0.048410891183246686  accuracy:  98.30555172888828\n",
            "epoch:  3327  loss:  0.052070218947065455  accuracy:  98.25044772007163\n",
            "epoch:  3328  loss:  0.05324893270360435  accuracy:  98.49152775864444\n",
            "epoch:  3329  loss:  0.03182283196899666  accuracy:  98.97368783579006\n",
            "epoch:  3330  loss:  0.02490660889498363  accuracy:  99.2009918721587\n",
            "epoch:  3331  loss:  0.020370911095949035  accuracy:  99.3731918997107\n",
            "epoch:  3332  loss:  0.014708269840090459  accuracy:  99.60738393718142\n",
            "epoch:  3333  loss:  0.013211336751145936  accuracy:  99.60049593607935\n",
            "epoch:  3334  loss:  0.01433229791128143  accuracy:  99.60049593607935\n",
            "epoch:  3335  loss:  0.013477888290999622  accuracy:  99.5798319327731\n",
            "epoch:  3336  loss:  0.014697825016344424  accuracy:  99.53850392616063\n",
            "epoch:  3337  loss:  0.013495265867914951  accuracy:  99.58671993387519\n",
            "epoch:  3338  loss:  0.01339124072794916  accuracy:  99.55916792946687\n",
            "epoch:  3339  loss:  0.0137698452087927  accuracy:  99.57294393167103\n",
            "epoch:  3340  loss:  0.014012219977759739  accuracy:  99.59360793497727\n",
            "epoch:  3341  loss:  0.02682863515718654  accuracy:  99.12522386003582\n",
            "epoch:  3342  loss:  0.08347694945993409  accuracy:  97.49276759884282\n",
            "epoch:  3343  loss:  0.06488624468478109  accuracy:  98.17467970794875\n",
            "epoch:  3344  loss:  0.037772144074279125  accuracy:  98.68439178950268\n",
            "epoch:  3345  loss:  0.019351749497597038  accuracy:  99.3731918997107\n",
            "epoch:  3346  loss:  0.017008971796878273  accuracy:  99.58671993387519\n",
            "epoch:  3347  loss:  0.011983502237421319  accuracy:  99.67626394820223\n",
            "epoch:  3348  loss:  0.01096871909522814  accuracy:  99.69692795150847\n",
            "epoch:  3349  loss:  0.01432604508673076  accuracy:  99.58671993387519\n",
            "epoch:  3350  loss:  0.013457490119182819  accuracy:  99.54539192726271\n",
            "epoch:  3351  loss:  0.015574077946069891  accuracy:  99.50406392065022\n",
            "epoch:  3352  loss:  0.014942530438930431  accuracy:  99.55227992836478\n",
            "epoch:  3353  loss:  0.02061202312057371  accuracy:  99.42140790742526\n",
            "epoch:  3354  loss:  0.019999105810439993  accuracy:  99.32497589199615\n",
            "epoch:  3355  loss:  0.01627740066765765  accuracy:  99.49028791844607\n",
            "epoch:  3356  loss:  0.019684768795915075  accuracy:  99.38696790191486\n",
            "epoch:  3357  loss:  0.023420288791950062  accuracy:  99.18721586995454\n",
            "epoch:  3358  loss:  0.054115888176383  accuracy:  98.17467970794875\n",
            "epoch:  3359  loss:  0.07062591923008678  accuracy:  97.6718556274969\n",
            "epoch:  3360  loss:  0.03993533216877429  accuracy:  98.71883179501309\n",
            "epoch:  3361  loss:  0.03311645203645421  accuracy:  99.05634384901502\n",
            "epoch:  3362  loss:  0.022716036522868757  accuracy:  99.2698718831795\n",
            "epoch:  3363  loss:  0.018570561042661828  accuracy:  99.46962391513982\n",
            "epoch:  3364  loss:  0.01566289204847258  accuracy:  99.59360793497727\n",
            "epoch:  3365  loss:  0.012891564769807648  accuracy:  99.58671993387519\n",
            "epoch:  3366  loss:  0.01570826056581424  accuracy:  99.4765119162419\n",
            "epoch:  3367  loss:  0.012717545392524303  accuracy:  99.60738393718142\n",
            "epoch:  3368  loss:  0.01192141651752107  accuracy:  99.61427193828351\n",
            "epoch:  3369  loss:  0.01606728502387318  accuracy:  99.50406392065022\n",
            "epoch:  3370  loss:  0.018141598425984416  accuracy:  99.36630389860862\n",
            "epoch:  3371  loss:  0.017006315961418557  accuracy:  99.48339991734399\n",
            "epoch:  3372  loss:  0.014077495538099331  accuracy:  99.60738393718142\n",
            "epoch:  3373  loss:  0.01834254217334605  accuracy:  99.38007990081279\n",
            "epoch:  3374  loss:  0.01790303591754786  accuracy:  99.41451990632318\n",
            "epoch:  3375  loss:  0.04021370811885697  accuracy:  98.76015980162556\n",
            "epoch:  3376  loss:  0.11943503282515183  accuracy:  96.25981540157046\n",
            "epoch:  3377  loss:  0.07568829272740141  accuracy:  97.85783165725306\n",
            "epoch:  3378  loss:  0.027836087874181386  accuracy:  99.18721586995454\n",
            "epoch:  3379  loss:  0.020826804674852636  accuracy:  99.3387518942003\n",
            "epoch:  3380  loss:  0.014023093706198813  accuracy:  99.5798319327731\n",
            "epoch:  3381  loss:  0.011426102004050778  accuracy:  99.66248794599807\n",
            "epoch:  3382  loss:  0.012045382272817705  accuracy:  99.61427193828351\n",
            "epoch:  3383  loss:  0.012011426666385595  accuracy:  99.64871194379391\n",
            "epoch:  3384  loss:  0.018893800566061065  accuracy:  99.35941589750654\n",
            "epoch:  3385  loss:  0.017966491465042634  accuracy:  99.45584791293567\n",
            "epoch:  3386  loss:  0.020011365527948122  accuracy:  99.42140790742526\n",
            "epoch:  3387  loss:  0.012465281267877515  accuracy:  99.54539192726271\n",
            "epoch:  3388  loss:  0.014769443417141063  accuracy:  99.49028791844607\n",
            "epoch:  3389  loss:  0.02111928878198857  accuracy:  99.2354318776691\n",
            "epoch:  3390  loss:  0.015379648979487742  accuracy:  99.52472792395646\n",
            "epoch:  3391  loss:  0.017719293616877983  accuracy:  99.40074390411903\n",
            "epoch:  3392  loss:  0.01588093384977903  accuracy:  99.51095192175231\n",
            "epoch:  3393  loss:  0.015515096909001538  accuracy:  99.49717591954814\n",
            "epoch:  3394  loss:  0.0161639168377054  accuracy:  99.44895991183358\n",
            "epoch:  3395  loss:  0.06133782077692439  accuracy:  97.98181567709051\n",
            "epoch:  3396  loss:  0.09160904493173275  accuracy:  97.33434357349498\n",
            "epoch:  3397  loss:  0.041123097803457014  accuracy:  98.56729577076732\n",
            "epoch:  3398  loss:  0.015540166363802116  accuracy:  99.53850392616063\n",
            "epoch:  3399  loss:  0.01362240851149616  accuracy:  99.58671993387519\n",
            "epoch:  3400  loss:  0.0123365921551986  accuracy:  99.62804794048768\n",
            "epoch:  3401  loss:  0.015012181670698647  accuracy:  99.55916792946687\n",
            "epoch:  3402  loss:  0.0133993600859593  accuracy:  99.66937594710015\n",
            "epoch:  3403  loss:  0.013312327092995718  accuracy:  99.57294393167103\n",
            "epoch:  3404  loss:  0.015583048227994573  accuracy:  99.49028791844607\n",
            "epoch:  3405  loss:  0.012141834981003727  accuracy:  99.63493594158975\n",
            "epoch:  3406  loss:  0.03434000516184986  accuracy:  98.91858382697342\n",
            "epoch:  3407  loss:  0.054043478706082705  accuracy:  98.18845571015291\n",
            "epoch:  3408  loss:  0.02152314326147079  accuracy:  99.38007990081279\n",
            "epoch:  3409  loss:  0.013890741596644777  accuracy:  99.59360793497727\n",
            "epoch:  3410  loss:  0.015106741268355704  accuracy:  99.46962391513982\n",
            "epoch:  3411  loss:  0.012303076435238064  accuracy:  99.63493594158975\n",
            "epoch:  3412  loss:  0.013141312474136774  accuracy:  99.60738393718142\n",
            "epoch:  3413  loss:  0.013662303144842635  accuracy:  99.59360793497727\n",
            "epoch:  3414  loss:  0.014258793833769344  accuracy:  99.49717591954814\n",
            "epoch:  3415  loss:  0.023693618868269928  accuracy:  99.2009918721587\n",
            "epoch:  3416  loss:  0.12548221340027044  accuracy:  96.39068742250998\n",
            "epoch:  3417  loss:  0.03170468646655521  accuracy:  99.0976718556275\n",
            "epoch:  3418  loss:  0.04061337419032957  accuracy:  98.71883179501309\n",
            "epoch:  3419  loss:  0.01627805804770775  accuracy:  99.48339991734399\n",
            "epoch:  3420  loss:  0.011930612437967184  accuracy:  99.62804794048768\n",
            "epoch:  3421  loss:  0.012242053390591813  accuracy:  99.70381595261055\n",
            "epoch:  3422  loss:  0.011412475252306422  accuracy:  99.64182394269183\n",
            "epoch:  3423  loss:  0.012614374863409968  accuracy:  99.5798319327731\n",
            "epoch:  3424  loss:  0.011515560980685048  accuracy:  99.68315194930432\n",
            "epoch:  3425  loss:  0.016138969765718703  accuracy:  99.53850392616063\n",
            "epoch:  3426  loss:  0.019001477921823197  accuracy:  99.41451990632318\n",
            "epoch:  3427  loss:  0.02804363305462153  accuracy:  99.06323185011709\n",
            "epoch:  3428  loss:  0.014879004948840873  accuracy:  99.55227992836478\n",
            "epoch:  3429  loss:  0.018476534618566666  accuracy:  99.41451990632318\n",
            "epoch:  3430  loss:  0.02643857217209193  accuracy:  99.18032786885246\n",
            "epoch:  3431  loss:  0.020416883945192837  accuracy:  99.33186389309822\n",
            "epoch:  3432  loss:  0.016554232258271396  accuracy:  99.53850392616063\n",
            "epoch:  3433  loss:  0.053746348107310625  accuracy:  98.47775175644028\n",
            "epoch:  3434  loss:  0.090219261225509  accuracy:  97.44455159112826\n",
            "epoch:  3435  loss:  0.043744948491222416  accuracy:  98.65683978509436\n",
            "epoch:  3436  loss:  0.016158953818951518  accuracy:  99.4765119162419\n",
            "epoch:  3437  loss:  0.018933123145525744  accuracy:  99.4420719107315\n",
            "epoch:  3438  loss:  0.011117076778777081  accuracy:  99.72447995591679\n",
            "epoch:  3439  loss:  0.012866482155104114  accuracy:  99.5798319327731\n",
            "epoch:  3440  loss:  0.012473630099571453  accuracy:  99.62115993938559\n",
            "epoch:  3441  loss:  0.014773332118884243  accuracy:  99.55916792946687\n",
            "epoch:  3442  loss:  0.012784979334723973  accuracy:  99.5798319327731\n",
            "epoch:  3443  loss:  0.019183123453686644  accuracy:  99.38007990081279\n",
            "epoch:  3444  loss:  0.01351080140416662  accuracy:  99.60738393718142\n",
            "epoch:  3445  loss:  0.015133515958400205  accuracy:  99.49028791844607\n",
            "epoch:  3446  loss:  0.014295981584219072  accuracy:  99.62804794048768\n",
            "epoch:  3447  loss:  0.03932639287317944  accuracy:  98.73949579831933\n",
            "epoch:  3448  loss:  0.11017671529143866  accuracy:  96.65243146438904\n",
            "epoch:  3449  loss:  0.04520654070393413  accuracy:  98.60173577627772\n",
            "epoch:  3450  loss:  0.022584297716678078  accuracy:  99.27675988428157\n",
            "epoch:  3451  loss:  0.012091845739151723  accuracy:  99.68315194930432\n",
            "epoch:  3452  loss:  0.011261374941313176  accuracy:  99.69692795150847\n",
            "epoch:  3453  loss:  0.01004914060401299  accuracy:  99.69692795150847\n",
            "epoch:  3454  loss:  0.012697418332137762  accuracy:  99.60738393718142\n",
            "epoch:  3455  loss:  0.012560034680575028  accuracy:  99.62115993938559\n",
            "epoch:  3456  loss:  0.01198192392190117  accuracy:  99.64182394269183\n",
            "epoch:  3457  loss:  0.01290018254814251  accuracy:  99.62115993938559\n",
            "epoch:  3458  loss:  0.013090432541351752  accuracy:  99.57294393167103\n",
            "epoch:  3459  loss:  0.016944852868034547  accuracy:  99.4765119162419\n",
            "epoch:  3460  loss:  0.015068652050833693  accuracy:  99.56605593056895\n",
            "epoch:  3461  loss:  0.01749646782084162  accuracy:  99.41451990632318\n",
            "epoch:  3462  loss:  0.047429982430173566  accuracy:  98.3331037332966\n",
            "epoch:  3463  loss:  0.07877496745669477  accuracy:  97.61675161868025\n",
            "epoch:  3464  loss:  0.039789569401480526  accuracy:  98.64306378289021\n",
            "epoch:  3465  loss:  0.023558459458077864  accuracy:  99.26298388207742\n",
            "epoch:  3466  loss:  0.025588038746772544  accuracy:  99.26298388207742\n",
            "epoch:  3467  loss:  0.028108457548136206  accuracy:  99.17343986775037\n",
            "epoch:  3468  loss:  0.02449439467736451  accuracy:  99.29742388758783\n",
            "epoch:  3469  loss:  0.01223607885052519  accuracy:  99.68315194930432\n",
            "epoch:  3470  loss:  0.010907096832309764  accuracy:  99.68315194930432\n",
            "epoch:  3471  loss:  0.011560464083233891  accuracy:  99.64871194379391\n",
            "epoch:  3472  loss:  0.011597484643912996  accuracy:  99.66937594710015\n",
            "epoch:  3473  loss:  0.01342949618007164  accuracy:  99.57294393167103\n",
            "epoch:  3474  loss:  0.021736114125191767  accuracy:  99.21476787436286\n",
            "epoch:  3475  loss:  0.017076020736969882  accuracy:  99.44895991183358\n",
            "epoch:  3476  loss:  0.012750903081067008  accuracy:  99.56605593056895\n",
            "epoch:  3477  loss:  0.01914183298468229  accuracy:  99.3387518942003\n",
            "epoch:  3478  loss:  0.013770927359693354  accuracy:  99.60049593607935\n",
            "epoch:  3479  loss:  0.013406067800934306  accuracy:  99.60049593607935\n",
            "epoch:  3480  loss:  0.01903105154530883  accuracy:  99.3731918997107\n",
            "epoch:  3481  loss:  0.015699341089338605  accuracy:  99.51095192175231\n",
            "epoch:  3482  loss:  0.016699824364472142  accuracy:  99.43518390962943\n",
            "epoch:  3483  loss:  0.015950723757374226  accuracy:  99.4765119162419\n",
            "epoch:  3484  loss:  0.03798043534447948  accuracy:  98.6086237773798\n",
            "epoch:  3485  loss:  0.1203429657095518  accuracy:  96.3149194103871\n",
            "epoch:  3486  loss:  0.05820677012510732  accuracy:  97.94048767047802\n",
            "epoch:  3487  loss:  0.02335219113426269  accuracy:  99.22165587546495\n",
            "epoch:  3488  loss:  0.011431604617668277  accuracy:  99.66248794599807\n",
            "epoch:  3489  loss:  0.009458255470760322  accuracy:  99.71070395371264\n",
            "epoch:  3490  loss:  0.01151096592795831  accuracy:  99.63493594158975\n",
            "epoch:  3491  loss:  0.010737014889836676  accuracy:  99.67626394820223\n",
            "epoch:  3492  loss:  0.011948955613149315  accuracy:  99.655599944896\n",
            "epoch:  3493  loss:  0.011200978631518201  accuracy:  99.68315194930432\n",
            "epoch:  3494  loss:  0.015297084163140774  accuracy:  99.52472792395646\n",
            "epoch:  3495  loss:  0.01423178242435398  accuracy:  99.51783992285439\n",
            "epoch:  3496  loss:  0.012539134900860427  accuracy:  99.64871194379391\n",
            "epoch:  3497  loss:  0.012285270654527235  accuracy:  99.60049593607935\n",
            "epoch:  3498  loss:  0.013040175850140445  accuracy:  99.64871194379391\n",
            "epoch:  3499  loss:  0.013606743259716716  accuracy:  99.53850392616063\n",
            "epoch:  3500  loss:  0.012282677828824374  accuracy:  99.62804794048768\n",
            "epoch:  3501  loss:  0.02391366146351626  accuracy:  99.24231987877118\n",
            "epoch:  3502  loss:  0.027067038430584067  accuracy:  99.17343986775037\n",
            "epoch:  3503  loss:  0.13778638813481323  accuracy:  96.30114340818295\n",
            "epoch:  3504  loss:  0.05273267253146026  accuracy:  98.66372778619645\n",
            "epoch:  3505  loss:  0.017690336183106746  accuracy:  99.53161592505855\n",
            "epoch:  3506  loss:  0.012274615362880978  accuracy:  99.68315194930432\n",
            "epoch:  3507  loss:  0.011723550446641343  accuracy:  99.62115993938559\n",
            "epoch:  3508  loss:  0.012734062528063342  accuracy:  99.59360793497727\n",
            "epoch:  3509  loss:  0.013190025063776216  accuracy:  99.64182394269183\n",
            "epoch:  3510  loss:  0.01030061594337581  accuracy:  99.69692795150847\n",
            "epoch:  3511  loss:  0.01102990248373769  accuracy:  99.71070395371264\n",
            "epoch:  3512  loss:  0.01085442355780062  accuracy:  99.69692795150847\n",
            "epoch:  3513  loss:  0.01287661894688353  accuracy:  99.62115993938559\n",
            "epoch:  3514  loss:  0.01440135779989957  accuracy:  99.53850392616063\n",
            "epoch:  3515  loss:  0.020999597269944326  accuracy:  99.3043118886899\n",
            "epoch:  3516  loss:  0.02447798580552483  accuracy:  99.07011985121918\n",
            "epoch:  3517  loss:  0.043965890105355204  accuracy:  98.63617578178813\n",
            "epoch:  3518  loss:  0.03766555024884058  accuracy:  98.76015980162556\n",
            "epoch:  3519  loss:  0.022068850624463957  accuracy:  99.35941589750654\n",
            "epoch:  3520  loss:  0.01125725939768396  accuracy:  99.64182394269183\n",
            "epoch:  3521  loss:  0.010380051440215744  accuracy:  99.72447995591679\n",
            "epoch:  3522  loss:  0.01271970667134414  accuracy:  99.58671993387519\n",
            "epoch:  3523  loss:  0.011804429254290484  accuracy:  99.66248794599807\n",
            "epoch:  3524  loss:  0.012695396329472048  accuracy:  99.55227992836478\n",
            "epoch:  3525  loss:  0.012371902050217454  accuracy:  99.57294393167103\n",
            "epoch:  3526  loss:  0.01785914712635032  accuracy:  99.48339991734399\n",
            "epoch:  3527  loss:  0.03818318492990567  accuracy:  98.62239977958396\n",
            "epoch:  3528  loss:  0.09577714441871323  accuracy:  97.14147954263673\n",
            "epoch:  3529  loss:  0.047597882838426836  accuracy:  98.58107177297148\n",
            "epoch:  3530  loss:  0.03825245133450955  accuracy:  98.711943793911\n",
            "epoch:  3531  loss:  0.014509652535253265  accuracy:  99.60049593607935\n",
            "epoch:  3532  loss:  0.012588732365269523  accuracy:  99.54539192726271\n",
            "epoch:  3533  loss:  0.01561897214445837  accuracy:  99.4765119162419\n",
            "epoch:  3534  loss:  0.011965059634918219  accuracy:  99.69692795150847\n",
            "epoch:  3535  loss:  0.01102300403307508  accuracy:  99.67626394820223\n",
            "epoch:  3536  loss:  0.012102262310315252  accuracy:  99.59360793497727\n",
            "epoch:  3537  loss:  0.009567366046822352  accuracy:  99.73825595812096\n",
            "epoch:  3538  loss:  0.014676903182517697  accuracy:  99.49717591954814\n",
            "epoch:  3539  loss:  0.01731546139413213  accuracy:  99.51095192175231\n",
            "epoch:  3540  loss:  0.013175772651219783  accuracy:  99.56605593056895\n",
            "epoch:  3541  loss:  0.013643155838627168  accuracy:  99.60738393718142\n",
            "epoch:  3542  loss:  0.012025648834597448  accuracy:  99.64871194379391\n",
            "epoch:  3543  loss:  0.01232631951671386  accuracy:  99.66248794599807\n",
            "epoch:  3544  loss:  0.012453301839485498  accuracy:  99.59360793497727\n",
            "epoch:  3545  loss:  0.011057688009288568  accuracy:  99.66937594710015\n",
            "epoch:  3546  loss:  0.02755337368376437  accuracy:  99.05634384901502\n",
            "epoch:  3547  loss:  0.10068934695384109  accuracy:  96.78330348532856\n",
            "epoch:  3548  loss:  0.10808194968641577  accuracy:  96.7006474721036\n",
            "epoch:  3549  loss:  0.019491221416696833  accuracy:  99.46962391513982\n",
            "epoch:  3550  loss:  0.013257520806185726  accuracy:  99.66248794599807\n",
            "epoch:  3551  loss:  0.011167708992298483  accuracy:  99.64871194379391\n",
            "epoch:  3552  loss:  0.01242901853623862  accuracy:  99.64871194379391\n",
            "epoch:  3553  loss:  0.011024596836793958  accuracy:  99.63493594158975\n",
            "epoch:  3554  loss:  0.010761089834539477  accuracy:  99.68315194930432\n",
            "epoch:  3555  loss:  0.01284538099157299  accuracy:  99.58671993387519\n",
            "epoch:  3556  loss:  0.011442558317643953  accuracy:  99.64871194379391\n",
            "epoch:  3557  loss:  0.014503940148186054  accuracy:  99.55227992836478\n",
            "epoch:  3558  loss:  0.012676270273872046  accuracy:  99.53850392616063\n",
            "epoch:  3559  loss:  0.013579134054448369  accuracy:  99.57294393167103\n",
            "epoch:  3560  loss:  0.017462611596601296  accuracy:  99.43518390962943\n",
            "epoch:  3561  loss:  0.042461008904841786  accuracy:  98.49152775864444\n",
            "epoch:  3562  loss:  0.06332903435091457  accuracy:  97.92671166827387\n",
            "epoch:  3563  loss:  0.07727315690234213  accuracy:  97.76828764292603\n",
            "epoch:  3564  loss:  0.029232471203970344  accuracy:  98.9943518390963\n",
            "epoch:  3565  loss:  0.012473134727134247  accuracy:  99.66937594710015\n",
            "epoch:  3566  loss:  0.010747918010795037  accuracy:  99.66248794599807\n",
            "epoch:  3567  loss:  0.015046078739909758  accuracy:  99.51783992285439\n",
            "epoch:  3568  loss:  0.010200008101394278  accuracy:  99.66248794599807\n",
            "epoch:  3569  loss:  0.013745693773257555  accuracy:  99.54539192726271\n",
            "epoch:  3570  loss:  0.011465945749363732  accuracy:  99.62804794048768\n",
            "epoch:  3571  loss:  0.01791573088614016  accuracy:  99.39385590301694\n",
            "epoch:  3572  loss:  0.011287524807079254  accuracy:  99.60738393718142\n",
            "epoch:  3573  loss:  0.012121969071296555  accuracy:  99.63493594158975\n",
            "epoch:  3574  loss:  0.011344539548907665  accuracy:  99.63493594158975\n",
            "epoch:  3575  loss:  0.011463421651536583  accuracy:  99.60738393718142\n",
            "epoch:  3576  loss:  0.016287113517614676  accuracy:  99.4420719107315\n",
            "epoch:  3577  loss:  0.02560800849971658  accuracy:  99.09078385452541\n",
            "epoch:  3578  loss:  0.05088860853723997  accuracy:  98.2297837167654\n",
            "epoch:  3579  loss:  0.049767013839903396  accuracy:  98.46397575423612\n",
            "epoch:  3580  loss:  0.039383014405274794  accuracy:  98.78771180603388\n",
            "epoch:  3581  loss:  0.037296026266187804  accuracy:  99.01501584240253\n",
            "epoch:  3582  loss:  0.031683460389752616  accuracy:  98.91169582587133\n",
            "epoch:  3583  loss:  0.015019847012080948  accuracy:  99.43518390962943\n",
            "epoch:  3584  loss:  0.010048501962162826  accuracy:  99.70381595261055\n",
            "epoch:  3585  loss:  0.009501310542829421  accuracy:  99.64182394269183\n",
            "epoch:  3586  loss:  0.01129180454159378  accuracy:  99.64182394269183\n",
            "epoch:  3587  loss:  0.011019022438416258  accuracy:  99.67626394820223\n",
            "epoch:  3588  loss:  0.010483406437907324  accuracy:  99.72447995591679\n",
            "epoch:  3589  loss:  0.012317382365532906  accuracy:  99.63493594158975\n",
            "epoch:  3590  loss:  0.012540438365226374  accuracy:  99.655599944896\n",
            "epoch:  3591  loss:  0.012142287717672442  accuracy:  99.60738393718142\n",
            "epoch:  3592  loss:  0.014634497441218752  accuracy:  99.57294393167103\n",
            "epoch:  3593  loss:  0.011627790926544954  accuracy:  99.69003995040639\n",
            "epoch:  3594  loss:  0.01609093977409528  accuracy:  99.48339991734399\n",
            "epoch:  3595  loss:  0.09935437877392923  accuracy:  96.907287505166\n",
            "epoch:  3596  loss:  0.08859400454211176  accuracy:  97.20347155255544\n",
            "epoch:  3597  loss:  0.01624213209061599  accuracy:  99.51783992285439\n",
            "epoch:  3598  loss:  0.00967418619481656  accuracy:  99.77269596363135\n",
            "epoch:  3599  loss:  0.009926948140278835  accuracy:  99.72447995591679\n",
            "epoch:  3600  loss:  0.009598845112529642  accuracy:  99.72447995591679\n",
            "epoch:  3601  loss:  0.011415052543676397  accuracy:  99.63493594158975\n",
            "epoch:  3602  loss:  0.011176297690738675  accuracy:  99.62804794048768\n",
            "epoch:  3603  loss:  0.011471532472161178  accuracy:  99.655599944896\n",
            "epoch:  3604  loss:  0.01470869867487657  accuracy:  99.54539192726271\n",
            "epoch:  3605  loss:  0.017044149988600585  accuracy:  99.49028791844607\n",
            "epoch:  3606  loss:  0.0468188644696221  accuracy:  98.63617578178813\n",
            "epoch:  3607  loss:  0.11279576030980787  accuracy:  96.74886347981816\n",
            "epoch:  3608  loss:  0.015197531349503067  accuracy:  99.55227992836478\n",
            "epoch:  3609  loss:  0.009815038270239397  accuracy:  99.67626394820223\n",
            "epoch:  3610  loss:  0.010094093238915757  accuracy:  99.67626394820223\n",
            "epoch:  3611  loss:  0.014478836211805438  accuracy:  99.55916792946687\n",
            "epoch:  3612  loss:  0.010459025632795013  accuracy:  99.69692795150847\n",
            "epoch:  3613  loss:  0.011218299556462363  accuracy:  99.64871194379391\n",
            "epoch:  3614  loss:  0.011213251014472885  accuracy:  99.64871194379391\n",
            "epoch:  3615  loss:  0.014994191041404918  accuracy:  99.55227992836478\n",
            "epoch:  3616  loss:  0.012389350631658538  accuracy:  99.62115993938559\n",
            "epoch:  3617  loss:  0.010881081138120894  accuracy:  99.71759195481471\n",
            "epoch:  3618  loss:  0.012422236382525955  accuracy:  99.58671993387519\n",
            "epoch:  3619  loss:  0.014146217175705232  accuracy:  99.60738393718142\n",
            "epoch:  3620  loss:  0.01577143411272409  accuracy:  99.46962391513982\n",
            "epoch:  3621  loss:  0.026810201365353916  accuracy:  99.12522386003582\n",
            "epoch:  3622  loss:  0.015241993900037196  accuracy:  99.53850392616063\n",
            "epoch:  3623  loss:  0.0674872143381845  accuracy:  98.19534371125499\n",
            "epoch:  3624  loss:  0.11642976645955039  accuracy:  96.67998346879736\n",
            "epoch:  3625  loss:  0.027270003998875855  accuracy:  99.15966386554622\n",
            "epoch:  3626  loss:  0.01603654287069731  accuracy:  99.55227992836478\n",
            "epoch:  3627  loss:  0.012400075781302413  accuracy:  99.60049593607935\n",
            "epoch:  3628  loss:  0.009150783188592896  accuracy:  99.77958396473343\n",
            "epoch:  3629  loss:  0.011248350645979873  accuracy:  99.63493594158975\n",
            "epoch:  3630  loss:  0.012589664425002187  accuracy:  99.66248794599807\n",
            "epoch:  3631  loss:  0.01256443497077306  accuracy:  99.5798319327731\n",
            "epoch:  3632  loss:  0.010614143229798657  accuracy:  99.655599944896\n",
            "epoch:  3633  loss:  0.01209064098864392  accuracy:  99.62115993938559\n",
            "epoch:  3634  loss:  0.011855524615817648  accuracy:  99.64182394269183\n",
            "epoch:  3635  loss:  0.011429812103184151  accuracy:  99.62115993938559\n",
            "epoch:  3636  loss:  0.011868981372244668  accuracy:  99.67626394820223\n",
            "epoch:  3637  loss:  0.0152846032709067  accuracy:  99.49028791844607\n",
            "epoch:  3638  loss:  0.05299946039459367  accuracy:  98.16090370574459\n",
            "epoch:  3639  loss:  0.029515979708412812  accuracy:  99.04256784681085\n",
            "epoch:  3640  loss:  0.057416892400625204  accuracy:  98.1264637002342\n",
            "epoch:  3641  loss:  0.03982369118459412  accuracy:  98.64306378289021\n",
            "epoch:  3642  loss:  0.014978653992916775  accuracy:  99.51783992285439\n",
            "epoch:  3643  loss:  0.011501185363471313  accuracy:  99.64871194379391\n",
            "epoch:  3644  loss:  0.011423103608215262  accuracy:  99.70381595261055\n",
            "epoch:  3645  loss:  0.008898879241316722  accuracy:  99.71759195481471\n",
            "epoch:  3646  loss:  0.010853832312414397  accuracy:  99.66248794599807\n",
            "epoch:  3647  loss:  0.014280511275364772  accuracy:  99.57294393167103\n",
            "epoch:  3648  loss:  0.013131555291769003  accuracy:  99.62804794048768\n",
            "epoch:  3649  loss:  0.012071260555911225  accuracy:  99.62115993938559\n",
            "epoch:  3650  loss:  0.014783413636006512  accuracy:  99.51783992285439\n",
            "epoch:  3651  loss:  0.013060599186847465  accuracy:  99.59360793497727\n",
            "epoch:  3652  loss:  0.010472256131072477  accuracy:  99.73136795701888\n",
            "epoch:  3653  loss:  0.017279255555217508  accuracy:  99.36630389860862\n",
            "epoch:  3654  loss:  0.01041007703064013  accuracy:  99.70381595261055\n",
            "epoch:  3655  loss:  0.011380530893610194  accuracy:  99.62115993938559\n",
            "epoch:  3656  loss:  0.01370296318632544  accuracy:  99.59360793497727\n",
            "epoch:  3657  loss:  0.08393222948550774  accuracy:  97.34123157459705\n",
            "epoch:  3658  loss:  0.08524270865561746  accuracy:  97.60986361757818\n",
            "epoch:  3659  loss:  0.03303240540831022  accuracy:  99.02190384350462\n",
            "epoch:  3660  loss:  0.015470922621856656  accuracy:  99.53850392616063\n",
            "epoch:  3661  loss:  0.0105481552417208  accuracy:  99.69003995040639\n",
            "epoch:  3662  loss:  0.011122820960939108  accuracy:  99.60049593607935\n",
            "epoch:  3663  loss:  0.008639657045253001  accuracy:  99.71759195481471\n",
            "epoch:  3664  loss:  0.009992437474640018  accuracy:  99.73825595812096\n",
            "epoch:  3665  loss:  0.009089392253944686  accuracy:  99.75203196032511\n",
            "epoch:  3666  loss:  0.011137219849341531  accuracy:  99.70381595261055\n",
            "epoch:  3667  loss:  0.013388748266871784  accuracy:  99.52472792395646\n",
            "epoch:  3668  loss:  0.016742178837523426  accuracy:  99.49717591954814\n",
            "epoch:  3669  loss:  0.01984949528048117  accuracy:  99.40074390411903\n",
            "epoch:  3670  loss:  0.04234221253086321  accuracy:  98.5053037608486\n",
            "epoch:  3671  loss:  0.059435040344944616  accuracy:  98.20223171235708\n",
            "epoch:  3672  loss:  0.039718044950206095  accuracy:  98.79459980713597\n",
            "epoch:  3673  loss:  0.032222202211912354  accuracy:  99.04256784681085\n",
            "epoch:  3674  loss:  0.013325250577086636  accuracy:  99.56605593056895\n",
            "epoch:  3675  loss:  0.011434964642842419  accuracy:  99.67626394820223\n",
            "epoch:  3676  loss:  0.01280676033026456  accuracy:  99.55916792946687\n",
            "epoch:  3677  loss:  0.0103220287600051  accuracy:  99.68315194930432\n",
            "epoch:  3678  loss:  0.009240358824629856  accuracy:  99.74514395922303\n",
            "epoch:  3679  loss:  0.01254497562578857  accuracy:  99.58671993387519\n",
            "epoch:  3680  loss:  0.011059767662380484  accuracy:  99.64182394269183\n",
            "epoch:  3681  loss:  0.01004716306713287  accuracy:  99.73136795701888\n",
            "epoch:  3682  loss:  0.012090860729724557  accuracy:  99.62804794048768\n",
            "epoch:  3683  loss:  0.025074131869479915  accuracy:  99.18032786885246\n",
            "epoch:  3684  loss:  0.020725556575944784  accuracy:  99.35252789640447\n",
            "epoch:  3685  loss:  0.029119529555806895  accuracy:  99.04256784681085\n",
            "epoch:  3686  loss:  0.051590799942299856  accuracy:  98.35376773660283\n",
            "epoch:  3687  loss:  0.055782554158293  accuracy:  98.44331175092988\n",
            "epoch:  3688  loss:  0.016287228602892653  accuracy:  99.55916792946687\n",
            "epoch:  3689  loss:  0.009648941332059752  accuracy:  99.7589199614272\n",
            "epoch:  3690  loss:  0.014853366272319235  accuracy:  99.5798319327731\n",
            "epoch:  3691  loss:  0.017986869690146897  accuracy:  99.4420719107315\n",
            "epoch:  3692  loss:  0.020223417296023012  accuracy:  99.43518390962943\n",
            "epoch:  3693  loss:  0.016365932701220335  accuracy:  99.48339991734399\n",
            "epoch:  3694  loss:  0.011269249898577957  accuracy:  99.655599944896\n",
            "epoch:  3695  loss:  0.009042127959659616  accuracy:  99.73136795701888\n",
            "epoch:  3696  loss:  0.009208538863851987  accuracy:  99.74514395922303\n",
            "epoch:  3697  loss:  0.009908535089890981  accuracy:  99.69692795150847\n",
            "epoch:  3698  loss:  0.010500038775668895  accuracy:  99.68315194930432\n",
            "epoch:  3699  loss:  0.03717848794986864  accuracy:  98.61551177848189\n",
            "epoch:  3700  loss:  0.07798515971271978  accuracy:  97.35500757680121\n",
            "epoch:  3701  loss:  0.03061972256520983  accuracy:  99.04256784681085\n",
            "epoch:  3702  loss:  0.018685097765533006  accuracy:  99.43518390962943\n",
            "epoch:  3703  loss:  0.012452270429924476  accuracy:  99.63493594158975\n",
            "epoch:  3704  loss:  0.009768045939306108  accuracy:  99.70381595261055\n",
            "epoch:  3705  loss:  0.01010555524806347  accuracy:  99.66937594710015\n",
            "epoch:  3706  loss:  0.012194395557446615  accuracy:  99.655599944896\n",
            "epoch:  3707  loss:  0.009689775383408344  accuracy:  99.69003995040639\n",
            "epoch:  3708  loss:  0.01213246181212791  accuracy:  99.62115993938559\n",
            "epoch:  3709  loss:  0.017843843907241523  accuracy:  99.53161592505855\n",
            "epoch:  3710  loss:  0.0910673077974044  accuracy:  97.17591954814712\n",
            "epoch:  3711  loss:  0.06241952735328446  accuracy:  97.96803967488634\n",
            "epoch:  3712  loss:  0.03356369350765366  accuracy:  99.02190384350462\n",
            "epoch:  3713  loss:  0.0163397142278268  accuracy:  99.54539192726271\n",
            "epoch:  3714  loss:  0.010041070163098834  accuracy:  99.64871194379391\n",
            "epoch:  3715  loss:  0.009187998320771485  accuracy:  99.71070395371264\n",
            "epoch:  3716  loss:  0.01062383216300643  accuracy:  99.66937594710015\n",
            "epoch:  3717  loss:  0.010208321662854113  accuracy:  99.69003995040639\n",
            "epoch:  3718  loss:  0.010273998786355565  accuracy:  99.61427193828351\n",
            "epoch:  3719  loss:  0.013005912270775301  accuracy:  99.66248794599807\n",
            "epoch:  3720  loss:  0.01281939866947434  accuracy:  99.60049593607935\n",
            "epoch:  3721  loss:  0.012458376654451743  accuracy:  99.5798319327731\n",
            "epoch:  3722  loss:  0.01339786214281396  accuracy:  99.58671993387519\n",
            "epoch:  3723  loss:  0.010303430171840084  accuracy:  99.62115993938559\n",
            "epoch:  3724  loss:  0.011550517430190803  accuracy:  99.68315194930432\n",
            "epoch:  3725  loss:  0.01292118242957385  accuracy:  99.54539192726271\n",
            "epoch:  3726  loss:  0.05414920306207982  accuracy:  98.11268769803003\n",
            "epoch:  3727  loss:  0.037349731642631646  accuracy:  98.78082380493181\n",
            "epoch:  3728  loss:  0.02369045965424964  accuracy:  99.31808789089406\n",
            "epoch:  3729  loss:  0.022828468225702885  accuracy:  99.1665518666483\n",
            "epoch:  3730  loss:  0.024296501533178742  accuracy:  99.2698718831795\n",
            "epoch:  3731  loss:  0.03442955917675181  accuracy:  99.18032786885246\n",
            "epoch:  3732  loss:  0.05350049314569471  accuracy:  98.46397575423612\n",
            "epoch:  3733  loss:  0.014710480244075211  accuracy:  99.55916792946687\n",
            "epoch:  3734  loss:  0.016994486324848866  accuracy:  99.48339991734399\n",
            "epoch:  3735  loss:  0.012648251504193835  accuracy:  99.63493594158975\n",
            "epoch:  3736  loss:  0.012322101643311115  accuracy:  99.59360793497727\n",
            "epoch:  3737  loss:  0.011431833017898246  accuracy:  99.655599944896\n",
            "epoch:  3738  loss:  0.008646041894457179  accuracy:  99.75203196032511\n",
            "epoch:  3739  loss:  0.012970446064443556  accuracy:  99.51095192175231\n",
            "epoch:  3740  loss:  0.011936580517111745  accuracy:  99.63493594158975\n",
            "epoch:  3741  loss:  0.011271550117055667  accuracy:  99.62804794048768\n",
            "epoch:  3742  loss:  0.012271681094920243  accuracy:  99.61427193828351\n",
            "epoch:  3743  loss:  0.015248292478663996  accuracy:  99.53850392616063\n",
            "epoch:  3744  loss:  0.018085174959475994  accuracy:  99.46273591403775\n",
            "epoch:  3745  loss:  0.015783587308031668  accuracy:  99.56605593056895\n",
            "epoch:  3746  loss:  0.028258149702604107  accuracy:  99.20787987326078\n",
            "epoch:  3747  loss:  0.12385631815014213  accuracy:  96.29425540708087\n",
            "epoch:  3748  loss:  0.061603547723991826  accuracy:  98.20911971345916\n",
            "epoch:  3749  loss:  0.02361000919965587  accuracy:  99.35252789640447\n",
            "epoch:  3750  loss:  0.012097653798347914  accuracy:  99.62804794048768\n",
            "epoch:  3751  loss:  0.012443020086269633  accuracy:  99.62804794048768\n",
            "epoch:  3752  loss:  0.010188462739397353  accuracy:  99.71070395371264\n",
            "epoch:  3753  loss:  0.00848469914850063  accuracy:  99.73825595812096\n",
            "epoch:  3754  loss:  0.010971975895935545  accuracy:  99.64871194379391\n",
            "epoch:  3755  loss:  0.0109399493879231  accuracy:  99.61427193828351\n",
            "epoch:  3756  loss:  0.008953861423595156  accuracy:  99.7933599669376\n",
            "epoch:  3757  loss:  0.009934034982766356  accuracy:  99.69003995040639\n",
            "epoch:  3758  loss:  0.010579815205138942  accuracy:  99.67626394820223\n",
            "epoch:  3759  loss:  0.008723458621293556  accuracy:  99.74514395922303\n",
            "epoch:  3760  loss:  0.01156006691339928  accuracy:  99.64871194379391\n",
            "epoch:  3761  loss:  0.012012951854372764  accuracy:  99.61427193828351\n",
            "epoch:  3762  loss:  0.01709528719065081  accuracy:  99.46273591403775\n",
            "epoch:  3763  loss:  0.023004008774508474  accuracy:  99.24231987877118\n",
            "epoch:  3764  loss:  0.020903448074712748  accuracy:  99.27675988428157\n",
            "epoch:  3765  loss:  0.06129632931418064  accuracy:  98.3331037332966\n",
            "epoch:  3766  loss:  0.09119973656841245  accuracy:  97.27235156357625\n",
            "epoch:  3767  loss:  0.014434919419892405  accuracy:  99.57294393167103\n",
            "epoch:  3768  loss:  0.00869560459067425  accuracy:  99.78647196583552\n",
            "epoch:  3769  loss:  0.009472238576315965  accuracy:  99.66937594710015\n",
            "epoch:  3770  loss:  0.008287433912236136  accuracy:  99.78647196583552\n",
            "epoch:  3771  loss:  0.013053420427110227  accuracy:  99.53850392616063\n",
            "epoch:  3772  loss:  0.01538187209857077  accuracy:  99.49028791844607\n",
            "epoch:  3773  loss:  0.009583620632845841  accuracy:  99.75203196032511\n",
            "epoch:  3774  loss:  0.008815236234106509  accuracy:  99.75203196032511\n",
            "epoch:  3775  loss:  0.009055170042729674  accuracy:  99.71070395371264\n",
            "epoch:  3776  loss:  0.010270908026934082  accuracy:  99.69003995040639\n",
            "epoch:  3777  loss:  0.011126670863070487  accuracy:  99.64871194379391\n",
            "epoch:  3778  loss:  0.01241905514113587  accuracy:  99.59360793497727\n",
            "epoch:  3779  loss:  0.013581270557901827  accuracy:  99.58671993387519\n",
            "epoch:  3780  loss:  0.011237415016006808  accuracy:  99.61427193828351\n",
            "epoch:  3781  loss:  0.01317973880161163  accuracy:  99.55227992836478\n",
            "epoch:  3782  loss:  0.02988368666314555  accuracy:  98.83592781374846\n",
            "epoch:  3783  loss:  0.12466330425963904  accuracy:  96.32869541259127\n",
            "epoch:  3784  loss:  0.05335560023679689  accuracy:  98.54663176746108\n",
            "epoch:  3785  loss:  0.022907097894674773  accuracy:  99.35941589750654\n",
            "epoch:  3786  loss:  0.013372540045419266  accuracy:  99.62804794048768\n",
            "epoch:  3787  loss:  0.012193136962414784  accuracy:  99.64182394269183\n",
            "epoch:  3788  loss:  0.009302568672026208  accuracy:  99.73136795701888\n",
            "epoch:  3789  loss:  0.010590554223618034  accuracy:  99.655599944896\n",
            "epoch:  3790  loss:  0.00857094203405886  accuracy:  99.72447995591679\n",
            "epoch:  3791  loss:  0.01251453843404703  accuracy:  99.60049593607935\n",
            "epoch:  3792  loss:  0.013458328352383921  accuracy:  99.55227992836478\n",
            "epoch:  3793  loss:  0.008854723147970976  accuracy:  99.69692795150847\n",
            "epoch:  3794  loss:  0.009702158326895468  accuracy:  99.69003995040639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzhNLIpoPts9"
      },
      "source": [
        "## Test Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvCCKouRjUCi",
        "outputId": "7aeac026-48c0-4a34-dc96-4f0d39242974"
      },
      "source": [
        "test_net(model,dataloader_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.405     0.286     0.336       576\n",
            "           1      0.358     0.521     0.424       436\n",
            "           2      0.593     0.160     0.252       100\n",
            "           3      0.838     0.581     0.686       516\n",
            "           4      0.608     0.820     0.698       582\n",
            "\n",
            "    accuracy                          0.536      2210\n",
            "   macro avg      0.560     0.474     0.479      2210\n",
            "weighted avg      0.559     0.536     0.527      2210\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSgKaGBeP0J0"
      },
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIktfBF42QSq"
      },
      "source": [
        "PATH = './5000epoch_base.pth'\r\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrfNnAJmXY4t"
      },
      "source": [
        "## Preload model and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J22oezA1j78C"
      },
      "source": [
        "with gzip.open('./data_test_split.pkl.gzip','rb') as f:\n",
        "    data = pickle.load(f)\n",
        "    S_test = data['state']\n",
        "    A_test = data['action']\n",
        "f.close()\n",
        "carRacing_dataset_test = carRacingDataset(train = False, load = True, states = S_test, actions = A_test)#, transform=transform)\n",
        "dataloader_test = DataLoader(carRacing_dataset_test,shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-uInjKpXrdm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e73f9a1-d0ea-451d-c7e6-f12542a2f898"
      },
      "source": [
        "pretrained_model = './car_racing_largenet_5000.pth'\r\n",
        "model = Net()\r\n",
        "model.load_state_dict(torch.load(pretrained_model))\r\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(16, 32, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(3, 3))\n",
              "  (fc1): Linear(in_features=576, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gTUNE5gMZKY"
      },
      "source": [
        "# Pruning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRvMqwcDX52b"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QSDPATYjCHc"
      },
      "source": [
        "def global_fc_unstructured_prune(net,ratio):\n",
        "    model.cuda()\n",
        "    parameters_to_prune = (\n",
        "        (net.fc1, 'weight'),\n",
        "        (net.fc2, 'weight'),\n",
        "        (net.fc3, 'weight')\n",
        "    )\n",
        "    prune.global_unstructured(parameters_to_prune, pruning_method=prune.L1Unstructured, amount=ratio)\n",
        "\n",
        "def global_conv_unstructured_prune(net,ratio):\n",
        "    model.cuda()\n",
        "    parameters_to_prune = (\n",
        "      (net.conv1, 'weight'),\n",
        "      (net.conv2, 'weight'),\n",
        "      (net.conv3, 'weight')\n",
        "    )\n",
        "    prune.global_unstructured(parameters_to_prune, pruning_method=prune.L1Unstructured, amount=ratio)\n",
        "\n",
        "def layerwise_conv_unstructured_prune(net,ratio):\n",
        "    model.cuda()\n",
        "    prune.l1_unstructured(net.conv1, name='weight', amount=ratio)\n",
        "    prune.l1_unstructured(net.conv2, name='weight', amount=ratio)\n",
        "    prune.l1_unstructured(net.conv3, name='weight', amount=ratio)\n",
        "\n",
        "def layerwise_conv_structured_prune(net,ratio):\n",
        "    model.cuda()\n",
        "    prune.ln_structured(net.conv1, name='weight', amount=ratio, n=1, dim=0)\n",
        "    prune.ln_structured(net.conv2, name='weight', amount=ratio, n=1, dim=0)\n",
        "    prune.ln_structured(net.conv3, name='weight', amount=ratio, n=1, dim=0)\n",
        "\n",
        "def remove_prune_params(model):\n",
        "    prune.remove(model.conv1,\"weight\")\n",
        "    prune.remove(model.conv2,\"weight\")\n",
        "    prune.remove(model.conv3,\"weight\")\n",
        "    prune.remove(model.fc1,\"weight\")\n",
        "    prune.remove(model.fc2,\"weight\")\n",
        "    prune.remove(model.fc3,\"weight\")\n",
        "\n",
        "def print_prune_results(net):\n",
        "    print(\n",
        "        \"Sparsity in conv1.weight: {:.2f}%\".format(\n",
        "            100. * float(torch.sum(net.conv1.weight == 0))\n",
        "            / float(net.conv1.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"Sparsity in conv2.weight: {:.2f}%\".format(\n",
        "            100. * float(torch.sum(net.conv2.weight == 0))\n",
        "            / float(net.conv2.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"Sparsity in conv3.weight: {:.2f}%\".format(\n",
        "            100. * float(torch.sum(net.conv3.weight == 0))\n",
        "            / float(net.conv3.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"Sparsity in fc1.weight: {:.2f}%\".format(\n",
        "            100. * float(torch.sum(net.fc1.weight == 0))\n",
        "            / float(net.fc1.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"Sparsity in fc2.weight: {:.2f}%\".format(\n",
        "            100. * float(torch.sum(net.fc2.weight == 0))\n",
        "            / float(net.fc2.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"Sparsity in fc3.weight: {:.2f}%\".format(\n",
        "            100. * float(torch.sum(net.fc3.weight == 0))\n",
        "            / float(net.fc3.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    num_pruned = float(torch.sum(net.conv1.weight == 0)\n",
        "                + torch.sum(net.conv2.weight == 0)\n",
        "                + torch.sum(net.conv3.weight == 0)\n",
        "                + torch.sum(net.fc1.weight == 0)\n",
        "                + torch.sum(net.fc2.weight == 0)\n",
        "                + torch.sum(net.fc3.weight == 0)\n",
        "            )\n",
        "    num_total = float(\n",
        "                net.conv1.weight.nelement()\n",
        "                + net.conv2.weight.nelement()\n",
        "                + net.conv3.weight.nelement()\n",
        "                + net.fc1.weight.nelement()\n",
        "                + net.fc2.weight.nelement()\n",
        "                + net.fc3.weight.nelement()\n",
        "            )\n",
        "    print(\n",
        "        \"Global sparsity: {:.2f}%\".format(\n",
        "            100. * float(num_pruned)/float(num_total)\n",
        "\n",
        "        )\n",
        "    )\n",
        "    print(\"Total number of weights: \",num_total)\n",
        "    print(\"Number of unpruned weights: \",num_total-num_pruned)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKZthLJGX9F2"
      },
      "source": [
        "## Prune model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQ-DQ5LRmLw_",
        "outputId": "628f63fa-ff02-490a-8f79-3e6de3403fc6"
      },
      "source": [
        "pretrained_model = './car_racing_largenet_5000.pth'\n",
        "model = Net()\n",
        "model.load_state_dict(torch.load(pretrained_model))\n",
        "#global_conv_unstructured_prune(model,0.8)\n",
        "layerwise_conv_unstructured_prune(model,0.0)\n",
        "#layerwise_conv_structured_prune(model,0.8)\n",
        "global_fc_unstructured_prune(model,0.0)\n",
        "# Remove pruning temp params\n",
        "remove_prune_params(model)\n",
        "print_prune_results(model)\n",
        "#count_sign_diff(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sparsity in conv1.weight: 0.00%\n",
            "Sparsity in conv2.weight: 0.00%\n",
            "Sparsity in conv3.weight: 0.00%\n",
            "Sparsity in fc1.weight: 0.00%\n",
            "Sparsity in fc2.weight: 0.00%\n",
            "Sparsity in fc3.weight: 0.00%\n",
            "Global sparsity: 0.00%\n",
            "Total number of weights:  207888.0\n",
            "Number of unpruned weights:  207888.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6hSXf3fYTQF"
      },
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQXFwPYf9_hI"
      },
      "source": [
        "PATH = './car_racing_largenet_p80_layerwise_unstructured_finetuned.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFak20bFYWl8"
      },
      "source": [
        "## Fine-tune model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B_8cofT0ghFy",
        "outputId": "d061b7cc-d65a-44e9-db63-1f7d44bdf533"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
        "train_net(model,dataloader,500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  1  loss:  21.7916922588698  accuracy:  33.457795881421134\n",
            "epoch:  2  loss:  6.318904612878513  accuracy:  41.69495360941389\n",
            "epoch:  3  loss:  4.3264882637920845  accuracy:  44.534962661235575\n",
            "epoch:  4  loss:  3.284208327457629  accuracy:  48.71011541072641\n",
            "epoch:  5  loss:  2.640258769585445  accuracy:  51.538809685449195\n",
            "epoch:  6  loss:  2.199879774197002  accuracy:  54.29961529757864\n",
            "epoch:  7  loss:  1.9202890122576142  accuracy:  57.06042090970808\n",
            "epoch:  8  loss:  1.7186625945025857  accuracy:  57.92034396922381\n",
            "epoch:  9  loss:  1.5429922574568344  accuracy:  59.651504865354156\n",
            "epoch:  10  loss:  1.4297382005282349  accuracy:  60.51142792486988\n",
            "epoch:  11  loss:  1.3453959791766597  accuracy:  61.09979633401222\n",
            "epoch:  12  loss:  1.2655168951272586  accuracy:  62.08418194161575\n",
            "epoch:  13  loss:  1.2142590999495366  accuracy:  63.05725277212039\n",
            "epoch:  14  loss:  1.1753860103865506  accuracy:  62.9214754469337\n",
            "epoch:  15  loss:  1.1304173368786115  accuracy:  63.74745417515275\n",
            "epoch:  16  loss:  1.1026156919389376  accuracy:  63.487214301878254\n",
            "epoch:  17  loss:  1.061304377090556  accuracy:  64.23398959040507\n",
            "epoch:  18  loss:  1.0251862866410737  accuracy:  64.5621181262729\n",
            "epoch:  19  loss:  0.9987105614703606  accuracy:  64.87893188504187\n",
            "epoch:  20  loss:  0.981282208806979  accuracy:  65.01470921022856\n",
            "epoch:  21  loss:  0.9576311784649522  accuracy:  65.26363430640416\n",
            "epoch:  22  loss:  0.942071783823189  accuracy:  65.51255940257977\n",
            "epoch:  23  loss:  0.9320848286084444  accuracy:  65.39941163159085\n",
            "epoch:  24  loss:  0.9072069300869304  accuracy:  66.39511201629328\n",
            "epoch:  25  loss:  0.8978864575678689  accuracy:  66.4969450101833\n",
            "epoch:  26  loss:  0.8818212465399341  accuracy:  67.06268386512785\n",
            "epoch:  27  loss:  0.8697017525677013  accuracy:  66.70061099796334\n",
            "epoch:  28  loss:  0.8616876134264925  accuracy:  67.06268386512785\n",
            "epoch:  29  loss:  0.8551438053718761  accuracy:  66.82507354605114\n",
            "epoch:  30  loss:  0.8476139973747053  accuracy:  67.2663498529079\n",
            "epoch:  31  loss:  0.8339705619776403  accuracy:  67.37949762389681\n",
            "epoch:  32  loss:  0.822892384902469  accuracy:  67.9112921475447\n",
            "epoch:  33  loss:  0.815876652075441  accuracy:  67.85471826205024\n",
            "epoch:  34  loss:  0.8077070094201597  accuracy:  68.29599456890699\n",
            "epoch:  35  loss:  0.8004675332872434  accuracy:  68.31862412310477\n",
            "epoch:  36  loss:  0.7983494387085175  accuracy:  67.74157049106132\n",
            "epoch:  37  loss:  0.7882087578005207  accuracy:  68.6806969902693\n",
            "epoch:  38  loss:  0.7914951024591774  accuracy:  68.09232858112695\n",
            "epoch:  39  loss:  0.7815729861589653  accuracy:  68.32993890020367\n",
            "epoch:  40  loss:  0.7781726318156728  accuracy:  68.23942068341253\n",
            "epoch:  41  loss:  0.7741812989301179  accuracy:  68.25073546051142\n",
            "epoch:  42  loss:  0.7670685229433098  accuracy:  68.75990042996153\n",
            "epoch:  43  loss:  0.7591336846324647  accuracy:  68.53360488798371\n",
            "epoch:  44  loss:  0.7544907593948319  accuracy:  68.98619597193935\n",
            "epoch:  45  loss:  0.7516513840055326  accuracy:  69.30300973070831\n",
            "epoch:  46  loss:  0.7443873622712034  accuracy:  69.08802896582937\n",
            "epoch:  47  loss:  0.741175534350755  accuracy:  69.26906539941163\n",
            "epoch:  48  loss:  0.7351143073579741  accuracy:  69.26906539941163\n",
            "epoch:  49  loss:  0.7382382927612094  accuracy:  69.1785471826205\n",
            "epoch:  50  loss:  0.7268388402437727  accuracy:  69.23512106811496\n",
            "epoch:  51  loss:  0.727179726976484  accuracy:  69.23512106811496\n",
            "epoch:  52  loss:  0.7205989660113935  accuracy:  69.51799049558724\n",
            "epoch:  53  loss:  0.7202985394888535  accuracy:  69.65376782077394\n",
            "epoch:  54  loss:  0.7188732526129148  accuracy:  69.83480425435619\n",
            "epoch:  55  loss:  0.7235261520046701  accuracy:  69.26906539941163\n",
            "epoch:  56  loss:  0.7100431233894018  accuracy:  70.14030323602626\n",
            "epoch:  57  loss:  0.7107437672618289  accuracy:  69.76691559176284\n",
            "epoch:  58  loss:  0.7083088278392775  accuracy:  70.18556234442181\n",
            "epoch:  59  loss:  0.7019103492080532  accuracy:  70.25345100701516\n",
            "epoch:  60  loss:  0.7014223858967009  accuracy:  70.1968771215207\n",
            "epoch:  61  loss:  0.7037041807072172  accuracy:  70.41185788639964\n",
            "epoch:  62  loss:  0.6936038680733747  accuracy:  70.47974654899298\n",
            "epoch:  63  loss:  0.6967381366401486  accuracy:  70.23082145281738\n",
            "epoch:  64  loss:  0.6907391642979244  accuracy:  70.38922833220185\n",
            "epoch:  65  loss:  0.6883478811974708  accuracy:  70.49106132609188\n",
            "epoch:  66  loss:  0.6829759993483562  accuracy:  71.30572527721203\n",
            "epoch:  67  loss:  0.6808022803433693  accuracy:  70.73998642226748\n",
            "epoch:  68  loss:  0.6821069711877038  accuracy:  70.88707852455306\n",
            "epoch:  69  loss:  0.679237919078744  accuracy:  71.28309572301426\n",
            "epoch:  70  loss:  0.6774611906866111  accuracy:  71.00022629554198\n",
            "epoch:  71  loss:  0.6754478604026336  accuracy:  71.07942973523421\n",
            "epoch:  72  loss:  0.6731041831030352  accuracy:  71.16994795202534\n",
            "epoch:  73  loss:  0.6672403693914036  accuracy:  71.19257750622313\n",
            "epoch:  74  loss:  0.6692829276134753  accuracy:  70.83050463905862\n",
            "epoch:  75  loss:  0.6693268066605552  accuracy:  71.36229916270649\n",
            "epoch:  76  loss:  0.6621797081706049  accuracy:  71.66779814437656\n",
            "epoch:  77  loss:  0.6623388321913861  accuracy:  71.67911292147545\n",
            "epoch:  78  loss:  0.658755617933215  accuracy:  71.80357546956326\n",
            "epoch:  79  loss:  0.6615740982324566  accuracy:  71.67911292147545\n",
            "epoch:  80  loss:  0.6572577450765854  accuracy:  71.90540846345327\n",
            "epoch:  81  loss:  0.6531698708014673  accuracy:  71.88277890925549\n",
            "epoch:  82  loss:  0.652157739401673  accuracy:  72.04118578863996\n",
            "epoch:  83  loss:  0.6608368720936003  accuracy:  71.71305725277212\n",
            "epoch:  84  loss:  0.6475964754341037  accuracy:  72.23353699932112\n",
            "epoch:  85  loss:  0.6488770430215912  accuracy:  72.00724145734328\n",
            "epoch:  86  loss:  0.6493609045042282  accuracy:  72.4937768725956\n",
            "epoch:  87  loss:  0.6479310438451683  accuracy:  72.21090744512333\n",
            "epoch:  88  loss:  0.6490638617423627  accuracy:  71.79226069246435\n",
            "epoch:  89  loss:  0.6417424060095757  accuracy:  72.05250056573885\n",
            "epoch:  90  loss:  0.6426973832384659  accuracy:  72.4937768725956\n",
            "epoch:  91  loss:  0.6422953600189107  accuracy:  72.4937768725956\n",
            "epoch:  92  loss:  0.6506979789337871  accuracy:  71.46413215659652\n",
            "epoch:  93  loss:  0.6438825639779547  accuracy:  71.96198234894773\n",
            "epoch:  94  loss:  0.6354797936168346  accuracy:  72.79927585426567\n",
            "epoch:  95  loss:  0.6306938466159271  accuracy:  72.93505317945237\n",
            "epoch:  96  loss:  0.6301260234395636  accuracy:  72.87847929395791\n",
            "epoch:  97  loss:  0.6249005467030063  accuracy:  72.93505317945237\n",
            "epoch:  98  loss:  0.6228648202806124  accuracy:  73.25186693822131\n",
            "epoch:  99  loss:  0.631161287039161  accuracy:  72.78796107716678\n",
            "epoch:  100  loss:  0.6207333602471491  accuracy:  73.26318171532021\n",
            "epoch:  101  loss:  0.6216197824297407  accuracy:  72.92373840235348\n",
            "epoch:  102  loss:  0.6233252372224289  accuracy:  72.96899751074903\n",
            "epoch:  103  loss:  0.6173599684203365  accuracy:  73.17266349852908\n",
            "epoch:  104  loss:  0.6211081860588266  accuracy:  73.04820095044127\n",
            "epoch:  105  loss:  0.6168663989272855  accuracy:  73.5234215885947\n",
            "epoch:  106  loss:  0.6167826445616864  accuracy:  73.24055216112242\n",
            "epoch:  107  loss:  0.6137717231403355  accuracy:  73.31975560081466\n",
            "epoch:  108  loss:  0.61370649354494  accuracy:  73.387644263408\n",
            "epoch:  109  loss:  0.6068517432058523  accuracy:  73.86286490156144\n",
            "epoch:  110  loss:  0.6088584063616401  accuracy:  73.5234215885947\n",
            "epoch:  111  loss:  0.6067033139700047  accuracy:  73.6478841366825\n",
            "epoch:  112  loss:  0.6092040251218024  accuracy:  73.1500339443313\n",
            "epoch:  113  loss:  0.607424306603788  accuracy:  73.69314324507808\n",
            "epoch:  114  loss:  0.6038924041620394  accuracy:  73.99864222674813\n",
            "epoch:  115  loss:  0.6034158426500279  accuracy:  73.97601267255035\n",
            "epoch:  116  loss:  0.6039321458388249  accuracy:  73.71577279927585\n",
            "epoch:  117  loss:  0.600303263247728  accuracy:  73.82892057026477\n",
            "epoch:  118  loss:  0.5990302850553206  accuracy:  74.05521611224259\n",
            "epoch:  119  loss:  0.5949514349085844  accuracy:  74.03258655804481\n",
            "epoch:  120  loss:  0.5956331185354153  accuracy:  74.07784566644037\n",
            "epoch:  121  loss:  0.5941989530290136  accuracy:  74.00995700384702\n",
            "epoch:  122  loss:  0.5939324835990182  accuracy:  74.22493776872595\n",
            "epoch:  123  loss:  0.5877253361877529  accuracy:  74.64358452138492\n",
            "epoch:  124  loss:  0.5897602875406965  accuracy:  74.1683638832315\n",
            "epoch:  125  loss:  0.5904826214138699  accuracy:  74.02127178094591\n",
            "epoch:  126  loss:  0.5857730362447146  accuracy:  74.25888210002263\n",
            "epoch:  127  loss:  0.5877933992765478  accuracy:  74.11178999773705\n",
            "epoch:  128  loss:  0.5882831616999472  accuracy:  74.64358452138492\n",
            "epoch:  129  loss:  0.5880479350783864  accuracy:  74.48517764200045\n",
            "epoch:  130  loss:  0.5799110308306388  accuracy:  74.58701063589048\n",
            "epoch:  131  loss:  0.5808029146074682  accuracy:  74.38334464811044\n",
            "epoch:  132  loss:  0.5817123400690222  accuracy:  74.6775288526816\n",
            "epoch:  133  loss:  0.575299398375464  accuracy:  74.75673229237384\n",
            "epoch:  134  loss:  0.5706649514500656  accuracy:  75.2093233763295\n",
            "epoch:  135  loss:  0.5745872167352368  accuracy:  75.08486082824169\n",
            "epoch:  136  loss:  0.5702850170725206  accuracy:  74.90382439465942\n",
            "epoch:  137  loss:  0.5702824293353165  accuracy:  75.3224711473184\n",
            "epoch:  138  loss:  0.565092862252602  accuracy:  75.22063815342838\n",
            "epoch:  139  loss:  0.571074863214195  accuracy:  75.1866938221317\n",
            "epoch:  140  loss:  0.5646453769222107  accuracy:  75.67322923738402\n",
            "epoch:  141  loss:  0.5658289729186544  accuracy:  75.09617560534058\n",
            "epoch:  142  loss:  0.5641776091320316  accuracy:  75.37904503281285\n",
            "epoch:  143  loss:  0.5645108678662472  accuracy:  75.45824847250509\n",
            "epoch:  144  loss:  0.5689228019999767  accuracy:  75.3224711473184\n",
            "epoch:  145  loss:  0.5596853210176648  accuracy:  75.96741344195519\n",
            "epoch:  146  loss:  0.5602244781905587  accuracy:  75.46956324960398\n",
            "epoch:  147  loss:  0.564324988434557  accuracy:  75.45824847250509\n",
            "epoch:  148  loss:  0.5587812864920704  accuracy:  75.91083955646074\n",
            "epoch:  149  loss:  0.5533183944942887  accuracy:  75.99004299615298\n",
            "epoch:  150  loss:  0.5555481331519451  accuracy:  75.76374745417515\n",
            "epoch:  151  loss:  0.5536997979462592  accuracy:  75.67322923738402\n",
            "epoch:  152  loss:  0.5500293771156117  accuracy:  76.14844987553745\n",
            "epoch:  153  loss:  0.5522208063884082  accuracy:  75.79769178547183\n",
            "epoch:  154  loss:  0.5519086299546301  accuracy:  76.11450554424079\n",
            "epoch:  155  loss:  0.5496235449043273  accuracy:  76.22765331522969\n",
            "epoch:  156  loss:  0.5493796120930322  accuracy:  76.43131930300973\n",
            "epoch:  157  loss:  0.5481228829509237  accuracy:  76.05793165874633\n",
            "epoch:  158  loss:  0.5461352158520766  accuracy:  76.45394885720751\n",
            "epoch:  159  loss:  0.5434838539943297  accuracy:  76.3408010862186\n",
            "epoch:  160  loss:  0.55080954003156  accuracy:  76.05793165874633\n",
            "epoch:  161  loss:  0.5432784986134486  accuracy:  76.45394885720751\n",
            "epoch:  162  loss:  0.5407489611703795  accuracy:  76.612355736592\n",
            "epoch:  163  loss:  0.5411661525378537  accuracy:  76.80470694727313\n",
            "epoch:  164  loss:  0.5412290084683051  accuracy:  76.44263408010862\n",
            "epoch:  165  loss:  0.5371598737842493  accuracy:  76.52183751980085\n",
            "epoch:  166  loss:  0.5377058296026648  accuracy:  76.57841140529531\n",
            "epoch:  167  loss:  0.5386846448048447  accuracy:  76.6010409594931\n",
            "epoch:  168  loss:  0.5338921488194639  accuracy:  76.73681828467979\n",
            "epoch:  169  loss:  0.5361373368014197  accuracy:  76.63498529078977\n",
            "epoch:  170  loss:  0.5347433865852662  accuracy:  76.63498529078977\n",
            "epoch:  171  loss:  0.5326879516018006  accuracy:  76.9857433808554\n",
            "epoch:  172  loss:  0.531713148679742  accuracy:  76.3521158633175\n",
            "epoch:  173  loss:  0.5372599893550739  accuracy:  76.6010409594931\n",
            "epoch:  174  loss:  0.5316270080579031  accuracy:  76.73681828467979\n",
            "epoch:  175  loss:  0.5322807475732284  accuracy:  77.09889115184431\n",
            "epoch:  176  loss:  0.5300054549091837  accuracy:  76.92916949536094\n",
            "epoch:  177  loss:  0.5272290286002965  accuracy:  76.73681828467979\n",
            "epoch:  178  loss:  0.528103023086314  accuracy:  76.62367051369088\n",
            "epoch:  179  loss:  0.5198886023101345  accuracy:  77.70988911518442\n",
            "epoch:  180  loss:  0.5272628293436128  accuracy:  76.63498529078977\n",
            "epoch:  181  loss:  0.5197790150770264  accuracy:  77.14415026023987\n",
            "epoch:  182  loss:  0.5218864517140156  accuracy:  77.2233536999321\n",
            "epoch:  183  loss:  0.5244803598602046  accuracy:  77.18940936863544\n",
            "epoch:  184  loss:  0.5174241237752064  accuracy:  77.52885268160217\n",
            "epoch:  185  loss:  0.521198790539819  accuracy:  77.40439013351437\n",
            "epoch:  186  loss:  0.5140017873427802  accuracy:  77.7438334464811\n",
            "epoch:  187  loss:  0.5172998475445749  accuracy:  77.3704458022177\n",
            "epoch:  188  loss:  0.5147241566428827  accuracy:  77.70988911518442\n",
            "epoch:  189  loss:  0.5143877172947577  accuracy:  77.32518669382213\n",
            "epoch:  190  loss:  0.5177515218176435  accuracy:  77.27992758542656\n",
            "epoch:  191  loss:  0.5143763999656791  accuracy:  77.3591310251188\n",
            "epoch:  192  loss:  0.5080564795818553  accuracy:  78.0040733197556\n",
            "epoch:  193  loss:  0.5107963768355203  accuracy:  77.65331522968998\n",
            "epoch:  194  loss:  0.5099816609424389  accuracy:  77.56279701289884\n",
            "epoch:  195  loss:  0.5078323041793852  accuracy:  78.1398506449423\n",
            "epoch:  196  loss:  0.5112186304164381  accuracy:  77.81172210907445\n",
            "epoch:  197  loss:  0.508645258451053  accuracy:  77.63068567549219\n",
            "epoch:  198  loss:  0.5069565310699957  accuracy:  77.77777777777777\n",
            "epoch:  199  loss:  0.501380491139366  accuracy:  78.36614618692012\n",
            "epoch:  200  loss:  0.5034536670764449  accuracy:  77.97012898845892\n",
            "epoch:  201  loss:  0.5009591302118519  accuracy:  78.53586784340348\n",
            "epoch:  202  loss:  0.5007426767806226  accuracy:  78.34351663272234\n",
            "epoch:  203  loss:  0.5000655605434751  accuracy:  78.40009051821679\n",
            "epoch:  204  loss:  0.5018084467765729  accuracy:  78.26431319303009\n",
            "epoch:  205  loss:  0.4984845273107337  accuracy:  78.23036886173342\n",
            "epoch:  206  loss:  0.49878216128350383  accuracy:  78.21905408463454\n",
            "epoch:  207  loss:  0.4963352628276477  accuracy:  78.56981217470016\n",
            "epoch:  208  loss:  0.49405516539393685  accuracy:  78.73953383118352\n",
            "epoch:  209  loss:  0.4971588260044634  accuracy:  78.33220185562344\n",
            "epoch:  210  loss:  0.49603014095225034  accuracy:  78.06064720525006\n",
            "epoch:  211  loss:  0.49570998593298227  accuracy:  78.32088707852455\n",
            "epoch:  212  loss:  0.48944806830730336  accuracy:  78.89794071056801\n",
            "epoch:  213  loss:  0.49158596507589536  accuracy:  78.3887757411179\n",
            "epoch:  214  loss:  0.48998156224313594  accuracy:  78.80742249377687\n",
            "epoch:  215  loss:  0.48956200132463873  accuracy:  79.23738402353473\n",
            "epoch:  216  loss:  0.49010866289630844  accuracy:  78.73953383118352\n",
            "epoch:  217  loss:  0.49563383048517884  accuracy:  78.26431319303009\n",
            "epoch:  218  loss:  0.4875619354413143  accuracy:  78.67164516859017\n",
            "epoch:  219  loss:  0.4835567463304857  accuracy:  79.06766236705137\n",
            "epoch:  220  loss:  0.4868186846001166  accuracy:  78.63770083729351\n",
            "epoch:  221  loss:  0.4900962898069767  accuracy:  78.36614618692012\n",
            "epoch:  222  loss:  0.4817205397595537  accuracy:  78.97714415026024\n",
            "epoch:  223  loss:  0.482843335895793  accuracy:  79.36184657162254\n",
            "epoch:  224  loss:  0.4771839143612666  accuracy:  79.38447612582033\n",
            "epoch:  225  loss:  0.48279335984926897  accuracy:  78.59244172889794\n",
            "epoch:  226  loss:  0.48035058626682947  accuracy:  79.18081013804029\n",
            "epoch:  227  loss:  0.4788733952238053  accuracy:  79.0224032586558\n",
            "epoch:  228  loss:  0.4787426704693013  accuracy:  79.16949536094138\n",
            "epoch:  229  loss:  0.4786119333528021  accuracy:  78.98845892735913\n",
            "epoch:  230  loss:  0.47817647523889717  accuracy:  78.99977370445802\n",
            "epoch:  231  loss:  0.4780766898338329  accuracy:  79.1468658067436\n",
            "epoch:  232  loss:  0.47401294359040763  accuracy:  79.27132835483141\n",
            "epoch:  233  loss:  0.4740976052306901  accuracy:  79.1581805838425\n",
            "epoch:  234  loss:  0.47616717634116884  accuracy:  79.6673455532926\n",
            "epoch:  235  loss:  0.4700729729404113  accuracy:  79.64471599909481\n",
            "epoch:  236  loss:  0.470699164521562  accuracy:  79.62208644489704\n",
            "epoch:  237  loss:  0.4672241334017922  accuracy:  79.73523421588595\n",
            "epoch:  238  loss:  0.4672807759155809  accuracy:  79.74654899298484\n",
            "epoch:  239  loss:  0.4639927009687512  accuracy:  80.1765105227427\n",
            "epoch:  240  loss:  0.46950014138901547  accuracy:  79.50893867390812\n",
            "epoch:  241  loss:  0.4674981655066141  accuracy:  79.37316134872142\n",
            "epoch:  242  loss:  0.46591423946582616  accuracy:  79.78049332428151\n",
            "epoch:  243  loss:  0.46203327855391585  accuracy:  80.02941842045712\n",
            "epoch:  244  loss:  0.4656524984551706  accuracy:  79.45236478841368\n",
            "epoch:  245  loss:  0.46504462497027704  accuracy:  79.83706720977597\n",
            "epoch:  246  loss:  0.46219816853838774  accuracy:  79.70128988458927\n",
            "epoch:  247  loss:  0.461712736724917  accuracy:  80.3122878479294\n",
            "epoch:  248  loss:  0.4589280802878785  accuracy:  80.10862186014936\n",
            "epoch:  249  loss:  0.4579910776023817  accuracy:  80.19914007694048\n",
            "epoch:  250  loss:  0.4597582147857349  accuracy:  80.13125141434713\n",
            "epoch:  251  loss:  0.4629827717845595  accuracy:  79.68997510749038\n",
            "epoch:  252  loss:  0.4593888952077096  accuracy:  79.96152975786377\n",
            "epoch:  253  loss:  0.4583909220556836  accuracy:  79.82575243267708\n",
            "epoch:  254  loss:  0.4599760850715702  accuracy:  80.22176963113827\n",
            "epoch:  255  loss:  0.4572329449421627  accuracy:  79.81443765557819\n",
            "epoch:  256  loss:  0.45514655173917407  accuracy:  80.10862186014936\n",
            "epoch:  257  loss:  0.4564765321234552  accuracy:  79.64471599909481\n",
            "epoch:  258  loss:  0.45275935802451084  accuracy:  80.21045485403937\n",
            "epoch:  259  loss:  0.45045347212666054  accuracy:  80.25571396243494\n",
            "epoch:  260  loss:  0.4469523251555737  accuracy:  80.65173116089613\n",
            "epoch:  261  loss:  0.4573794968137916  accuracy:  80.18782529984159\n",
            "epoch:  262  loss:  0.447577586592687  accuracy:  80.90065625707173\n",
            "epoch:  263  loss:  0.44864267519519024  accuracy:  80.11993663724824\n",
            "epoch:  264  loss:  0.4503173491862544  accuracy:  80.3122878479294\n",
            "epoch:  265  loss:  0.4477814711254359  accuracy:  80.35754695632497\n",
            "epoch:  266  loss:  0.4457821826450316  accuracy:  80.51595383570944\n",
            "epoch:  267  loss:  0.4473066051355933  accuracy:  80.44806517311609\n",
            "epoch:  268  loss:  0.44950534129849545  accuracy:  80.3122878479294\n",
            "epoch:  269  loss:  0.44196365919688296  accuracy:  80.85539714867618\n",
            "epoch:  270  loss:  0.44809489419865484  accuracy:  80.30097307083051\n",
            "epoch:  271  loss:  0.4399822734820678  accuracy:  80.92328581126952\n",
            "epoch:  272  loss:  0.43841725141383264  accuracy:  81.21747001584069\n",
            "epoch:  273  loss:  0.44040710678816003  accuracy:  81.01380402806065\n",
            "epoch:  274  loss:  0.43725529271948255  accuracy:  81.05906313645622\n",
            "epoch:  275  loss:  0.45231088440217  accuracy:  80.09730708305047\n",
            "epoch:  276  loss:  0.43862451369148975  accuracy:  81.02511880515954\n",
            "epoch:  277  loss:  0.4382568773882884  accuracy:  81.0703779135551\n",
            "epoch:  278  loss:  0.4439796947885299  accuracy:  80.96854491966508\n",
            "epoch:  279  loss:  0.4336272904332824  accuracy:  81.3193030097307\n",
            "epoch:  280  loss:  0.4356952959000997  accuracy:  80.70830504639059\n",
            "epoch:  281  loss:  0.4381582400369331  accuracy:  80.84408237157729\n",
            "epoch:  282  loss:  0.4356519836838846  accuracy:  80.99117447386287\n",
            "epoch:  283  loss:  0.43081212146273024  accuracy:  81.56822810590631\n",
            "epoch:  284  loss:  0.4337079002391054  accuracy:  81.16089613034623\n",
            "epoch:  285  loss:  0.42893967023665186  accuracy:  81.25141434713736\n",
            "epoch:  286  loss:  0.43043896991571545  accuracy:  81.26272912423626\n",
            "epoch:  287  loss:  0.4320230720491802  accuracy:  81.13826657614845\n",
            "epoch:  288  loss:  0.4296564634810964  accuracy:  81.21747001584069\n",
            "epoch:  289  loss:  0.4292730217971098  accuracy:  81.24009957003847\n",
            "epoch:  290  loss:  0.4322504261198775  accuracy:  81.00248925096176\n",
            "epoch:  291  loss:  0.4261076928641791  accuracy:  81.59085766010409\n",
            "epoch:  292  loss:  0.43165935043175585  accuracy:  81.48902466621408\n",
            "epoch:  293  loss:  0.42527365584696114  accuracy:  81.59085766010409\n",
            "epoch:  294  loss:  0.4260571040052935  accuracy:  81.14958135324734\n",
            "epoch:  295  loss:  0.4253388918088178  accuracy:  81.69269065399412\n",
            "epoch:  296  loss:  0.4247277184737487  accuracy:  81.59085766010409\n",
            "epoch:  297  loss:  0.42439218756029795  accuracy:  81.42113600362073\n",
            "epoch:  298  loss:  0.4298909302614587  accuracy:  81.38719167232405\n",
            "epoch:  299  loss:  0.425724416634  accuracy:  81.11563702195066\n",
            "epoch:  300  loss:  0.42563281472815356  accuracy:  81.53428377460963\n",
            "epoch:  301  loss:  0.42387328759715903  accuracy:  81.77189409368636\n",
            "epoch:  302  loss:  0.4245097054078801  accuracy:  81.47770988911519\n",
            "epoch:  303  loss:  0.42313501081684646  accuracy:  81.5795428830052\n",
            "epoch:  304  loss:  0.4178981425455184  accuracy:  81.85109753337859\n",
            "epoch:  305  loss:  0.4152716899935167  accuracy:  81.93030097307083\n",
            "epoch:  306  loss:  0.42111432863916576  accuracy:  81.62480199140077\n",
            "epoch:  307  loss:  0.41590933285570975  accuracy:  82.15659651504865\n",
            "epoch:  308  loss:  0.4155481939443665  accuracy:  81.76057931658747\n",
            "epoch:  309  loss:  0.4152430158161583  accuracy:  81.82846797918081\n",
            "epoch:  310  loss:  0.41666592525718277  accuracy:  81.77189409368636\n",
            "epoch:  311  loss:  0.41575603026911045  accuracy:  81.67006109979633\n",
            "epoch:  312  loss:  0.4146342446534821  accuracy:  82.12265218375198\n",
            "epoch:  313  loss:  0.40994622611465376  accuracy:  82.32631817153202\n",
            "epoch:  314  loss:  0.4140726895482326  accuracy:  81.72663498529079\n",
            "epoch:  315  loss:  0.4113547219548136  accuracy:  82.26974428603756\n",
            "epoch:  316  loss:  0.40774605588611906  accuracy:  82.07739307535641\n",
            "epoch:  317  loss:  0.4075807443933537  accuracy:  81.94161575016972\n",
            "epoch:  318  loss:  0.41080589184773997  accuracy:  82.16791129214755\n",
            "epoch:  319  loss:  0.41242433203968915  accuracy:  81.94161575016972\n",
            "epoch:  320  loss:  0.40798543165323015  accuracy:  82.24711473183979\n",
            "epoch:  321  loss:  0.40570520303939417  accuracy:  82.32631817153202\n",
            "epoch:  322  loss:  0.40974596346441666  accuracy:  81.68137587689523\n",
            "epoch:  323  loss:  0.4050417306817584  accuracy:  82.30368861733425\n",
            "epoch:  324  loss:  0.41027038979244385  accuracy:  82.04344874405975\n",
            "epoch:  325  loss:  0.4146793588884655  accuracy:  81.85109753337859\n",
            "epoch:  326  loss:  0.4025417726809797  accuracy:  82.50735460511427\n",
            "epoch:  327  loss:  0.4046817548567959  accuracy:  82.06607829825752\n",
            "epoch:  328  loss:  0.41084218843270814  accuracy:  81.90767141887305\n",
            "epoch:  329  loss:  0.41319788129493157  accuracy:  81.80583842498302\n",
            "epoch:  330  loss:  0.3985673963659407  accuracy:  82.77890925548766\n",
            "epoch:  331  loss:  0.3998507446672453  accuracy:  82.55261371350984\n",
            "epoch:  332  loss:  0.39656950961979676  accuracy:  83.02783435166327\n",
            "epoch:  333  loss:  0.3998373881956926  accuracy:  82.55261371350984\n",
            "epoch:  334  loss:  0.39966595004953176  accuracy:  82.65444670739987\n",
            "epoch:  335  loss:  0.4000681324913157  accuracy:  82.49603982801538\n",
            "epoch:  336  loss:  0.39788860181765096  accuracy:  82.75627970128988\n",
            "epoch:  337  loss:  0.39862716252595004  accuracy:  82.50735460511427\n",
            "epoch:  338  loss:  0.3946547703280064  accuracy:  83.16361167684997\n",
            "epoch:  339  loss:  0.3973556937311375  accuracy:  82.62050237610319\n",
            "epoch:  340  loss:  0.39575832178485315  accuracy:  82.88074224937769\n",
            "epoch:  341  loss:  0.39637184422947913  accuracy:  82.32631817153202\n",
            "epoch:  342  loss:  0.39291924263158245  accuracy:  83.09572301425662\n",
            "epoch:  343  loss:  0.39305246082008305  accuracy:  82.744964924191\n",
            "epoch:  344  loss:  0.39410224002555205  accuracy:  82.76759447838877\n",
            "epoch:  345  loss:  0.3921125721448578  accuracy:  82.89205702647658\n",
            "epoch:  346  loss:  0.3953564423367189  accuracy:  82.90337180357547\n",
            "epoch:  347  loss:  0.3949035467012189  accuracy:  82.43946594252093\n",
            "epoch:  348  loss:  0.3880030353513339  accuracy:  83.16361167684997\n",
            "epoch:  349  loss:  0.3918952605025103  accuracy:  82.75627970128988\n",
            "epoch:  350  loss:  0.39249752326690385  accuracy:  83.07309346005884\n",
            "epoch:  351  loss:  0.39102133648593546  accuracy:  83.15229689975108\n",
            "epoch:  352  loss:  0.38556306278929503  accuracy:  83.40122199592668\n",
            "epoch:  353  loss:  0.38470328526546527  accuracy:  83.35596288753112\n",
            "epoch:  354  loss:  0.38393452069923384  accuracy:  83.29938900203666\n",
            "epoch:  355  loss:  0.3861434178051298  accuracy:  83.25412989364109\n",
            "epoch:  356  loss:  0.38865000791856136  accuracy:  83.20887078524554\n",
            "epoch:  357  loss:  0.382573761209478  accuracy:  83.57094365241005\n",
            "epoch:  358  loss:  0.38113681787574794  accuracy:  83.59357320660783\n",
            "epoch:  359  loss:  0.3801603964697481  accuracy:  83.55962887531116\n",
            "epoch:  360  loss:  0.37948617092636167  accuracy:  83.44648110432225\n",
            "epoch:  361  loss:  0.38097788026953855  accuracy:  83.3785924417289\n",
            "epoch:  362  loss:  0.3850048223915454  accuracy:  83.14098212265219\n",
            "epoch:  363  loss:  0.38139408276506775  accuracy:  83.44648110432225\n",
            "epoch:  364  loss:  0.3785492055730114  accuracy:  83.3785924417289\n",
            "epoch:  365  loss:  0.38195630203250525  accuracy:  83.62751753790451\n",
            "epoch:  366  loss:  0.3780891793322903  accuracy:  83.29938900203666\n",
            "epoch:  367  loss:  0.3785756500119617  accuracy:  83.7519800859923\n",
            "epoch:  368  loss:  0.37713941129172757  accuracy:  83.58225842950894\n",
            "epoch:  369  loss:  0.37810810172981363  accuracy:  83.58225842950894\n",
            "epoch:  370  loss:  0.3764461997030655  accuracy:  83.55962887531116\n",
            "epoch:  371  loss:  0.3772971296261867  accuracy:  83.43516632722336\n",
            "epoch:  372  loss:  0.37533910117299885  accuracy:  83.60488798370672\n",
            "epoch:  373  loss:  0.3726570525706745  accuracy:  83.54831409821226\n",
            "epoch:  374  loss:  0.3712070943152481  accuracy:  84.1366825073546\n",
            "epoch:  375  loss:  0.3708851451004056  accuracy:  83.94433129667345\n",
            "epoch:  376  loss:  0.37407243174917426  accuracy:  83.78592441728898\n",
            "epoch:  377  loss:  0.38277093977794896  accuracy:  83.49174021271781\n",
            "epoch:  378  loss:  0.37124916340571557  accuracy:  83.95564607377234\n",
            "epoch:  379  loss:  0.37036624510691807  accuracy:  84.00090518216791\n",
            "epoch:  380  loss:  0.3651251157205767  accuracy:  84.05747906766237\n",
            "epoch:  381  loss:  0.37696982853740124  accuracy:  83.10703779135551\n",
            "epoch:  382  loss:  0.36776794056515805  accuracy:  83.887757411179\n",
            "epoch:  383  loss:  0.36828922283921905  accuracy:  84.29508938673908\n",
            "epoch:  384  loss:  0.3713862148850556  accuracy:  83.41253677302556\n",
            "epoch:  385  loss:  0.3661043029088838  accuracy:  84.03484951346458\n",
            "epoch:  386  loss:  0.3659858246495967  accuracy:  83.91038696537679\n",
            "epoch:  387  loss:  0.3646743004948987  accuracy:  83.86512785698122\n",
            "epoch:  388  loss:  0.36749302396733285  accuracy:  83.78592441728898\n",
            "epoch:  389  loss:  0.36636533804489063  accuracy:  83.84249830278344\n",
            "epoch:  390  loss:  0.3628143570823188  accuracy:  84.19325639284907\n",
            "epoch:  391  loss:  0.3635842646003228  accuracy:  84.09142339895904\n",
            "epoch:  392  loss:  0.362952613647126  accuracy:  84.44218148902466\n",
            "epoch:  393  loss:  0.36524408168856387  accuracy:  84.12536773025572\n",
            "epoch:  394  loss:  0.3644668185406072  accuracy:  84.05747906766237\n",
            "epoch:  395  loss:  0.3609003181956855  accuracy:  84.48744059742023\n",
            "epoch:  396  loss:  0.35857501515410933  accuracy:  84.71373613939805\n",
            "epoch:  397  loss:  0.3612723034427403  accuracy:  84.23851550124462\n",
            "epoch:  398  loss:  0.36413215203613253  accuracy:  83.86512785698122\n",
            "epoch:  399  loss:  0.36062928306878383  accuracy:  84.37429282643132\n",
            "epoch:  400  loss:  0.36056746321246214  accuracy:  84.02353473636569\n",
            "epoch:  401  loss:  0.3683656923815146  accuracy:  83.94433129667345\n",
            "epoch:  402  loss:  0.3542696538858215  accuracy:  84.54401448291469\n",
            "epoch:  403  loss:  0.3596758201573331  accuracy:  84.00090518216791\n",
            "epoch:  404  loss:  0.3578193465504449  accuracy:  84.41955193482688\n",
            "epoch:  405  loss:  0.35970056107557313  accuracy:  84.45349626612355\n",
            "epoch:  406  loss:  0.3545990478307258  accuracy:  84.79293957909029\n",
            "epoch:  407  loss:  0.3630918963283509  accuracy:  84.41955193482688\n",
            "epoch:  408  loss:  0.35064661510931094  accuracy:  84.75899524779362\n",
            "epoch:  409  loss:  0.35502475647128906  accuracy:  84.79293957909029\n",
            "epoch:  410  loss:  0.353375974048665  accuracy:  84.57795881421136\n",
            "epoch:  411  loss:  0.3526169621558663  accuracy:  84.55532926001358\n",
            "epoch:  412  loss:  0.3640340431314109  accuracy:  83.85381307988233\n",
            "epoch:  413  loss:  0.35200565476092743  accuracy:  84.72505091649694\n",
            "epoch:  414  loss:  0.3493317207934819  accuracy:  84.89477257298032\n",
            "epoch:  415  loss:  0.35485493490047976  accuracy:  84.26114505544241\n",
            "epoch:  416  loss:  0.34909147123293416  accuracy:  84.81556913328808\n",
            "epoch:  417  loss:  0.3500081883226215  accuracy:  84.47612582032134\n",
            "epoch:  418  loss:  0.35231536247121126  accuracy:  84.80425435618918\n",
            "epoch:  419  loss:  0.35150013545380104  accuracy:  84.56664403711247\n",
            "epoch:  420  loss:  0.34786630751496395  accuracy:  85.00792034396922\n",
            "epoch:  421  loss:  0.3485051279398186  accuracy:  84.60058836840915\n",
            "epoch:  422  loss:  0.34692901755976285  accuracy:  85.06449422946368\n",
            "epoch:  423  loss:  0.3463573678670412  accuracy:  85.24553066304594\n",
            "epoch:  424  loss:  0.3498426576792641  accuracy:  84.74768047069473\n",
            "epoch:  425  loss:  0.34358051452304367  accuracy:  85.21158633174926\n",
            "epoch:  426  loss:  0.35390394967547584  accuracy:  84.28377460964019\n",
            "epoch:  427  loss:  0.34585222241079466  accuracy:  85.01923512106812\n",
            "epoch:  428  loss:  0.34449214696830205  accuracy:  85.08712378366147\n",
            "epoch:  429  loss:  0.3447477277161768  accuracy:  84.99660556687033\n",
            "epoch:  430  loss:  0.3438039184776629  accuracy:  84.99660556687033\n",
            "epoch:  431  loss:  0.3426617185848011  accuracy:  85.05317945236479\n",
            "epoch:  432  loss:  0.3407483612130092  accuracy:  85.46051142792487\n",
            "epoch:  433  loss:  0.34380950819018957  accuracy:  85.14369766915591\n",
            "epoch:  434  loss:  0.3444813652380097  accuracy:  85.01923512106812\n",
            "epoch:  435  loss:  0.3388881265584309  accuracy:  85.14369766915591\n",
            "epoch:  436  loss:  0.34397613655242154  accuracy:  85.03054989816701\n",
            "epoch:  437  loss:  0.3382883252271243  accuracy:  85.18895677755148\n",
            "epoch:  438  loss:  0.3410848149463693  accuracy:  85.66417741570491\n",
            "epoch:  439  loss:  0.33743900541510347  accuracy:  85.24553066304594\n",
            "epoch:  440  loss:  0.3378533097272762  accuracy:  85.3021045485404\n",
            "epoch:  441  loss:  0.3363901229837033  accuracy:  85.46051142792487\n",
            "epoch:  442  loss:  0.3389401855809194  accuracy:  85.12106811495813\n",
            "epoch:  443  loss:  0.33887377111896666  accuracy:  85.51708531341933\n",
            "epoch:  444  loss:  0.33328456191367545  accuracy:  85.65286263860602\n",
            "epoch:  445  loss:  0.33520548238180214  accuracy:  85.551029644716\n",
            "epoch:  446  loss:  0.3360201081564103  accuracy:  85.42656709662819\n",
            "epoch:  447  loss:  0.3325513856298758  accuracy:  85.64154786150714\n",
            "epoch:  448  loss:  0.33578307346659403  accuracy:  85.21158633174926\n",
            "epoch:  449  loss:  0.3405905517113643  accuracy:  85.21158633174926\n",
            "epoch:  450  loss:  0.3308264633552552  accuracy:  85.68680696990269\n",
            "epoch:  451  loss:  0.3326158798753905  accuracy:  85.84521384928716\n",
            "epoch:  452  loss:  0.3324889317340348  accuracy:  85.69812174700158\n",
            "epoch:  453  loss:  0.3343290561739744  accuracy:  85.32473410273818\n",
            "epoch:  454  loss:  0.3389030864475323  accuracy:  85.26816021724372\n",
            "epoch:  455  loss:  0.32907272788646885  accuracy:  85.92441728897941\n",
            "epoch:  456  loss:  0.32720732392499174  accuracy:  86.00362072867165\n",
            "epoch:  457  loss:  0.33082724294327426  accuracy:  85.46051142792487\n",
            "epoch:  458  loss:  0.32808807637592224  accuracy:  85.72075130119937\n",
            "epoch:  459  loss:  0.327095048548032  accuracy:  85.82258429508938\n",
            "epoch:  460  loss:  0.33236007234930964  accuracy:  85.48314098212265\n",
            "epoch:  461  loss:  0.3273280389635615  accuracy:  85.66417741570491\n",
            "epoch:  462  loss:  0.3274671442673524  accuracy:  85.94704684317719\n",
            "epoch:  463  loss:  0.32994650448641916  accuracy:  85.74338085539715\n",
            "epoch:  464  loss:  0.324933176208983  accuracy:  86.12808327675945\n",
            "epoch:  465  loss:  0.3274979232312004  accuracy:  86.21860149355058\n",
            "epoch:  466  loss:  0.3316355864706016  accuracy:  85.42656709662819\n",
            "epoch:  467  loss:  0.33064871264693696  accuracy:  85.75469563249604\n",
            "epoch:  468  loss:  0.32429183084491586  accuracy:  85.89047295768273\n",
            "epoch:  469  loss:  0.3233561679555647  accuracy:  86.27517537904504\n",
            "epoch:  470  loss:  0.3273613762028699  accuracy:  85.35867843403484\n",
            "epoch:  471  loss:  0.3266283601225704  accuracy:  86.00362072867165\n",
            "epoch:  472  loss:  0.32325912720344  accuracy:  86.00362072867165\n",
            "epoch:  473  loss:  0.3247286979767445  accuracy:  85.96967639737497\n",
            "epoch:  474  loss:  0.32181472463976285  accuracy:  86.20728671645169\n",
            "epoch:  475  loss:  0.3219582119943546  accuracy:  86.08282416836389\n",
            "epoch:  476  loss:  0.32654190701471514  accuracy:  85.69812174700158\n",
            "epoch:  477  loss:  0.32309498432050004  accuracy:  86.01493550577054\n",
            "epoch:  478  loss:  0.31729084257694845  accuracy:  86.17334238515501\n",
            "epoch:  479  loss:  0.32141844433245276  accuracy:  85.95836162027608\n",
            "epoch:  480  loss:  0.3170993865332093  accuracy:  86.3091197103417\n",
            "epoch:  481  loss:  0.3168188714858336  accuracy:  86.20728671645169\n",
            "epoch:  482  loss:  0.3145826625511047  accuracy:  86.59198913781398\n",
            "epoch:  483  loss:  0.31503972719362566  accuracy:  86.67119257750622\n",
            "epoch:  484  loss:  0.3195447314679825  accuracy:  86.08282416836389\n",
            "epoch:  485  loss:  0.32019339296836125  accuracy:  86.16202760805612\n",
            "epoch:  486  loss:  0.3226270816847598  accuracy:  86.00362072867165\n",
            "epoch:  487  loss:  0.3129880922962622  accuracy:  86.37700837293505\n",
            "epoch:  488  loss:  0.3151487279636986  accuracy:  86.25254582484725\n",
            "epoch:  489  loss:  0.31177190260113996  accuracy:  86.76171079429736\n",
            "epoch:  490  loss:  0.31107557319318796  accuracy:  86.73908124009957\n",
            "epoch:  491  loss:  0.31552899152236064  accuracy:  86.29780493324282\n",
            "epoch:  492  loss:  0.3121075641248366  accuracy:  86.5693595836162\n",
            "epoch:  493  loss:  0.31255059304362  accuracy:  86.60330391491287\n",
            "epoch:  494  loss:  0.31754618496019715  accuracy:  86.09413894546277\n",
            "epoch:  495  loss:  0.31350655239357833  accuracy:  86.17334238515501\n",
            "epoch:  496  loss:  0.30986098368517495  accuracy:  86.76171079429736\n",
            "epoch:  497  loss:  0.31130827955259244  accuracy:  86.7051369088029\n",
            "epoch:  498  loss:  0.31438405716357176  accuracy:  86.4448970355284\n",
            "epoch:  499  loss:  0.30860583118978036  accuracy:  86.9653767820774\n",
            "epoch:  500  loss:  0.30742673850027136  accuracy:  86.67119257750622\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7DSv859mM4J"
      },
      "source": [
        "## Test Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKDoihYxY2US",
        "outputId": "8a9ee27f-3f25-4175-ac10-55b2474fde35"
      },
      "source": [
        "model.cuda()\n",
        "test_net(model,dataloader_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.429     0.382     0.404       545\n",
            "           1      0.407     0.581     0.479       425\n",
            "           2      0.732     0.300     0.426       100\n",
            "           3      0.857     0.613     0.714       537\n",
            "           4      0.700     0.804     0.748       603\n",
            "\n",
            "    accuracy                          0.588      2210\n",
            "   macro avg      0.625     0.536     0.554      2210\n",
            "weighted avg      0.616     0.588     0.589      2210\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}